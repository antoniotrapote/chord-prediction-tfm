{"cells":[{"cell_type":"markdown","id":"36e6ce9a","metadata":{"id":"36e6ce9a"},"source":["# LSTM_model_v2 ‚Äî modelo LSTM (PyTorch)\n","utilizamos el dataset `songdb_funcional_v4`"]},{"cell_type":"markdown","id":"00436936","metadata":{"id":"00436936"},"source":["## 0) Entorno (Colab)"]},{"cell_type":"code","source":["#@title Semillas y determinismo\n","import random, os, numpy as np, torch\n","SEED = 42\n","random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"],"metadata":{"id":"C38G_ux7fg8i","executionInfo":{"status":"ok","timestamp":1756231091159,"user_tz":-120,"elapsed":7886,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}}},"id":"C38G_ux7fg8i","execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"id":"48d96011","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48d96011","executionInfo":{"status":"ok","timestamp":1756231091177,"user_tz":-120,"elapsed":20,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"264304ed-d275-4f29-e637-959167ba41f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n","PyTorch: 2.8.0+cu126\n","CUDA disponible: True\n","GPU: Tesla T4\n"]}],"source":["\n","#@title Comprobar GPU/versions\n","import sys, torch\n","print(\"Python:\", sys.version)\n","print(\"PyTorch:\", torch.__version__)\n","print(\"CUDA disponible:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))\n","else:\n","    print(\"‚ö†Ô∏è Activa GPU: Runtime ‚ñ∂ Change runtime type ‚ñ∂ GPU\")\n"]},{"cell_type":"markdown","id":"ec304546","metadata":{"id":"ec304546"},"source":["## 1) Configuraci√≥n"]},{"cell_type":"code","execution_count":3,"id":"e12770a1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e12770a1","executionInfo":{"status":"ok","timestamp":1756231091213,"user_tz":-120,"elapsed":23,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"25fe39d5-b599-4485-9025-f0bdbb7340ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config(data_path='/content/songdb_funcional_v4.csv', sequence_col='funcional_prog', val_size=0.1, test_size=0.1, random_state=42, seq_len=24, batch_size=128, epochs=6, lr=0.002, weight_decay=0.0001, dropout=0.2, embedding_dim=128, hidden_size=256, num_layers=2, grad_clip=1.0, amp=True, save_dir='/content/models_lstm_v1', save_name='lstm_best.pt', tokenizer_path='lstm_tokenizer.json', min_seq_len=8)\n"]}],"source":["from dataclasses import dataclass\n","\n","@dataclass\n","class Config:\n","    # Ruta al CSV en Colab (sube el archivo o m√≥ntalo desde Drive)\n","    data_path: str = \"/content/songdb_funcional_v4.csv\"\n","    # üîß Elige la columna de secuencia (sin autodetecci√≥n):\n","    sequence_col: str = \"funcional_prog\"   # cambia a \"chordprog\" si prefieres s√≠mbolos originales\n","\n","    # Splits y semilla\n","    val_size: float = 0.10\n","    test_size: float = 0.10\n","    random_state: int = 42\n","\n","    # Modelo/entrenamiento\n","    seq_len: int = 24\n","    batch_size: int = 128\n","    epochs: int = 6\n","    lr: float = 2e-3\n","    weight_decay: float = 1e-4\n","    dropout: float = 0.2\n","    embedding_dim: int = 128\n","    hidden_size: int = 256\n","    num_layers: int = 2\n","    grad_clip: float = 1.0\n","    amp: bool = True\n","\n","    # Guardado\n","    save_dir: str = \"/content/models_lstm_v1\"\n","    save_name: str = \"lstm_best.pt\"\n","    tokenizer_path: str = \"lstm_tokenizer.json\"\n","\n","    # Filtrado\n","    min_seq_len: int = 8  # ignora secuencias muy cortas\n","\n","cfg = Config()\n","print(cfg)\n"]},{"cell_type":"markdown","id":"9ddef432","metadata":{"id":"9ddef432"},"source":["## 2) Traer el CSV a Colab (elige una opci√≥n)"]},{"cell_type":"code","execution_count":4,"id":"9e7eb715","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"9e7eb715","executionInfo":{"status":"ok","timestamp":1756231114818,"user_tz":-120,"elapsed":23603,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"1907a388-bbe5-4079-b379-121d1efce8dd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c12001dd-4a2b-4e19-8d14-883388c70d65\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c12001dd-4a2b-4e19-8d14-883388c70d65\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving songdb_funcional_v4.csv to songdb_funcional_v4.csv\n","Subido: ['songdb_funcional_v4.csv']\n"]}],"source":["#@title A) Subir archivo\n","try:\n","    from google.colab import files\n","    uploaded = files.upload()\n","    print(\"Subido:\", list(uploaded.keys()))\n","except Exception as e:\n","    print(\"Subida (UI Colab) no disponible aqu√≠:\", e)\n"]},{"cell_type":"code","execution_count":5,"id":"ac76ee94","metadata":{"id":"ac76ee94","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756231117000,"user_tz":-120,"elapsed":2187,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"f4ee0fd6-017c-4503-d0c4-f21b8de9a9e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive no disponible aqu√≠: Error: credential propagation was unsuccessful\n"]}],"source":["#@title B) Montar Google Drive\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    print(\"Ejemplo: cfg.data_path = '/content/drive/MyDrive/songdb_funcional_v4.csv'\")\n","except Exception as e:\n","    print(\"Drive no disponible aqu√≠:\", e)\n"]},{"cell_type":"markdown","id":"ce4a6a9c","metadata":{"id":"ce4a6a9c"},"source":["## 3) Cargar CSV y tokenizar (whitespace)"]},{"cell_type":"code","execution_count":6,"id":"23512052","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"23512052","executionInfo":{"status":"ok","timestamp":1756231117479,"user_tz":-120,"elapsed":477,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"a8ad7241-9cc7-4058-8790-37ccd24975e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Filas totales: 2613\n"]},{"output_type":"display_data","data":{"text/plain":["                                      funcional_prog\n","0  vi #iv√∏ V/III V/VI vi IV ii V7 iii vi ii V7 I ...\n","1  VII VII I vi ii V7 VII VII I vi ii V7 I IV #iv...\n","2  i VI V/V V7 i VI V/V V7 i VI ii√∏ V7 i VI ii√∏ V..."],"text/html":["\n","  <div id=\"df-0cb95577-b05b-4157-ab1e-510501ae1522\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>funcional_prog</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vi #iv√∏ V/III V/VI vi IV ii V7 iii vi ii V7 I ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>VII VII I vi ii V7 VII VII I vi ii V7 I IV #iv...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>i VI V/V V7 i VI V/V V7 i VI ii√∏ V7 i VI ii√∏ V...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cb95577-b05b-4157-ab1e-510501ae1522')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0cb95577-b05b-4157-ab1e-510501ae1522 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0cb95577-b05b-4157-ab1e-510501ae1522');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-38a7b579-3a4b-4a3e-816b-6c37c3213e03\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38a7b579-3a4b-4a3e-816b-6c37c3213e03')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-38a7b579-3a4b-4a3e-816b-6c37c3213e03 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"print(\\\"Filas tras filtro min_seq_len:\\\", len(df))\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"funcional_prog\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"vi #iv\\u00f8 V/III V/VI vi IV ii V7 iii vi ii V7 I IV7 vii\\u00f8 V/VI vi #iv\\u00f8 V/III V/VI vi IV ii V7 iii vi ii V7 I V7 I V/II ii ii V7 I V/II ii V7 I V/VI vi #iv\\u00f8 V/III V/VI vi IV ii V7 iii vi ii V7 I V7 I III7\",\n          \"VII VII I vi ii V7 VII VII I vi ii V7 I IV #ivo I iii vi V/V V7 VII VII I vi ii V7 VII VII I vi ii V7 I IV #ivo I ii V7 I I vi bvi v V/IV IV IV vi bvi v V/IV IV IV vii bvii vi V/V V V ii V7 ii V7 VII VII I vi ii V7 VII VII I vi ii V7 I IV #ivo I iii vi V/V V7 iii IV iii IV iii ii ii V7 I V7\",\n          \"i VI V/V V7 i VI V/V V7 i VI ii\\u00f8 V7 i VI ii\\u00f8 V7 i i Vsub/V V7 iv iv ii\\u00f8 bII7 iv bII v\\u00f8 V/IV iv bII v\\u00f8 V/IV iv bII v\\u00f8 V/IV iv Vsub/II ii\\u00f8 V7 i VI ii\\u00f8 V7 i VI ii\\u00f8 V7 i i Vsub/V V7 iv iv ii\\u00f8 bII7 bII bII\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Filas tras filtro min_seq_len: 2612\n"]}],"source":["#@title Carga + tokenizaci√≥n\n","import pandas as pd, ast, re\n","\n","df = pd.read_csv(cfg.data_path)\n","assert cfg.sequence_col in df.columns, f\"Columna {cfg.sequence_col} no encontrada en el CSV.\"\n","print(\"Filas totales:\", len(df))\n","display(df[[cfg.sequence_col]].head(3))\n","\n","def parse_tokens_simple(s: str):\n","  \"\"\"Si viene como lista en string, intenta parsear\"\"\"\n","  if isinstance(s, str) and s.strip().startswith(\"[\") and s.strip().endswith(\"]\"):\n","    try:\n","      lst = ast.literal_eval(s)\n","      if isinstance(lst, list):\n","        return [str(t) for t in lst]\n","    except Exception:\n","      pass\n","\n","  # Normaliza separadores de comp√°s y saltos de l√≠nea a espacios\n","  s = str(s).replace(\"|\", \" \").replace(\"\\n\", \" \")\n","  toks = [t for t in re.findall(r\"\\S+\", s) if t.strip()]\n","  return toks\n","\n","df[\"_tokens_\"] = df[cfg.sequence_col].apply(parse_tokens_simple)\n","df = df[df[\"_tokens_\"].apply(len) >= cfg.min_seq_len].reset_index(drop=True)\n","print(\"Filas tras filtro min_seq_len:\", len(df))\n"]},{"cell_type":"markdown","id":"395c628f","metadata":{"id":"395c628f"},"source":["## 4) Split train/val/test (simple, por filas)"]},{"cell_type":"code","execution_count":7,"id":"6bd427ae","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bd427ae","executionInfo":{"status":"ok","timestamp":1756231118500,"user_tz":-120,"elapsed":1016,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"70336aa7-1e9b-4938-e153-1573660209ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["2089 261 262\n"]}],"source":["from sklearn.model_selection import train_test_split\n","train_df, tmp_df = train_test_split(df, test_size=cfg.val_size+cfg.test_size, random_state=cfg.random_state, shuffle=True)\n","rel_test = cfg.test_size / (cfg.val_size + cfg.test_size) if (cfg.val_size + cfg.test_size) > 0 else 0.5\n","val_df, test_df = train_test_split(tmp_df, test_size=rel_test, random_state=cfg.random_state, shuffle=True)\n","\n","train_seqs = train_df[\"_tokens_\"].tolist()\n","val_seqs   = val_df[\"_tokens_\"].tolist()\n","test_seqs  = test_df[\"_tokens_\"].tolist()\n","print(len(train_seqs), len(val_seqs), len(test_seqs))\n"]},{"cell_type":"markdown","id":"525bbdae","metadata":{"id":"525bbdae"},"source":["## 5) Vocabulario y codificaci√≥n"]},{"cell_type":"code","execution_count":8,"id":"6c2802e2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6c2802e2","executionInfo":{"status":"ok","timestamp":1756231118507,"user_tz":-120,"elapsed":6,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"0a753895-c6e6-4971-857f-b77e18ed7324"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size: 86\n"]}],"source":["from collections import Counter\n","import json\n","PAD, UNK, BOS, EOS = \"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"\n","\n","def build_vocab(seqs, min_freq=1):\n","    c = Counter()\n","    for s in seqs: c.update(s)\n","    vocab = [PAD, UNK, BOS, EOS] + [t for t,f in c.items() if f >= min_freq and t not in {PAD,UNK,BOS,EOS}]\n","    stoi = {t:i for i,t in enumerate(vocab)}\n","    itos = {i:t for t,i in stoi.items()}\n","    return vocab, stoi, itos\n","\n","vocab, stoi, itos = build_vocab(train_seqs, 1)\n","print(\"Vocab size:\", len(vocab))\n","\n","with open(cfg.tokenizer_path, \"w\") as f:\n","    json.dump({\"vocab\": vocab}, f, ensure_ascii=False, indent=2)\n","\n","def encode(seq, add_bos=True):\n","    ids = [stoi[BOS]] if add_bos else []\n","    ids += [stoi.get(t, stoi[UNK]) for t in seq]\n","    return ids\n"]},{"cell_type":"markdown","id":"969ecf11","metadata":{"id":"969ecf11"},"source":["## 6) Dataset (context‚Üínext) y DataLoaders"]},{"cell_type":"code","execution_count":9,"id":"72490711","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72490711","executionInfo":{"status":"ok","timestamp":1756231118709,"user_tz":-120,"elapsed":200,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"b7dde1b6-4231-475e-b1ce-6f10d1f2e889"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60979, 7044, 7669)"]},"metadata":{},"execution_count":9}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class NextTokenDataset(Dataset):\n","    def __init__(self, sequences, seq_len):\n","        self.samples = []\n","        for seq in sequences:\n","            ids = encode(seq, add_bos=True)\n","            if len(ids) <= seq_len: continue\n","            for i in range(seq_len, len(ids)):\n","                self.samples.append((ids[i-seq_len:i], ids[i]))\n","    def __len__(self): return len(self.samples)\n","    def __getitem__(self, idx):\n","        x, y = self.samples[idx]\n","        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n","\n","train_data = NextTokenDataset(train_seqs, cfg.seq_len)\n","val_data   = NextTokenDataset(val_seqs,   cfg.seq_len)\n","test_data  = NextTokenDataset(test_seqs,  cfg.seq_len)\n","\n","train_loader = DataLoader(train_data, batch_size=cfg.batch_size, shuffle=True, drop_last=True)\n","val_loader   = DataLoader(val_data,   batch_size=cfg.batch_size, shuffle=False)\n","test_loader  = DataLoader(test_data,  batch_size=cfg.batch_size, shuffle=False)\n","\n","len(train_data), len(val_data), len(test_data)\n"]},{"cell_type":"markdown","id":"ec1916a2","metadata":{"id":"ec1916a2"},"source":["## 7) Modelo LSTM"]},{"cell_type":"code","execution_count":10,"id":"6b17ed09","metadata":{"id":"6b17ed09","executionInfo":{"status":"ok","timestamp":1756231118713,"user_tz":-120,"elapsed":2,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}}},"outputs":[],"source":["#@title Definici√≥n del modelo\n","import torch.nn as nn\n","class ChordLSTM(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n","                           batch_first=True, dropout=dropout if num_layers>1 else 0.0,\n","                           bidirectional=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n","    def forward(self, x):\n","        e = self.emb(x)\n","        o, _ = self.rnn(e)\n","        return self.fc(self.dropout(o[:, -1, :]))\n"]},{"cell_type":"markdown","id":"7fffb0ff","metadata":{"id":"7fffb0ff"},"source":["## 8) Entrenamiento y m√©tricas (Top@K, MRR, PPL)"]},{"cell_type":"code","execution_count":11,"id":"15db18bc","metadata":{"id":"15db18bc","executionInfo":{"status":"ok","timestamp":1756231118717,"user_tz":-120,"elapsed":3,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}}},"outputs":[],"source":["import math, time, os, torch\n","import torch.nn.functional as F\n","\n","def topk_metrics(logits, targets, ks=(1,3,5)):\n","    out = {}\n","    with torch.no_grad():\n","        for k in ks:\n","            topk = logits.topk(k, dim=-1).indices\n","            out[f\"Top@{k}\"] = (topk == targets.unsqueeze(1)).any(dim=1).float().mean().item()\n","        ranks = (logits.argsort(dim=-1, descending=True) == targets.unsqueeze(1)).nonzero(as_tuple=False)[:,1] + 1\n","        out[\"MRR\"] = (1.0 / ranks.float()).mean().item()\n","    return out\n","\n","def evaluate(model, loader, criterion):\n","    model.eval()\n","    total, n = 0.0, 0\n","    agg = {\"Top@1\":0.0,\"Top@3\":0.0,\"Top@5\":0.0,\"MRR\":0.0}\n","    with torch.no_grad():\n","        for x,y in loader:\n","            x,y = x.to(device), y.to(device)\n","            logits = model(x)\n","            loss = criterion(logits, y)\n","            b = x.size(0); total += loss.item()*b; n += b\n","            m = topk_metrics(logits, y)\n","            for k in agg: agg[k] += m[k]*b\n","    for k in agg: agg[k] /= max(1,n)\n","    return {\"loss\": total/max(1,n), \"ppl\": math.exp(total/max(1,n)), **agg}\n","\n","def train_model(model, train_loader, val_loader, epochs, lr, weight_decay, grad_clip=1.0, amp=True, save_dir=\".\", save_name=\"best.pt\"):\n","    os.makedirs(save_dir, exist_ok=True)\n","    scaler = torch.cuda.amp.GradScaler(enabled=(amp and device.type=='cuda'))\n","    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    crit = torch.nn.CrossEntropyLoss()\n","    best_mrr, best_path = -1.0, os.path.join(save_dir, save_name)\n","    for ep in range(1, epochs+1):\n","        model.train(); t0 = time.time()\n","        for i,(x,y) in enumerate(train_loader,1):\n","            x,y = x.to(device), y.to(device)\n","            opt.zero_grad(set_to_none=True)\n","            with torch.cuda.amp.autocast(enabled=(amp and device.type=='cuda')):\n","                logits = model(x); loss = crit(logits,y)\n","            scaler.scale(loss).backward()\n","            if grad_clip is not None:\n","                scaler.unscale_(opt)\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","            scaler.step(opt); scaler.update()\n","            if i % 100 == 0: print(f\"Ep{ep} step {i}/{len(train_loader)} loss {loss.item():.4f}\")\n","        valm = evaluate(model, val_loader, crit)\n","        print(f\"Epoch {ep} | val loss {valm['loss']:.4f} ppl {valm['ppl']:.2f} Top@1 {valm['Top@1']:.3f} Top@3 {valm['Top@3']:.3f} Top@5 {valm['Top@5']:.3f} MRR {valm['MRR']:.3f}\")\n","        if valm[\"MRR\"] > best_mrr:\n","            best_mrr = valm[\"MRR\"]\n","            torch.save({\"model_state\": model.state_dict(), \"config\": dict(vars(cfg)), \"stoi\": stoi, \"itos\": itos}, best_path)\n","            print(\"üî• Guardado best ->\", best_path, \"| MRR:\", best_mrr)\n","    return best_mrr, best_path\n"]},{"cell_type":"markdown","id":"f8cc5fcc","metadata":{"id":"f8cc5fcc"},"source":["## 9) Entrenar LSTM"]},{"cell_type":"code","execution_count":12,"id":"05d64822","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05d64822","executionInfo":{"status":"ok","timestamp":1756231160902,"user_tz":-120,"elapsed":42169,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"22430c52-677f-461b-d304-e2515d570e31"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-717191719.py:31: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler(enabled=(amp and device.type=='cuda'))\n","/tmp/ipython-input-717191719.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=(amp and device.type=='cuda')):\n"]},{"output_type":"stream","name":"stdout","text":["Ep1 step 100/476 loss 2.2384\n","Ep1 step 200/476 loss 2.3146\n","Ep1 step 300/476 loss 2.0664\n","Ep1 step 400/476 loss 2.2425\n","Epoch 1 | val loss 2.1566 ppl 8.64 Top@1 0.437 Top@3 0.680 Top@5 0.767 MRR 0.584\n","üî• Guardado best -> /content/models_lstm_v1/lstm_best.pt | MRR: 0.5841175761837502\n","Ep2 step 100/476 loss 2.2561\n","Ep2 step 200/476 loss 1.9753\n","Ep2 step 300/476 loss 2.1835\n","Ep2 step 400/476 loss 1.9502\n","Epoch 2 | val loss 2.0980 ppl 8.15 Top@1 0.453 Top@3 0.691 Top@5 0.774 MRR 0.597\n","üî• Guardado best -> /content/models_lstm_v1/lstm_best.pt | MRR: 0.5970214201197713\n","Ep3 step 100/476 loss 2.3348\n","Ep3 step 200/476 loss 1.9495\n","Ep3 step 300/476 loss 1.7481\n","Ep3 step 400/476 loss 1.7912\n","Epoch 3 | val loss 2.0810 ppl 8.01 Top@1 0.460 Top@3 0.695 Top@5 0.776 MRR 0.602\n","üî• Guardado best -> /content/models_lstm_v1/lstm_best.pt | MRR: 0.6020486079651411\n","Ep4 step 100/476 loss 1.8587\n","Ep4 step 200/476 loss 1.7421\n","Ep4 step 300/476 loss 1.8021\n","Ep4 step 400/476 loss 2.1285\n","Epoch 4 | val loss 2.0956 ppl 8.13 Top@1 0.452 Top@3 0.693 Top@5 0.779 MRR 0.597\n","Ep5 step 100/476 loss 1.7164\n","Ep5 step 200/476 loss 1.8218\n","Ep5 step 300/476 loss 1.6124\n","Ep5 step 400/476 loss 1.7764\n","Epoch 5 | val loss 2.1347 ppl 8.45 Top@1 0.457 Top@3 0.685 Top@5 0.772 MRR 0.597\n","Ep6 step 100/476 loss 1.4832\n","Ep6 step 200/476 loss 1.5518\n","Ep6 step 300/476 loss 1.6740\n","Ep6 step 400/476 loss 1.4452\n","Epoch 6 | val loss 2.1611 ppl 8.68 Top@1 0.445 Top@3 0.687 Top@5 0.771 MRR 0.591\n","Best MRR: 0.6020486079651411 | path: /content/models_lstm_v1/lstm_best.pt\n"]}],"source":["#@title Train\n","import torch, os, json\n","torch.manual_seed(cfg.random_state)\n","model = ChordLSTM(vocab_size=len(vocab), embedding_dim=cfg.embedding_dim,\n","                          hidden_size=cfg.hidden_size, num_layers=cfg.num_layers,\n","                          dropout=cfg.dropout).to(device)\n","best_mrr, best_path = train_model(model, train_loader, val_loader, cfg.epochs, cfg.lr, cfg.weight_decay,\n","                                  grad_clip=cfg.grad_clip, amp=cfg.amp, save_dir=cfg.save_dir, save_name=cfg.save_name)\n","print(\"Best MRR:\", best_mrr, \"| path:\", best_path)\n"]},{"cell_type":"markdown","id":"0c28d6e7","metadata":{"id":"0c28d6e7"},"source":["## 10) Evaluaci√≥n en Test"]},{"cell_type":"code","execution_count":13,"id":"5277126c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5277126c","executionInfo":{"status":"ok","timestamp":1756231161512,"user_tz":-120,"elapsed":615,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"a1b00d77-b7a9-435f-8178-67bcaf8af4ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test: {'loss': 2.169651968660403, 'ppl': 8.755236413779173, 'Top@1': 0.4305646108755591, 'Top@3': 0.6828791240480612, 'Top@5': 0.7668535665390716, 'MRR': 0.580885472159635}\n"]}],"source":["#@title Test\n","import torch, os\n","ckpt = torch.load(os.path.join(cfg.save_dir, cfg.save_name), map_location=device)\n","model.load_state_dict(ckpt[\"model_state\"])\n","test_metrics = evaluate(model, test_loader, torch.nn.CrossEntropyLoss())\n","print(\"Test:\", test_metrics)\n"]},{"cell_type":"markdown","id":"510af377","metadata":{"id":"510af377"},"source":["## 11) predict_next(context, k=5)"]},{"cell_type":"code","execution_count":14,"id":"165bfb26","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"165bfb26","executionInfo":{"status":"ok","timestamp":1756231161525,"user_tz":-120,"elapsed":12,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"dba220e2-4839-4335-8d45-7af91a5344ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Context: ['III', 'III', '#IV', '#IV', 'bII', 'bII', 'natIII', 'natIII', 'III', '#IV', 'IV', 'VI', 'V', 'bVII', 'natVI', 'I', 'II', 'VII', 'VI', 'IV', 'III', 'I', 'VII', 'natVI']\n","Pred: [('II', 0.24083514511585236), ('VI', 0.11550020426511765), ('VII', 0.09397098422050476), ('natIII', 0.05708475410938263), ('natVI', 0.05385180190205574)]\n"]}],"source":["#@title predict_next()\n","import torch.nn.functional as F\n","def predict_next(context_tokens, k=5):\n","    model.eval()\n","    ids = [stoi.get(t, stoi[\"<unk>\"]) for t in context_tokens]\n","    if len(ids) < cfg.seq_len:\n","        ids = [stoi[\"<bos>\"]] * (cfg.seq_len - len(ids)) + ids\n","    else:\n","        ids = ids[-cfg.seq_len:]\n","    import torch\n","    x = torch.tensor(ids, dtype=torch.long, device=device).unsqueeze(0)\n","    with torch.no_grad():\n","        logits = model(x)\n","        probs = F.softmax(logits[0], dim=-1)\n","        topk = torch.topk(probs, k)\n","        return [(itos[i], float(p)) for i,p in zip(topk.indices.tolist(), topk.values.tolist())]\n","\n","# Ejemplo r√°pido (si hay datos)\n","if len(train_seqs):\n","    ctx = train_seqs[0][:cfg.seq_len]\n","    print(\"Context:\", ctx)\n","    print(\"Pred:\", predict_next(ctx, k=5))\n"]},{"cell_type":"markdown","source":["## 12) Inferencia incremental (quick test)"],"metadata":{"id":"e8cn_1P6r3d2"},"id":"e8cn_1P6r3d2"},{"cell_type":"code","source":["# @title Stateful predictor para uso interactivo paso a paso\n","import torch, torch.nn.functional as F\n","from torch import nn\n","\n","class StatefulPredictor:\n","    def __init__(self, model, stoi, itos, device, start_with_bos=True):\n","        self.model, self.stoi, self.itos = model.eval(), stoi, itos\n","        self.device = device\n","        self.start_with_bos = start_with_bos\n","        self.h = None  # (h,c) en LSTM; h en GRU\n","\n","    def reset(self):\n","        self.h = None\n","        if self.start_with_bos and \"<bos>\" in self.stoi:\n","            self._step(\"<bos>\")  # alinear con el entrenamiento\n","\n","    def _step(self, token):\n","        tid = torch.tensor([[self.stoi.get(token, self.stoi[\"<unk>\"])]], device=self.device)\n","        e = self.model.emb(tid)                             # (1,1,E)\n","        # Funciona igual para LSTM y GRU\n","        out, self.h = self.model.rnn(e, self.h)            # out: (1,1,H)\n","        logits = self.model.fc(out[:, -1, :])              # (1,V)\n","        return logits[0]\n","\n","    def add(self, token, k=5):\n","        \"\"\"Introduce el √∫ltimo acorde del contexto y devuelve predicci√≥n para el SIGUIENTE.\"\"\"\n","        logits = self._step(token)\n","        probs = F.softmax(logits, dim=-1)\n","        topk = torch.topk(probs, k)\n","        return [(self.itos[i.item()], float(p.item())) for i,p in zip(topk.indices, topk.values)]\n","\n","    def suggest(self, context_tokens, k=5):\n","        \"\"\"Da una predicci√≥n para el siguiente acorde tras un contexto completo.\"\"\"\n","        self.reset()\n","        preds = None\n","        for t in context_tokens:\n","            preds = self.add(t, k=k)  # la √∫ltima llamada produce la sugerencia para el siguiente\n","        return preds"],"metadata":{"id":"jQ2Jh9KKrnti","executionInfo":{"status":"ok","timestamp":1756231161526,"user_tz":-120,"elapsed":4,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}}},"id":"jQ2Jh9KKrnti","execution_count":15,"outputs":[]},{"cell_type":"code","source":["sp = StatefulPredictor(model, stoi, itos, device)\n","sp.suggest([\"ii\",\"V\"], k=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S1nHo4t3gwY9","executionInfo":{"status":"ok","timestamp":1756231161560,"user_tz":-120,"elapsed":34,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"1364eb97-dd90-440d-9e6e-3da200c5f5ec"},"id":"S1nHo4t3gwY9","execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('V', 0.19276435673236847),\n"," ('V7', 0.1380607634782791),\n"," ('v', 0.06758282333612442),\n"," ('ii', 0.06204349175095558),\n"," ('bVII', 0.049799397587776184)]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["sp.suggest([\"i\",\"vi\", 'ii'], k=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__5FJ5ZnXwkC","executionInfo":{"status":"ok","timestamp":1756231161688,"user_tz":-120,"elapsed":130,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"06f99e36-e389-4ad8-896d-d1b50c7aa39f"},"id":"__5FJ5ZnXwkC","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('V7', 0.27057090401649475),\n"," ('i', 0.12024112790822983),\n"," ('vi', 0.11982262134552002),\n"," ('ii', 0.10807666927576065),\n"," ('vii√∏', 0.05500981584191322)]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["sp.suggest([\"i\",\"bvi\"], k=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfVOVw4JYSJN","executionInfo":{"status":"ok","timestamp":1756231161689,"user_tz":-120,"elapsed":114,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"b0bfd39e-bcca-45d5-f878-bc440d328e5d"},"id":"qfVOVw4JYSJN","execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('VI', 0.09826728701591492),\n"," ('bII7', 0.09121581166982651),\n"," ('i', 0.08353113383054733),\n"," ('bii', 0.07816524803638458),\n"," ('vi√∏', 0.06509044766426086)]"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","id":"53afbbdb","metadata":{"id":"53afbbdb"},"source":["### Roadmap\n","- Ajuste de hiperpar√°metros (Ranadom Search)\n","- Re-ranking suave para evitar repes y favorecer cadencias.\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"accelerator":"GPU","language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}