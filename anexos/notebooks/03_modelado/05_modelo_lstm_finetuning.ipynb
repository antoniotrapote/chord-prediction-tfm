{"cells":[{"cell_type":"markdown","id":"615071c5","metadata":{"id":"615071c5"},"source":["# LSTM_torch_v3 — LSTM + Random Search (PyTorch)\n","\n","**Objetivo:** ajuste de hiperparámetros sobre un modelo **LSTM** base.  \n","**dataset:** `songdb_funcional_v4`\n","\n","**Estructura:**  \n","1) Entorno (semillas, GPU/versions).  \n","2) Configuración.  \n","3) Carga de CSV + tokenización.  \n","4) Split train/val/test.  \n","5) Vocab + codificación.  \n","6) Dataset + DataLoaders.  \n","7) Modelo LSTM con `tie_weights` opcional.  \n","8) Metricas y entrenamiento (Top@k, MRR, PPL).  \n","9) A/B Test: selección manual de hiperparámetros.  \n","10) Random Search (espacio de búsqueda,tabla de resultados, checkpoints).  \n","11) Empaquetar el mejor checkpoint con metadatos y nombre informativo"]},{"cell_type":"markdown","id":"fb6d041e","metadata":{"id":"fb6d041e"},"source":["## 1) Entorno"]},{"cell_type":"code","execution_count":null,"id":"53e2aad0","metadata":{"id":"53e2aad0"},"outputs":[],"source":["#@title  Semillas y determinismo\n","import random, os, numpy as np, torch\n","SEED = 42\n","random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n"]},{"cell_type":"code","execution_count":null,"id":"da47f894","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"da47f894","executionInfo":{"status":"ok","timestamp":1755690399368,"user_tz":-120,"elapsed":29,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"7dcf13f3-fb09-4a81-90b2-8eed0e94e3bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n","PyTorch: 2.8.0+cu126\n","CUDA disponible: True\n","GPU: Tesla T4\n"]}],"source":["#@title Comprobar GPU/versions\n","import sys, torch\n","print(\"Python:\", sys.version)  # python 3.11.13\n","print(\"PyTorch:\", torch.__version__)  # PyTorch: 2.6.0+cu124\n","print(\"CUDA disponible:\", torch.cuda.is_available())\n","if torch.cuda.is_available():\n","    print(\"GPU:\", torch.cuda.get_device_name(0))\n","else:\n","    print(\"⚠️ Activa GPU: Runtime ▶ Change runtime type ▶ GPU\")\n"]},{"cell_type":"markdown","id":"4514720b","metadata":{"id":"4514720b"},"source":["## 2) Configuración"]},{"cell_type":"code","execution_count":null,"id":"da00fda0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"da00fda0","executionInfo":{"status":"ok","timestamp":1755690402173,"user_tz":-120,"elapsed":8,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"c6d4650a-62f1-47a7-9e46-8703015dfe9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Config(data_path='/content/songdb_funcional_v4_2.csv', sequence_col='funcional_prog', val_size=0.1, test_size=0.1, random_state=42, seq_len=24, batch_size=128, epochs=6, lr=0.002, weight_decay=0.0001, dropout=0.2, embedding_dim=128, hidden_size=256, num_layers=2, grad_clip=1.0, amp=True, scheduler='cosine', pct_start=0.15, div_factor=10.0, final_div_factor=1000.0, save_dir='/content/models_rs', tokenizer_path='lstm_tokenizer_.json', min_seq_len=8.0)\n"]}],"source":["from dataclasses import dataclass\n","\n","@dataclass\n","class Config:\n","    # Ruta al CSV\n","    data_path: str = \"/content/songdb_funcional_v4.csv\"\n","    # Columna con la secuencia\n","    sequence_col: str = \"funcional_prog\"  # cambia a \"chordprog\" si prefieres\n","\n","    # Splits\n","    val_size: float = 0.10\n","    test_size: float = 0.10\n","    random_state: int = 42\n","\n","    # Entrenamiento base (puede ser sobrescrito por RS)\n","    seq_len: int = 24\n","    batch_size: int = 128\n","    epochs: int = 6\n","    lr: float = 2e-3\n","    weight_decay: float = 1e-4\n","    dropout: float = 0.2\n","    embedding_dim: int = 128\n","    hidden_size: int = 256\n","    num_layers: int = 2\n","    grad_clip: float = 1.0\n","    amp: bool = True\n","    # Scheduler\n","    scheduler: str = \"cosine\"       # {\"none\",\"onecycle\",\"cosine\"}\n","    pct_start: float = 0.15         # solo si scheduler=\"onecycle\"\n","    div_factor: float = 10.0        # solo si scheduler=\"onecycle\"\n","    final_div_factor: float = 1e3   # solo si scheduler=\"onecycle\"\n","\n","    # Guardado\n","    save_dir: str = \"/content/models_rs\"\n","    tokenizer_path: str = \"lstm_tokenizer_.json\"\n","\n","    # Filtrado\n","    min_seq_len: int = 8. #Probar distintos valores\n","\n","cfg = Config()\n","print(cfg)\n"]},{"cell_type":"markdown","id":"96aca577","metadata":{"id":"96aca577"},"source":["## 3) Cargar CSV y tokenizar"]},{"cell_type":"code","source":["#@title opción A) Subir archivo\n","try:\n","    from google.colab import files\n","    uploaded = files.upload()\n","except Exception:\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"nKFnbxemkX6P","executionInfo":{"status":"ok","timestamp":1755690414517,"user_tz":-120,"elapsed":9051,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"a2d60bbe-89f8-432c-b8ba-bbc8a040fd2d"},"id":"nKFnbxemkX6P","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-9a3d4a13-450d-4ca4-a930-3803a090520b\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-9a3d4a13-450d-4ca4-a930-3803a090520b\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving songdb_funcional_v4_2.csv to songdb_funcional_v4_2.csv\n"]}]},{"cell_type":"code","source":["#@title opción B) montar desde Google Drive\n","try:\n","    from google.colab import drive\n","    # drive.mount('/content/drive') # Descomentar para utilizar Drive\n","except Exception:\n","    pass"],"metadata":{"id":"Es4k0wzPklex"},"id":"Es4k0wzPklex","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"21ebeacb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"21ebeacb","executionInfo":{"status":"ok","timestamp":1755690417464,"user_tz":-120,"elapsed":516,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"23576021-77ab-4b1f-9c73-5263b673b14c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Filas totales: 2613\n"]},{"output_type":"display_data","data":{"text/plain":["                                      funcional_prog\n","0  vi #ivø V/III V/VI vi IV ii V7 iii vi ii V7 I ...\n","1  VII VII I vi ii V7 VII VII I vi ii V7 I IV #iv...\n","2  i VI V/V V7 i VI V/V V7 i VI iiø V7 i VI iiø V..."],"text/html":["\n","  <div id=\"df-afd0af60-6e34-46c6-bfc2-510de493a406\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>funcional_prog</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>vi #ivø V/III V/VI vi IV ii V7 iii vi ii V7 I ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>VII VII I vi ii V7 VII VII I vi ii V7 I IV #iv...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>i VI V/V V7 i VI V/V V7 i VI iiø V7 i VI iiø V...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afd0af60-6e34-46c6-bfc2-510de493a406')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-afd0af60-6e34-46c6-bfc2-510de493a406 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-afd0af60-6e34-46c6-bfc2-510de493a406');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-9d3dca20-3bd9-41f6-85fe-79d2a2795dd1\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d3dca20-3bd9-41f6-85fe-79d2a2795dd1')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-9d3dca20-3bd9-41f6-85fe-79d2a2795dd1 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"print(\\\"Filas tras filtro min_seq_len:\\\", len(df))\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"funcional_prog\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"vi #iv\\u00f8 V/III V/VI vi IV ii V7 iii vi ii V7 I IV7 vii\\u00f8 V/VI vi #iv\\u00f8 V/III V/VI vi IV ii V7 iii vi ii V7 I V7 I V/II ii ii V7 I V/II ii V7 I V/VI vi #iv\\u00f8 V/III V/VI vi IV ii V7 iii vi ii V7 I V7 I III7\",\n          \"VII VII I vi ii V7 VII VII I vi ii V7 I IV #ivo I iii vi V/V V7 VII VII I vi ii V7 VII VII I vi ii V7 I IV #ivo I ii V7 I I vi bvi v V/IV IV IV vi bvi v V/IV IV IV vii bvii vi V/V V V ii V7 ii V7 VII VII I vi ii V7 VII VII I vi ii V7 I IV #ivo I iii vi V/V V7 iii IV iii IV iii ii ii V7 I V7\",\n          \"i VI V/V V7 i VI V/V V7 i VI ii\\u00f8 V7 i VI ii\\u00f8 V7 i i Vsub/V V7 iv iv ii\\u00f8 bII7 iv bII v\\u00f8 V/IV iv bII v\\u00f8 V/IV iv bII v\\u00f8 V/IV iv Vsub/II ii\\u00f8 V7 i VI ii\\u00f8 V7 i VI ii\\u00f8 V7 i i Vsub/V V7 iv iv ii\\u00f8 bII7 bII bII\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Filas tras filtro min_seq_len: 2612\n"]}],"source":["#@title Tokenización de las progresiones funcinoales\n","import pandas as pd, ast, re, json\n","\n","df = pd.read_csv(cfg.data_path)\n","assert cfg.sequence_col in df.columns, f\"Columna {cfg.sequence_col} no encontrada en el CSV.\"\n","print(\"Filas totales:\", len(df))\n","display(df[[cfg.sequence_col]].head(3))\n","\n","def parse_tokens_simple(s: str):\n","    # Si viene como lista en string, intenta parsear\n","    if isinstance(s, str) and s.strip().startswith(\"[\") and s.strip().endswith(\"]\"):\n","        try:\n","            lst = ast.literal_eval(s)\n","            if isinstance(lst, list):\n","                return [str(t) for t in lst]\n","        except Exception:\n","            pass\n","    # Normalizar a tokens por espacios\n","    s = str(s).replace(\"|\", \" \").replace(\"\\n\", \" \")\n","    toks = [t for t in re.findall(r\"\\S+\", s) if t.strip()]\n","    return toks\n","\n","df[\"_tokens_\"] = df[cfg.sequence_col].apply(parse_tokens_simple)\n","df = df[df[\"_tokens_\"].apply(len) >= cfg.min_seq_len].reset_index(drop=True)\n","print(\"Filas tras filtro min_seq_len:\", len(df))\n"]},{"cell_type":"markdown","id":"b213aaa1","metadata":{"id":"b213aaa1"},"source":["## 4) Split train/val/test (simple, por filas)"]},{"cell_type":"code","execution_count":null,"id":"ebe2a8d9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebe2a8d9","executionInfo":{"status":"ok","timestamp":1755690421952,"user_tz":-120,"elapsed":1290,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"5d6344b8-aaa6-44da-9552-055d6a12ea89"},"outputs":[{"output_type":"stream","name":"stdout","text":["2089 261 262\n"]}],"source":["\n","from sklearn.model_selection import train_test_split\n","train_df, tmp_df = train_test_split(df, test_size=cfg.val_size+cfg.test_size, random_state=cfg.random_state, shuffle=True)\n","rel_test = cfg.test_size / (cfg.val_size + cfg.test_size) if (cfg.val_size + cfg.test_size) > 0 else 0.5\n","val_df, test_df = train_test_split(tmp_df, test_size=rel_test, random_state=cfg.random_state, shuffle=True)\n","\n","train_seqs = train_df[\"_tokens_\"].tolist()\n","val_seqs   = val_df[\"_tokens_\"].tolist()\n","test_seqs  = test_df[\"_tokens_\"].tolist()\n","print(len(train_seqs), len(val_seqs), len(test_seqs))\n"]},{"cell_type":"markdown","id":"718adf54","metadata":{"id":"718adf54"},"source":["## 5) Vocabulario y codificación"]},{"cell_type":"code","execution_count":null,"id":"9967a362","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9967a362","executionInfo":{"status":"ok","timestamp":1755690424805,"user_tz":-120,"elapsed":11,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"cfd53b2b-0d15-428a-af28-0bef523cc52f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size: 86\n"]}],"source":["from collections import Counter\n","PAD, UNK, BOS, EOS = \"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"\n","\n","def build_vocab(seqs, min_freq=1):\n","    c = Counter()\n","    for s in seqs: c.update(s)\n","    vocab = [PAD, UNK, BOS, EOS] + [t for t,f in c.items() if f >= min_freq and t not in {PAD,UNK,BOS,EOS}]\n","    stoi = {t:i for i,t in enumerate(vocab)} # token to id dict\n","    itos = {i:t for t,i in stoi.items()}     # id to token dict\n","    return vocab, stoi, itos\n","\n","vocab, stoi, itos = build_vocab(train_seqs, 1)\n","print(\"Vocab size:\", len(vocab))\n","\n","with open(cfg.tokenizer_path, \"w\") as f:\n","    json.dump({\"vocab\": list(vocab)}, f, ensure_ascii=False, indent=2)\n","\n","def encode(seq, add_bos=True):\n","    ids = [stoi[BOS]] if add_bos else []\n","    ids += [stoi.get(t, stoi[UNK]) for t in seq]\n","    return ids\n"]},{"cell_type":"markdown","id":"c9bf672b","metadata":{"id":"c9bf672b"},"source":["## 6) Dataset (context→next) + DataLoaders"]},{"cell_type":"code","execution_count":null,"id":"612fc37a","metadata":{"id":"612fc37a"},"outputs":[],"source":["\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class NextTokenDataset(Dataset):\n","    def __init__(self, sequences, seq_len):\n","        self.samples = []\n","        for seq in sequences:\n","            ids = encode(seq, add_bos=True)\n","            if len(ids) <= seq_len: continue\n","            for i in range(seq_len, len(ids)):\n","                self.samples.append((ids[i-seq_len:i], ids[i]))\n","    def __len__(self): return len(self.samples)\n","    def __getitem__(self, idx):\n","        x, y = self.samples[idx]\n","        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n","\n","def make_dataloaders(train_seqs, val_seqs, test_seqs, seq_len, batch_size):\n","    \"\"\"\n","\n","    \"\"\"\n","    train_data = NextTokenDataset(train_seqs, seq_len)\n","    val_data   = NextTokenDataset(val_seqs,   seq_len)\n","    test_data  = NextTokenDataset(test_seqs,  seq_len)\n","    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n","    val_loader   = DataLoader(val_data,   batch_size=batch_size, shuffle=False)\n","    test_loader  = DataLoader(test_data,  batch_size=batch_size, shuffle=False)\n","    return train_loader, val_loader, test_loader, len(test_data)\n"]},{"cell_type":"markdown","id":"ecc527fa","metadata":{"id":"ecc527fa"},"source":["## 7) Modelo LSTM (con `tie_weights` opcional)"]},{"cell_type":"code","execution_count":null,"id":"70a9da81","metadata":{"id":"70a9da81"},"outputs":[],"source":["\n","import torch.nn as nn\n","\n","class ChordLSTM(nn.Module):\n","    \"\"\"\n","    LSTM sencillo con opción tie_weights. Si tie_weights=True y hidden_size!=embedding_dim,\n","    se añade una proyección H->E antes de decodificar con los pesos compartidos de la embedding.\n","    \"\"\"\n","    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout, tie_weights=False):\n","        super().__init__()\n","        self.emb = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n","                           batch_first=True, dropout=dropout if num_layers>1 else 0.0)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.tie_weights = tie_weights\n","        if tie_weights:\n","            self.proj = nn.Linear(hidden_size, embedding_dim, bias=False) if hidden_size != embedding_dim else nn.Identity()\n","            self.decoder = nn.Linear(embedding_dim, vocab_size, bias=False)\n","            self.decoder.weight = self.emb.weight\n","        else:\n","            self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, x):\n","        e = self.emb(x)                 # (B, T, E)\n","        o, _ = self.rnn(e)              # (B, T, H)\n","        h_t = self.dropout(o[:, -1, :]) # (B, H)\n","        if self.tie_weights:\n","            e_t = self.proj(h_t)        # (B, E)\n","            return self.decoder(e_t)    # (B, V)\n","        else:\n","            return self.fc(h_t)         # (B, V)\n"]},{"cell_type":"markdown","id":"ac38d1fa","metadata":{"id":"ac38d1fa"},"source":["## 8) Métricas y entrenamiento (Top@k, MRR, PPL)"]},{"cell_type":"code","execution_count":null,"id":"aff6518e","metadata":{"id":"aff6518e"},"outputs":[],"source":["\n","import math, time, os, torch\n","import torch.nn.functional as F\n","from torch.amp import GradScaler, autocast\n","\n","def topk_metrics(logits, targets, ks=(1,3,5)):\n","    \"\"\"\n","    Definción de métricas Top@k y MRR.\n","    \"\"\"\n","    out = {}\n","    with torch.no_grad():\n","        for k in ks:\n","            topk = logits.topk(k, dim=-1).indices\n","            out[f\"Top@{k}\"] = (topk == targets.unsqueeze(1)).any(dim=1).float().mean().item()\n","        ranks = (logits.argsort(dim=-1, descending=True) == targets.unsqueeze(1)).nonzero(as_tuple=False)[:,1] + 1\n","        out[\"MRR\"] = (1.0 / ranks.float()).mean().item()\n","    return out\n","\n","def evaluate(model, loader, criterion, device):\n","    \"\"\"\n","    Función de evaluación\n","    \"\"\"\n","    model.eval()\n","    total, n = 0.0, 0\n","    agg = {\"Top@1\":0.0,\"Top@3\":0.0,\"Top@5\":0.0,\"MRR\":0.0}\n","    with torch.no_grad():\n","        for x,y in loader:\n","            x,y = x.to(device), y.to(device)\n","            logits = model(x)\n","            loss = criterion(logits, y)\n","            b = x.size(0); total += loss.item()*b; n += b\n","            m = topk_metrics(logits, y)\n","            for k in agg: agg[k] += m[k]*b\n","    for k in agg: agg[k] /= max(1,n)\n","    return {\"loss\": total/max(1,n), \"ppl\": math.exp(total/max(1,n)), **agg}\n","\n","def train_once(model, train_loader, val_loader, epochs, lr, weight_decay,\n","               grad_clip=1.0, amp=True, save_path=None, label_smoothing=0.0,\n","               patience=2, device=torch.device(\"cpu\"),\n","               scheduler_type=\"cosine\", pct_start=0.15, div_factor=10.0,   #nuevo\n","               final_div_factor=1e3):                                   #nuevo\n","    \"\"\"\n","    train_once: bucle de entrenamiento con early stopping por MRR.\n","\n","    Parámetros clave:\n","    - scheduler_type: \"cosine\" (por defecto), \"onecycle\" o \"none\".\n","    - label_smoothing: e.g., 0.05 en train/val. (En test solemos usar 0.0 para comparabilidad.)\n","    - pct_start / div_factor / final_div_factor: SOLO aplican si scheduler_type == \"onecycle\".\n","      Con \"cosine\" y \"none\" se ignoran.\n","\n","    Notas:\n","    - Se hace scheduler.step() por batch (T_max = epochs * steps_per_epoch para cosine).\n","    - Guardamos el mejor estado según MRR de validación y lo restauramos al final.\n","\"\"\"\n","\n","    scaler = GradScaler('cuda' if device.type=='cuda' else 'cpu',\n","                        enabled=(amp and device.type=='cuda'))\n","    crit = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n","    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","    # Scheduler\n","    steps_per_epoch = len(train_loader)\n","    if scheduler_type == \"onecycle\":\n","        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","            opt, max_lr=lr, steps_per_epoch=steps_per_epoch, epochs=epochs,\n","            pct_start=pct_start,\n","            anneal_strategy='cos',\n","            div_factor=div_factor,\n","            final_div_factor=final_div_factor\n","        )\n","    elif scheduler_type == \"cosine\":\n","        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n","            opt, T_max=epochs * steps_per_epoch\n","        )\n","    else:\n","        scheduler = None\n","\n","    best_mrr, best_state = -1.0, None\n","    no_improve = 0\n","\n","    for ep in range(1, epochs+1):\n","        model.train()\n","        for x,y in train_loader:\n","            x,y = x.to(device), y.to(device)\n","            opt.zero_grad(set_to_none=True)\n","            with autocast('cuda', enabled=(amp and device.type=='cuda')):\n","                logits = model(x); loss = crit(logits,y)\n","            scaler.scale(loss).backward()\n","            if grad_clip is not None:\n","                scaler.unscale_(opt)\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n","            scaler.step(opt); scaler.update()\n","            if scheduler is not None:\n","                scheduler.step()\n","\n","        valm = evaluate(model, val_loader, crit, device)\n","        print(f\"Epoch {ep} | val loss {valm['loss']:.4f} ppl {valm['ppl']:.2f} Top@1 {valm['Top@1']:.3f} Top@3 {valm['Top@3']:.3f} Top@5 {valm['Top@5']:.3f} MRR {valm['MRR']:.3f}\")\n","        if valm[\"MRR\"] > best_mrr:\n","            best_mrr, no_improve = valm[\"MRR\"], 0\n","            best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n","            if save_path:\n","                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","                torch.save({\"model_state\": model.state_dict()}, save_path)\n","        else:\n","            no_improve += 1\n","            if no_improve >= patience:\n","                print(f\"⏹️ Early stopping (patience={patience})\")\n","                break\n","\n","    if best_state is not None:\n","        model.load_state_dict(best_state)\n","    return best_mrr\n"]},{"cell_type":"markdown","source":["## 9) A/B Tests: comparativa de parámetros"],"metadata":{"id":"tL8l7uvDXWpw"},"id":"tL8l7uvDXWpw"},{"cell_type":"code","source":["#@title A/B helper\n","import copy, torch.nn as nn, random, numpy as np, torch\n","from dataclasses import replace\n","\n","def _reseed(seed: int):\n","    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n","    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","\n","def run_single(cfg_local, *, tie_weights=False, label_smoothing=0.05,\n","               test_label_smoothing=0.0):\n","    \"\"\"\n","    Ejecuta 1 entrenamiento + test con la config dada (sin RS).\n","    - tie_weights: para probar rápido con/ sin weight tying\n","    - label_smoothing: en training/validación\n","    - test_label_smoothing: en test (0.0 para comparabilidad entre runs)\n","    \"\"\"\n","    # reseed para que las A/B sean comparables\n","    _reseed(cfg_local.random_state)\n","\n","    # dataloaders\n","    train_loader_t, val_loader_t, test_loader_t, _ = make_dataloaders(\n","        train_seqs, val_seqs, test_seqs,\n","        seq_len=cfg_local.seq_len, batch_size=cfg_local.batch_size\n","    )\n","\n","    # modelo\n","    model = ChordLSTM(\n","        vocab_size=len(vocab),\n","        embedding_dim=cfg_local.embedding_dim,\n","        hidden_size=cfg_local.hidden_size,\n","        num_layers=cfg_local.num_layers,\n","        dropout=cfg_local.dropout,\n","        tie_weights=tie_weights\n","    ).to(device)\n","\n","    # train (usa el scheduler definido en cfg_local)\n","    _ = train_once(\n","        model, train_loader_t, val_loader_t,\n","        epochs=cfg_local.epochs, lr=cfg_local.lr, weight_decay=cfg_local.weight_decay,\n","        grad_clip=cfg_local.grad_clip, amp=cfg_local.amp, save_path=None,\n","        label_smoothing=label_smoothing, patience=2, device=device,\n","        scheduler_type=cfg_local.scheduler, pct_start=cfg_local.pct_start,\n","        div_factor=cfg_local.div_factor, final_div_factor=cfg_local.final_div_factor\n","    )\n","\n","    # test (elige coherencia con training o comparabilidad entre runs)\n","    test_crit = nn.CrossEntropyLoss(label_smoothing=test_label_smoothing)\n","    return evaluate(model, test_loader_t, test_crit, device)\n"],"metadata":{"id":"K_k3Z2Lg9GbS"},"id":"K_k3Z2Lg9GbS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Mini A/B test function: compara Top@1 y MRR y muestra difs ===\n","from dataclasses import replace\n","\n","def compare_ab(cfg_A, cfg_B, *,\n","               tie_A=False, tie_B=False,\n","               ls_train=0.05, ls_test=0.0,\n","               label_A=\"A\", label_B=\"B\"):\n","    \"\"\"\n","    Ejecuta A y B con mismos seeds/hparams (salvo los cambios que pongas en cfg_A/cfg_B)\n","    y muestra Top@1 / MRR + diferencias.\n","    - ls_train: label smoothing usado en training/validación\n","    - ls_test:  label smoothing del criterio en test (0.0 para comparabilidad)\n","    - tie_A/B:  activa/desactiva tie_weights en cada iteración\n","    \"\"\"\n","    print(f\"\\n>>> Run {label_A}\")\n","    resA = run_single(cfg_A, tie_weights=tie_A, label_smoothing=ls_train, test_label_smoothing=ls_test)\n","    print(f\"{label_A}: Top@1={resA['Top@1']:.4f}  MRR={resA['MRR']:.4f}\")\n","\n","    print(f\"\\n>>> Run {label_B}\")\n","    resB = run_single(cfg_B, tie_weights=tie_B, label_smoothing=ls_train, test_label_smoothing=ls_test)\n","    print(f\"{label_B}: Top@1={resB['Top@1']:.4f}  MRR={resB['MRR']:.4f}\")\n","\n","    d_top1 = resB['Top@1'] - resA['Top@1']\n","    d_mrr  = resB['MRR']  - resA['MRR']\n","    print(\"\\nΔ (B − A):  Top@1={:+.4f}  MRR={:+.4f}\".format(d_top1, d_mrr))\n","\n","    return resA, resB\n"],"metadata":{"id":"sVBLyHuV-HrA"},"id":"sVBLyHuV-HrA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title 9.1) A/B test: scheduler 'none' vs 'onecycle' (mismos hparams)\n","cfgA = replace(cfg, scheduler=\"none\")\n","cfgB = replace(cfg, scheduler=\"onecycle\")\n","compare_ab(cfgA, cfgB, tie_A=False, tie_B=False, ls_train=0.05, ls_test=0.0,\n","           label_A=\"none\", label_B=\"onecycle\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_veX7c_9cZL","executionInfo":{"status":"ok","timestamp":1755601797138,"user_tz":-120,"elapsed":50781,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"74581d6b-d5f2-4991-a5cf-d14f5c26658f"},"id":"3_veX7c_9cZL","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n",">>> Run none\n","Epoch 1 | val loss 2.4178 ppl 11.22 Top@1 0.433 Top@3 0.670 Top@5 0.759 MRR 0.577\n","Epoch 2 | val loss 2.3498 ppl 10.48 Top@1 0.445 Top@3 0.685 Top@5 0.772 MRR 0.591\n","Epoch 3 | val loss 2.3194 ppl 10.17 Top@1 0.457 Top@3 0.691 Top@5 0.775 MRR 0.599\n","Epoch 4 | val loss 2.3177 ppl 10.15 Top@1 0.460 Top@3 0.691 Top@5 0.776 MRR 0.600\n","Epoch 5 | val loss 2.3246 ppl 10.22 Top@1 0.465 Top@3 0.694 Top@5 0.775 MRR 0.604\n","Epoch 6 | val loss 2.3393 ppl 10.37 Top@1 0.460 Top@3 0.690 Top@5 0.767 MRR 0.599\n","none: Top@1=0.4390  MRR=0.5845\n","\n",">>> Run onecycle\n","Epoch 1 | val loss 2.5604 ppl 12.94 Top@1 0.412 Top@3 0.629 Top@5 0.722 MRR 0.550\n","Epoch 2 | val loss 2.3916 ppl 10.93 Top@1 0.437 Top@3 0.675 Top@5 0.766 MRR 0.581\n","Epoch 3 | val loss 2.3299 ppl 10.28 Top@1 0.451 Top@3 0.687 Top@5 0.768 MRR 0.594\n","Epoch 4 | val loss 2.3017 ppl 9.99 Top@1 0.465 Top@3 0.695 Top@5 0.778 MRR 0.605\n","Epoch 5 | val loss 2.2936 ppl 9.91 Top@1 0.466 Top@3 0.697 Top@5 0.779 MRR 0.606\n","Epoch 6 | val loss 2.2991 ppl 9.97 Top@1 0.465 Top@3 0.698 Top@5 0.779 MRR 0.605\n","onecycle: Top@1=0.4443  MRR=0.5888\n","\n","Δ (B − A):  Top@1=+0.0052  MRR=+0.0044\n"]},{"output_type":"execute_result","data":{"text/plain":["({'loss': 2.1717863362683265,\n","  'ppl': 8.77394326332569,\n","  'Top@1': 0.4390402926212962,\n","  'Top@3': 0.6824879387644003,\n","  'Top@5': 0.7615073675639255,\n","  'MRR': 0.5844942458233353},\n"," {'loss': 2.132555847358231,\n","  'ppl': 8.436401434432007,\n","  'Top@1': 0.44425609648375364,\n","  'Top@3': 0.6866605818574751,\n","  'Top@5': 0.7658104057619167,\n","  'MRR': 0.588845919623868})"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["#@title 9.2) A/B test: scheduler 'cosine' vs 'onecycle'\n","cfgA = replace(cfg, scheduler=\"cosine\")\n","cfgB = replace(cfg, scheduler=\"onecycle\")\n","compare_ab(cfgA, cfgB, tie_A=False, tie_B=False, ls_train=0.05, ls_test=0.0,\n","           label_A=\"cosine\", label_B=\"onecycle\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJUCH657-ZwA","executionInfo":{"status":"ok","timestamp":1755602628156,"user_tz":-120,"elapsed":50475,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"ff832094-b0a3-46ee-db6f-84c109d9a2f5"},"id":"xJUCH657-ZwA","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n",">>> Run cosine\n","Epoch 1 | val loss 2.4219 ppl 11.27 Top@1 0.430 Top@3 0.672 Top@5 0.756 MRR 0.576\n","Epoch 2 | val loss 2.3421 ppl 10.40 Top@1 0.446 Top@3 0.684 Top@5 0.775 MRR 0.592\n","Epoch 3 | val loss 2.3156 ppl 10.13 Top@1 0.454 Top@3 0.693 Top@5 0.774 MRR 0.598\n","Epoch 4 | val loss 2.3064 ppl 10.04 Top@1 0.461 Top@3 0.696 Top@5 0.778 MRR 0.602\n","Epoch 5 | val loss 2.3017 ppl 9.99 Top@1 0.466 Top@3 0.694 Top@5 0.779 MRR 0.605\n","Epoch 6 | val loss 2.3053 ppl 10.03 Top@1 0.466 Top@3 0.695 Top@5 0.777 MRR 0.605\n","cosine: Top@1=0.4463  MRR=0.5903\n","\n",">>> Run onecycle\n","Epoch 1 | val loss 2.4679 ppl 11.80 Top@1 0.421 Top@3 0.655 Top@5 0.749 MRR 0.566\n","Epoch 2 | val loss 2.3614 ppl 10.61 Top@1 0.444 Top@3 0.680 Top@5 0.769 MRR 0.588\n","Epoch 3 | val loss 2.3139 ppl 10.11 Top@1 0.457 Top@3 0.691 Top@5 0.775 MRR 0.599\n","Epoch 4 | val loss 2.3001 ppl 9.97 Top@1 0.461 Top@3 0.695 Top@5 0.782 MRR 0.602\n","Epoch 5 | val loss 2.2974 ppl 9.95 Top@1 0.464 Top@3 0.697 Top@5 0.780 MRR 0.605\n","Epoch 6 | val loss 2.3019 ppl 9.99 Top@1 0.465 Top@3 0.696 Top@5 0.780 MRR 0.605\n","onecycle: Top@1=0.4452  MRR=0.5893\n","\n","Δ (B − A):  Top@1=-0.0012  MRR=-0.0009\n"]},{"output_type":"execute_result","data":{"text/plain":["({'loss': 2.139258915076341,\n","  'ppl': 8.493141157198066,\n","  'Top@1': 0.4463424180380632,\n","  'Top@3': 0.687051767141136,\n","  'Top@5': 0.7686790978913202,\n","  'MRR': 0.5902759316054919},\n"," {'loss': 2.1423883281423737,\n","  'ppl': 8.519761335148631,\n","  'Top@1': 0.4451688621870805,\n","  'Top@3': 0.6858782112823811,\n","  'Top@5': 0.7655496155831724,\n","  'MRR': 0.5893271848343702})"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["#@title 9.3) A/B test: tie_weights False vs True (con mismo scheduler)\n","cfg_fix = replace(cfg, scheduler=\"onecycle\")  # o \"none\"\n","compare_ab(cfg_fix, cfg_fix, tie_A=False, tie_B=True, ls_train=0.05, ls_test=0.0,\n","           label_A=\"tie=False\", label_B=\"tie=True\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJ07EnUH9hPw","executionInfo":{"status":"ok","timestamp":1755602553542,"user_tz":-120,"elapsed":50640,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"708588fa-3235-4690-cad8-661c16a47058"},"id":"MJ07EnUH9hPw","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n",">>> Run tie=False\n","Epoch 1 | val loss 2.4679 ppl 11.80 Top@1 0.421 Top@3 0.655 Top@5 0.749 MRR 0.566\n","Epoch 2 | val loss 2.3614 ppl 10.61 Top@1 0.444 Top@3 0.680 Top@5 0.769 MRR 0.588\n","Epoch 3 | val loss 2.3139 ppl 10.11 Top@1 0.457 Top@3 0.691 Top@5 0.775 MRR 0.599\n","Epoch 4 | val loss 2.3001 ppl 9.97 Top@1 0.461 Top@3 0.695 Top@5 0.782 MRR 0.602\n","Epoch 5 | val loss 2.2974 ppl 9.95 Top@1 0.464 Top@3 0.697 Top@5 0.780 MRR 0.605\n","Epoch 6 | val loss 2.3019 ppl 9.99 Top@1 0.465 Top@3 0.696 Top@5 0.780 MRR 0.605\n","tie=False: Top@1=0.4452  MRR=0.5893\n","\n",">>> Run tie=True\n","Epoch 1 | val loss 2.5061 ppl 12.26 Top@1 0.401 Top@3 0.666 Top@5 0.751 MRR 0.556\n","Epoch 2 | val loss 2.3819 ppl 10.83 Top@1 0.436 Top@3 0.680 Top@5 0.771 MRR 0.583\n","Epoch 3 | val loss 2.3329 ppl 10.31 Top@1 0.453 Top@3 0.692 Top@5 0.774 MRR 0.596\n","Epoch 4 | val loss 2.3205 ppl 10.18 Top@1 0.458 Top@3 0.697 Top@5 0.779 MRR 0.601\n","Epoch 5 | val loss 2.3150 ppl 10.12 Top@1 0.458 Top@3 0.699 Top@5 0.780 MRR 0.602\n","Epoch 6 | val loss 2.3292 ppl 10.27 Top@1 0.461 Top@3 0.699 Top@5 0.780 MRR 0.602\n","tie=True: Top@1=0.4486  MRR=0.5918\n","\n","Δ (B − A):  Top@1=+0.0034  MRR=+0.0025\n"]},{"output_type":"execute_result","data":{"text/plain":["({'loss': 2.1423883281423737,\n","  'ppl': 8.519761335148631,\n","  'Top@1': 0.4451688621870805,\n","  'Top@3': 0.6858782112823811,\n","  'Top@5': 0.7655496155831724,\n","  'MRR': 0.5893271848343702},\n"," {'loss': 2.151621562030328,\n","  'ppl': 8.598790570479268,\n","  'Top@1': 0.44855913470506137,\n","  'Top@3': 0.6884861132019516,\n","  'Top@5': 0.7707654194378576,\n","  'MRR': 0.5918436967606867})"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["Se probaron distintos parámetros de entrenamiento:\n","- scheduler: 'cosine', 'OneCycle', 'none'\n","- weight_tying: True, False.\n","\n","Todas ellas aportaron ligeras mejoras en métricas Top@1/MRR.\n","\n","Finalmente, se seleccionó la configuración con scheduler: 'cosine' y tie_weights= True, aunque las diferencias respecto a OneCycle sin tying no fueron estadísticamente significativas."],"metadata":{"id":"rMR-AeySFWDu"},"id":"rMR-AeySFWDu"},{"cell_type":"markdown","metadata":{"id":"-W2NbGAHGUqN"},"source":["## 10) Random Search (espacio de búsqueda, resultados, checkpoints)"],"id":"-W2NbGAHGUqN"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1755604505038,"user_tz":-120,"elapsed":748657,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"e6e00827-3c31-4502-e8b2-646cad59573b","id":"3rUKOPX6GUqN"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== TRIAL 1/20 ===\n","{'embedding_dim': 192, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0008787429588337066, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n","Epoch 1 | val loss 2.4071 ppl 11.10 Top@1 0.419 Top@3 0.657 Top@5 0.753 MRR 0.567\n","Epoch 2 | val loss 2.3254 ppl 10.23 Top@1 0.429 Top@3 0.674 Top@5 0.769 MRR 0.578\n","Epoch 3 | val loss 2.3036 ppl 10.01 Top@1 0.438 Top@3 0.681 Top@5 0.769 MRR 0.585\n","Epoch 4 | val loss 2.2411 ppl 9.40 Top@1 0.454 Top@3 0.686 Top@5 0.777 MRR 0.597\n","Epoch 5 | val loss 2.2277 ppl 9.28 Top@1 0.458 Top@3 0.690 Top@5 0.778 MRR 0.600\n","Epoch 6 | val loss 2.2243 ppl 9.25 Top@1 0.459 Top@3 0.692 Top@5 0.780 MRR 0.601\n","\n","=== TRIAL 2/20 ===\n","{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 128, 'lr': 0.0016007565680120513, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4485 ppl 11.57 Top@1 0.424 Top@3 0.668 Top@5 0.755 MRR 0.572\n","Epoch 2 | val loss 2.3813 ppl 10.82 Top@1 0.444 Top@3 0.687 Top@5 0.770 MRR 0.589\n","Epoch 3 | val loss 2.3625 ppl 10.62 Top@1 0.447 Top@3 0.689 Top@5 0.772 MRR 0.592\n","Epoch 4 | val loss 2.3241 ppl 10.22 Top@1 0.461 Top@3 0.689 Top@5 0.776 MRR 0.601\n","Epoch 5 | val loss 2.3172 ppl 10.15 Top@1 0.461 Top@3 0.694 Top@5 0.777 MRR 0.601\n","Epoch 6 | val loss 2.3163 ppl 10.14 Top@1 0.462 Top@3 0.694 Top@5 0.777 MRR 0.602\n","\n","=== TRIAL 3/20 ===\n","{'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0024952231976338324, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.5482 ppl 12.78 Top@1 0.413 Top@3 0.649 Top@5 0.743 MRR 0.561\n","Epoch 2 | val loss 2.4323 ppl 11.39 Top@1 0.436 Top@3 0.668 Top@5 0.760 MRR 0.579\n","Epoch 3 | val loss 2.3834 ppl 10.84 Top@1 0.439 Top@3 0.686 Top@5 0.770 MRR 0.586\n","Epoch 4 | val loss 2.3521 ppl 10.51 Top@1 0.451 Top@3 0.691 Top@5 0.772 MRR 0.595\n","Epoch 5 | val loss 2.3500 ppl 10.49 Top@1 0.450 Top@3 0.688 Top@5 0.774 MRR 0.593\n","Epoch 6 | val loss 2.3525 ppl 10.51 Top@1 0.449 Top@3 0.690 Top@5 0.776 MRR 0.593\n","⏹️ Early stopping (patience=2)\n","\n","=== TRIAL 4/20 ===\n","{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0011427451449300696, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.03}\n","Epoch 1 | val loss 2.3688 ppl 10.68 Top@1 0.424 Top@3 0.666 Top@5 0.757 MRR 0.570\n","Epoch 2 | val loss 2.2801 ppl 9.78 Top@1 0.448 Top@3 0.684 Top@5 0.768 MRR 0.591\n","Epoch 3 | val loss 2.2396 ppl 9.39 Top@1 0.452 Top@3 0.694 Top@5 0.773 MRR 0.597\n","Epoch 4 | val loss 2.2319 ppl 9.32 Top@1 0.460 Top@3 0.695 Top@5 0.777 MRR 0.602\n","Epoch 5 | val loss 2.2387 ppl 9.38 Top@1 0.464 Top@3 0.695 Top@5 0.778 MRR 0.604\n","Epoch 6 | val loss 2.2470 ppl 9.46 Top@1 0.464 Top@3 0.693 Top@5 0.776 MRR 0.603\n","\n","=== TRIAL 5/20 ===\n","{'embedding_dim': 160, 'hidden_size': 256, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0018893923369180784, 'weight_decay': 0.0005, 'grad_clip': 0.5, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4404 ppl 11.48 Top@1 0.426 Top@3 0.677 Top@5 0.758 MRR 0.575\n","Epoch 2 | val loss 2.3626 ppl 10.62 Top@1 0.446 Top@3 0.681 Top@5 0.767 MRR 0.588\n","Epoch 3 | val loss 2.3396 ppl 10.38 Top@1 0.454 Top@3 0.691 Top@5 0.772 MRR 0.596\n","Epoch 4 | val loss 2.3012 ppl 9.99 Top@1 0.469 Top@3 0.695 Top@5 0.783 MRR 0.607\n","Epoch 5 | val loss 2.3050 ppl 10.02 Top@1 0.463 Top@3 0.697 Top@5 0.779 MRR 0.604\n","Epoch 6 | val loss 2.3081 ppl 10.06 Top@1 0.466 Top@3 0.695 Top@5 0.778 MRR 0.606\n","⏹️ Early stopping (patience=2)\n","\n","=== TRIAL 6/20 ===\n","{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0009482953204352053, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4769 ppl 11.90 Top@1 0.427 Top@3 0.666 Top@5 0.756 MRR 0.572\n","Epoch 2 | val loss 2.3874 ppl 10.89 Top@1 0.436 Top@3 0.677 Top@5 0.769 MRR 0.582\n","Epoch 3 | val loss 2.3343 ppl 10.32 Top@1 0.445 Top@3 0.691 Top@5 0.771 MRR 0.592\n","Epoch 4 | val loss 2.3090 ppl 10.06 Top@1 0.457 Top@3 0.693 Top@5 0.777 MRR 0.600\n","Epoch 5 | val loss 2.2972 ppl 9.95 Top@1 0.457 Top@3 0.695 Top@5 0.779 MRR 0.601\n","Epoch 6 | val loss 2.2961 ppl 9.94 Top@1 0.460 Top@3 0.695 Top@5 0.778 MRR 0.602\n","\n","=== TRIAL 7/20 ===\n","{'embedding_dim': 128, 'hidden_size': 384, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0020328297598925242, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4364 ppl 11.43 Top@1 0.433 Top@3 0.669 Top@5 0.751 MRR 0.577\n","Epoch 2 | val loss 2.3699 ppl 10.70 Top@1 0.444 Top@3 0.677 Top@5 0.764 MRR 0.588\n","Epoch 3 | val loss 2.3158 ppl 10.13 Top@1 0.466 Top@3 0.699 Top@5 0.779 MRR 0.606\n","Epoch 4 | val loss 2.3219 ppl 10.20 Top@1 0.463 Top@3 0.695 Top@5 0.780 MRR 0.604\n","Epoch 5 | val loss 2.3435 ppl 10.42 Top@1 0.462 Top@3 0.692 Top@5 0.778 MRR 0.602\n","⏹️ Early stopping (patience=2)\n","\n","=== TRIAL 8/20 ===\n","{'embedding_dim': 160, 'hidden_size': 384, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 24, 'batch_size': 64, 'lr': 0.003481945141955723, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.5486 ppl 12.79 Top@1 0.408 Top@3 0.650 Top@5 0.743 MRR 0.557\n","Epoch 2 | val loss 2.4365 ppl 11.43 Top@1 0.439 Top@3 0.672 Top@5 0.763 MRR 0.581\n","Epoch 3 | val loss 2.3609 ppl 10.60 Top@1 0.447 Top@3 0.687 Top@5 0.769 MRR 0.592\n","Epoch 4 | val loss 2.3243 ppl 10.22 Top@1 0.451 Top@3 0.693 Top@5 0.780 MRR 0.597\n","Epoch 5 | val loss 2.3139 ppl 10.11 Top@1 0.459 Top@3 0.694 Top@5 0.779 MRR 0.601\n","Epoch 6 | val loss 2.3136 ppl 10.11 Top@1 0.459 Top@3 0.696 Top@5 0.778 MRR 0.602\n","\n","=== TRIAL 9/20 ===\n","{'embedding_dim': 160, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 128, 'lr': 0.0008158241335586644, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4550 ppl 11.65 Top@1 0.423 Top@3 0.663 Top@5 0.760 MRR 0.570\n","Epoch 2 | val loss 2.3854 ppl 10.86 Top@1 0.433 Top@3 0.684 Top@5 0.768 MRR 0.582\n","Epoch 3 | val loss 2.3445 ppl 10.43 Top@1 0.451 Top@3 0.684 Top@5 0.773 MRR 0.593\n","Epoch 4 | val loss 2.3309 ppl 10.29 Top@1 0.455 Top@3 0.691 Top@5 0.775 MRR 0.597\n","Epoch 5 | val loss 2.3129 ppl 10.10 Top@1 0.461 Top@3 0.692 Top@5 0.776 MRR 0.602\n","Epoch 6 | val loss 2.3125 ppl 10.10 Top@1 0.463 Top@3 0.694 Top@5 0.779 MRR 0.603\n","\n","=== TRIAL 10/20 ===\n","{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.003951781173884884, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4635 ppl 11.75 Top@1 0.421 Top@3 0.659 Top@5 0.757 MRR 0.568\n","Epoch 2 | val loss 2.3844 ppl 10.85 Top@1 0.436 Top@3 0.681 Top@5 0.766 MRR 0.583\n","Epoch 3 | val loss 2.3419 ppl 10.40 Top@1 0.452 Top@3 0.685 Top@5 0.775 MRR 0.595\n","Epoch 4 | val loss 2.3147 ppl 10.12 Top@1 0.453 Top@3 0.692 Top@5 0.775 MRR 0.598\n","Epoch 5 | val loss 2.3016 ppl 9.99 Top@1 0.462 Top@3 0.695 Top@5 0.776 MRR 0.603\n","Epoch 6 | val loss 2.3032 ppl 10.01 Top@1 0.463 Top@3 0.697 Top@5 0.779 MRR 0.604\n","\n","=== TRIAL 11/20 ===\n","{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0021203914581812977, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4551 ppl 11.65 Top@1 0.419 Top@3 0.663 Top@5 0.762 MRR 0.569\n","Epoch 2 | val loss 2.4093 ppl 11.13 Top@1 0.434 Top@3 0.676 Top@5 0.769 MRR 0.581\n","Epoch 3 | val loss 2.3588 ppl 10.58 Top@1 0.441 Top@3 0.688 Top@5 0.776 MRR 0.588\n","Epoch 4 | val loss 2.3334 ppl 10.31 Top@1 0.450 Top@3 0.696 Top@5 0.778 MRR 0.596\n","Epoch 5 | val loss 2.3302 ppl 10.28 Top@1 0.459 Top@3 0.691 Top@5 0.779 MRR 0.600\n","Epoch 6 | val loss 2.3311 ppl 10.29 Top@1 0.459 Top@3 0.692 Top@5 0.781 MRR 0.601\n","\n","=== TRIAL 12/20 ===\n","{'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 128, 'lr': 0.002394712684403, 'weight_decay': 0.0, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4092 ppl 11.13 Top@1 0.437 Top@3 0.676 Top@5 0.762 MRR 0.583\n","Epoch 2 | val loss 2.3705 ppl 10.70 Top@1 0.449 Top@3 0.681 Top@5 0.770 MRR 0.591\n","Epoch 3 | val loss 2.3445 ppl 10.43 Top@1 0.457 Top@3 0.697 Top@5 0.777 MRR 0.599\n","Epoch 4 | val loss 2.3320 ppl 10.30 Top@1 0.467 Top@3 0.695 Top@5 0.776 MRR 0.605\n","Epoch 5 | val loss 2.3399 ppl 10.38 Top@1 0.465 Top@3 0.694 Top@5 0.775 MRR 0.604\n","Epoch 6 | val loss 2.3527 ppl 10.51 Top@1 0.465 Top@3 0.695 Top@5 0.776 MRR 0.604\n","⏹️ Early stopping (patience=2)\n","\n","=== TRIAL 13/20 ===\n","{'embedding_dim': 160, 'hidden_size': 256, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 64, 'lr': 0.004495582084837762, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4723 ppl 11.85 Top@1 0.424 Top@3 0.659 Top@5 0.751 MRR 0.568\n","Epoch 2 | val loss 2.3786 ppl 10.79 Top@1 0.448 Top@3 0.683 Top@5 0.768 MRR 0.590\n","Epoch 3 | val loss 2.3478 ppl 10.46 Top@1 0.447 Top@3 0.690 Top@5 0.779 MRR 0.593\n","Epoch 4 | val loss 2.3133 ppl 10.11 Top@1 0.461 Top@3 0.693 Top@5 0.781 MRR 0.602\n","Epoch 5 | val loss 2.3147 ppl 10.12 Top@1 0.463 Top@3 0.695 Top@5 0.779 MRR 0.604\n","Epoch 6 | val loss 2.3189 ppl 10.16 Top@1 0.464 Top@3 0.693 Top@5 0.780 MRR 0.604\n","\n","=== TRIAL 14/20 ===\n","{'embedding_dim': 192, 'hidden_size': 384, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 128, 'lr': 0.0011827252180412623, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n","Epoch 1 | val loss 2.3781 ppl 10.78 Top@1 0.419 Top@3 0.668 Top@5 0.761 MRR 0.569\n","Epoch 2 | val loss 2.3294 ppl 10.27 Top@1 0.432 Top@3 0.685 Top@5 0.767 MRR 0.581\n","Epoch 3 | val loss 2.2569 ppl 9.55 Top@1 0.451 Top@3 0.690 Top@5 0.779 MRR 0.595\n","Epoch 4 | val loss 2.2446 ppl 9.44 Top@1 0.449 Top@3 0.695 Top@5 0.776 MRR 0.596\n","Epoch 5 | val loss 2.2331 ppl 9.33 Top@1 0.458 Top@3 0.698 Top@5 0.781 MRR 0.602\n","Epoch 6 | val loss 2.2306 ppl 9.31 Top@1 0.459 Top@3 0.696 Top@5 0.783 MRR 0.602\n","\n","=== TRIAL 15/20 ===\n","{'embedding_dim': 128, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0005713407109004834, 'weight_decay': 0.0005, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n","Epoch 1 | val loss 2.3458 ppl 10.44 Top@1 0.437 Top@3 0.669 Top@5 0.757 MRR 0.579\n","Epoch 2 | val loss 2.2727 ppl 9.71 Top@1 0.450 Top@3 0.686 Top@5 0.771 MRR 0.593\n","Epoch 3 | val loss 2.2415 ppl 9.41 Top@1 0.453 Top@3 0.693 Top@5 0.775 MRR 0.596\n","Epoch 4 | val loss 2.2318 ppl 9.32 Top@1 0.457 Top@3 0.696 Top@5 0.779 MRR 0.600\n","Epoch 5 | val loss 2.2265 ppl 9.27 Top@1 0.457 Top@3 0.694 Top@5 0.776 MRR 0.600\n","Epoch 6 | val loss 2.2281 ppl 9.28 Top@1 0.460 Top@3 0.694 Top@5 0.779 MRR 0.602\n","\n","=== TRIAL 16/20 ===\n","{'embedding_dim': 192, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 128, 'lr': 0.004424036323090671, 'weight_decay': 0.0, 'grad_clip': 1.0, 'label_smoothing': 0.03}\n","Epoch 1 | val loss 2.4628 ppl 11.74 Top@1 0.420 Top@3 0.654 Top@5 0.742 MRR 0.564\n","Epoch 2 | val loss 2.3570 ppl 10.56 Top@1 0.431 Top@3 0.671 Top@5 0.761 MRR 0.576\n","Epoch 3 | val loss 2.3133 ppl 10.11 Top@1 0.442 Top@3 0.684 Top@5 0.764 MRR 0.587\n","Epoch 4 | val loss 2.2649 ppl 9.63 Top@1 0.452 Top@3 0.689 Top@5 0.772 MRR 0.594\n","Epoch 5 | val loss 2.2529 ppl 9.51 Top@1 0.459 Top@3 0.691 Top@5 0.773 MRR 0.599\n","Epoch 6 | val loss 2.2532 ppl 9.52 Top@1 0.463 Top@3 0.692 Top@5 0.774 MRR 0.602\n","\n","=== TRIAL 17/20 ===\n","{'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0013711030226214714, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.03}\n","Epoch 1 | val loss 2.3917 ppl 10.93 Top@1 0.423 Top@3 0.660 Top@5 0.747 MRR 0.569\n","Epoch 2 | val loss 2.2821 ppl 9.80 Top@1 0.450 Top@3 0.688 Top@5 0.772 MRR 0.593\n","Epoch 3 | val loss 2.2456 ppl 9.45 Top@1 0.451 Top@3 0.692 Top@5 0.774 MRR 0.596\n","Epoch 4 | val loss 2.2135 ppl 9.15 Top@1 0.467 Top@3 0.698 Top@5 0.783 MRR 0.607\n","Epoch 5 | val loss 2.2155 ppl 9.17 Top@1 0.469 Top@3 0.698 Top@5 0.783 MRR 0.608\n","Epoch 6 | val loss 2.2211 ppl 9.22 Top@1 0.467 Top@3 0.699 Top@5 0.782 MRR 0.607\n","\n","=== TRIAL 18/20 ===\n","{'embedding_dim': 128, 'hidden_size': 320, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0019382514554016706, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n","Epoch 1 | val loss 2.3827 ppl 10.83 Top@1 0.423 Top@3 0.656 Top@5 0.759 MRR 0.569\n","Epoch 2 | val loss 2.3179 ppl 10.15 Top@1 0.444 Top@3 0.682 Top@5 0.766 MRR 0.586\n","Epoch 3 | val loss 2.2606 ppl 9.59 Top@1 0.448 Top@3 0.692 Top@5 0.772 MRR 0.594\n","Epoch 4 | val loss 2.2433 ppl 9.42 Top@1 0.459 Top@3 0.694 Top@5 0.775 MRR 0.600\n","Epoch 5 | val loss 2.2454 ppl 9.44 Top@1 0.465 Top@3 0.696 Top@5 0.775 MRR 0.604\n","Epoch 6 | val loss 2.2503 ppl 9.49 Top@1 0.464 Top@3 0.695 Top@5 0.776 MRR 0.604\n","\n","=== TRIAL 19/20 ===\n","{'embedding_dim': 128, 'hidden_size': 320, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0009493957173113636, 'weight_decay': 0.0001, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n","Epoch 1 | val loss 2.3699 ppl 10.70 Top@1 0.430 Top@3 0.664 Top@5 0.756 MRR 0.575\n","Epoch 2 | val loss 2.2942 ppl 9.92 Top@1 0.442 Top@3 0.680 Top@5 0.766 MRR 0.586\n","Epoch 3 | val loss 2.2474 ppl 9.46 Top@1 0.451 Top@3 0.692 Top@5 0.777 MRR 0.596\n","Epoch 4 | val loss 2.2369 ppl 9.36 Top@1 0.457 Top@3 0.695 Top@5 0.774 MRR 0.599\n","Epoch 5 | val loss 2.2247 ppl 9.25 Top@1 0.462 Top@3 0.699 Top@5 0.781 MRR 0.604\n","Epoch 6 | val loss 2.2252 ppl 9.26 Top@1 0.462 Top@3 0.700 Top@5 0.779 MRR 0.604\n","\n","=== TRIAL 20/20 ===\n","{'embedding_dim': 160, 'hidden_size': 320, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 128, 'lr': 0.0006250299360799462, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n","Epoch 1 | val loss 2.4712 ppl 11.84 Top@1 0.427 Top@3 0.657 Top@5 0.753 MRR 0.570\n","Epoch 2 | val loss 2.3807 ppl 10.81 Top@1 0.442 Top@3 0.680 Top@5 0.768 MRR 0.586\n","Epoch 3 | val loss 2.3405 ppl 10.39 Top@1 0.454 Top@3 0.688 Top@5 0.775 MRR 0.596\n","Epoch 4 | val loss 2.3160 ppl 10.14 Top@1 0.451 Top@3 0.693 Top@5 0.780 MRR 0.596\n","Epoch 5 | val loss 2.3070 ppl 10.04 Top@1 0.461 Top@3 0.693 Top@5 0.779 MRR 0.603\n","Epoch 6 | val loss 2.3075 ppl 10.05 Top@1 0.457 Top@3 0.696 Top@5 0.778 MRR 0.601\n","Top 10 trials por MRR (test):\n"]},{"output_type":"display_data","data":{"text/plain":["    trial  embedding_dim  hidden_size  num_layers  dropout  seq_len  \\\n","16     17            192          320           2      0.3       16   \n","11     12            192          320           2      0.2       16   \n","9      10            128          256           2      0.3       16   \n","17     18            128          320           1      0.2       16   \n","4       5            160          256           2      0.3       16   \n","12     13            160          256           2      0.2       16   \n","8       9            160          256           1      0.3       16   \n","1       2            128          256           1      0.2       16   \n","15     16            192          256           1      0.3       16   \n","2       3            192          320           1      0.2       16   \n","\n","    batch_size        lr  weight_decay  grad_clip  ...  scheduler  \\\n","16          64  0.001371        0.0005        1.0  ...     cosine   \n","11         128  0.002395        0.0000        1.0  ...     cosine   \n","9           64  0.003952        0.0001        1.0  ...     cosine   \n","17          64  0.001938        0.0000        0.5  ...     cosine   \n","4           64  0.001889        0.0005        0.5  ...     cosine   \n","12          64  0.004496        0.0005        1.0  ...     cosine   \n","8          128  0.000816        0.0001        1.0  ...     cosine   \n","1          128  0.001601        0.0000        0.5  ...     cosine   \n","15         128  0.004424        0.0000        1.0  ...     cosine   \n","2           64  0.002495        0.0001        1.0  ...     cosine   \n","\n","    val_best_MRR      loss        ppl     Top@1     Top@3     Top@5       MRR  \\\n","16      0.608370  2.248762   9.476001  0.453590  0.695630  0.775026  0.597564   \n","11      0.605005  2.334087  10.320029  0.450989  0.695525  0.777940  0.596172   \n","9       0.604140  2.322862  10.204841  0.449740  0.696878  0.779188  0.595479   \n","17      0.604135  2.271196   9.690984  0.449948  0.692716  0.777211  0.595159   \n","4       0.606909  2.329096  10.268655  0.447451  0.695838  0.776691  0.593974   \n","12      0.604112  2.351196  10.498117  0.450676  0.688658  0.770656  0.593781   \n","8       0.603441  2.326750  10.244592  0.444433  0.697919  0.778460  0.593088   \n","1       0.602110  2.347062  10.454803  0.447451  0.691988  0.772529  0.592816   \n","15      0.601590  2.268224   9.662229  0.443600  0.690531  0.774610  0.591012   \n","2       0.595211  2.370365  10.701294  0.443809  0.688033  0.772320  0.590707   \n","\n","    n_test                               ckpt  \n","16    9610  /content/models_rs/rs_trial_17.pt  \n","11    9610  /content/models_rs/rs_trial_12.pt  \n","9     9610  /content/models_rs/rs_trial_10.pt  \n","17    9610  /content/models_rs/rs_trial_18.pt  \n","4     9610   /content/models_rs/rs_trial_5.pt  \n","12    9610  /content/models_rs/rs_trial_13.pt  \n","8     9610   /content/models_rs/rs_trial_9.pt  \n","1     9610   /content/models_rs/rs_trial_2.pt  \n","15    9610  /content/models_rs/rs_trial_16.pt  \n","2     9610   /content/models_rs/rs_trial_3.pt  \n","\n","[10 rows x 22 columns]"],"text/html":["\n","  <div id=\"df-e09c0afa-6131-4f9d-b814-b5d7104a115a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>trial</th>\n","      <th>embedding_dim</th>\n","      <th>hidden_size</th>\n","      <th>num_layers</th>\n","      <th>dropout</th>\n","      <th>seq_len</th>\n","      <th>batch_size</th>\n","      <th>lr</th>\n","      <th>weight_decay</th>\n","      <th>grad_clip</th>\n","      <th>...</th>\n","      <th>scheduler</th>\n","      <th>val_best_MRR</th>\n","      <th>loss</th>\n","      <th>ppl</th>\n","      <th>Top@1</th>\n","      <th>Top@3</th>\n","      <th>Top@5</th>\n","      <th>MRR</th>\n","      <th>n_test</th>\n","      <th>ckpt</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>192</td>\n","      <td>320</td>\n","      <td>2</td>\n","      <td>0.3</td>\n","      <td>16</td>\n","      <td>64</td>\n","      <td>0.001371</td>\n","      <td>0.0005</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.608370</td>\n","      <td>2.248762</td>\n","      <td>9.476001</td>\n","      <td>0.453590</td>\n","      <td>0.695630</td>\n","      <td>0.775026</td>\n","      <td>0.597564</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_17.pt</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>192</td>\n","      <td>320</td>\n","      <td>2</td>\n","      <td>0.2</td>\n","      <td>16</td>\n","      <td>128</td>\n","      <td>0.002395</td>\n","      <td>0.0000</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.605005</td>\n","      <td>2.334087</td>\n","      <td>10.320029</td>\n","      <td>0.450989</td>\n","      <td>0.695525</td>\n","      <td>0.777940</td>\n","      <td>0.596172</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_12.pt</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>128</td>\n","      <td>256</td>\n","      <td>2</td>\n","      <td>0.3</td>\n","      <td>16</td>\n","      <td>64</td>\n","      <td>0.003952</td>\n","      <td>0.0001</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.604140</td>\n","      <td>2.322862</td>\n","      <td>10.204841</td>\n","      <td>0.449740</td>\n","      <td>0.696878</td>\n","      <td>0.779188</td>\n","      <td>0.595479</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_10.pt</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>128</td>\n","      <td>320</td>\n","      <td>1</td>\n","      <td>0.2</td>\n","      <td>16</td>\n","      <td>64</td>\n","      <td>0.001938</td>\n","      <td>0.0000</td>\n","      <td>0.5</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.604135</td>\n","      <td>2.271196</td>\n","      <td>9.690984</td>\n","      <td>0.449948</td>\n","      <td>0.692716</td>\n","      <td>0.777211</td>\n","      <td>0.595159</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_18.pt</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>160</td>\n","      <td>256</td>\n","      <td>2</td>\n","      <td>0.3</td>\n","      <td>16</td>\n","      <td>64</td>\n","      <td>0.001889</td>\n","      <td>0.0005</td>\n","      <td>0.5</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.606909</td>\n","      <td>2.329096</td>\n","      <td>10.268655</td>\n","      <td>0.447451</td>\n","      <td>0.695838</td>\n","      <td>0.776691</td>\n","      <td>0.593974</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_5.pt</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>160</td>\n","      <td>256</td>\n","      <td>2</td>\n","      <td>0.2</td>\n","      <td>16</td>\n","      <td>64</td>\n","      <td>0.004496</td>\n","      <td>0.0005</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.604112</td>\n","      <td>2.351196</td>\n","      <td>10.498117</td>\n","      <td>0.450676</td>\n","      <td>0.688658</td>\n","      <td>0.770656</td>\n","      <td>0.593781</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_13.pt</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>160</td>\n","      <td>256</td>\n","      <td>1</td>\n","      <td>0.3</td>\n","      <td>16</td>\n","      <td>128</td>\n","      <td>0.000816</td>\n","      <td>0.0001</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.603441</td>\n","      <td>2.326750</td>\n","      <td>10.244592</td>\n","      <td>0.444433</td>\n","      <td>0.697919</td>\n","      <td>0.778460</td>\n","      <td>0.593088</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_9.pt</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>128</td>\n","      <td>256</td>\n","      <td>1</td>\n","      <td>0.2</td>\n","      <td>16</td>\n","      <td>128</td>\n","      <td>0.001601</td>\n","      <td>0.0000</td>\n","      <td>0.5</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.602110</td>\n","      <td>2.347062</td>\n","      <td>10.454803</td>\n","      <td>0.447451</td>\n","      <td>0.691988</td>\n","      <td>0.772529</td>\n","      <td>0.592816</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_2.pt</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>192</td>\n","      <td>256</td>\n","      <td>1</td>\n","      <td>0.3</td>\n","      <td>16</td>\n","      <td>128</td>\n","      <td>0.004424</td>\n","      <td>0.0000</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.601590</td>\n","      <td>2.268224</td>\n","      <td>9.662229</td>\n","      <td>0.443600</td>\n","      <td>0.690531</td>\n","      <td>0.774610</td>\n","      <td>0.591012</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_16.pt</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>192</td>\n","      <td>320</td>\n","      <td>1</td>\n","      <td>0.2</td>\n","      <td>16</td>\n","      <td>64</td>\n","      <td>0.002495</td>\n","      <td>0.0001</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>cosine</td>\n","      <td>0.595211</td>\n","      <td>2.370365</td>\n","      <td>10.701294</td>\n","      <td>0.443809</td>\n","      <td>0.688033</td>\n","      <td>0.772320</td>\n","      <td>0.590707</td>\n","      <td>9610</td>\n","      <td>/content/models_rs/rs_trial_3.pt</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 22 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e09c0afa-6131-4f9d-b814-b5d7104a115a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e09c0afa-6131-4f9d-b814-b5d7104a115a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e09c0afa-6131-4f9d-b814-b5d7104a115a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-a5757ce0-b33f-4f82-abaf-b85707a8fb35\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5757ce0-b33f-4f82-abaf-b85707a8fb35')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-a5757ce0-b33f-4f82-abaf-b85707a8fb35 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Resultados guardados en: /content/models_rs/random_search_results.csv\n","\n","=== MEJOR ENSAYO (por MRR en test) ===\n","Config: {'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0013711030226214714, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.03, 'tie_weights': True, 'scheduler': 'cosine'}\n","Metrics (test): {'loss': 2.2487623936179775, 'ppl': 9.476001016978005, 'Top@1': 0.4535900104120296, 'Top@3': 0.695629552537023, 'Top@5': 0.7750260146053723, 'MRR': 0.5975637307772403}\n","Checkpoint: /content/models_rs/rs_trial_17.pt\n"]}],"source":["\n","import math, time, copy, random, os, gc\n","import pandas as pd\n","from pprint import pprint\n","import torch.nn as nn\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def log_uniform(a,b):\n","    return math.exp(random.uniform(math.log(a), math.log(b)))\n","\n","def sample_cfg(base_cfg_dict):\n","    cfg_local = copy.deepcopy(base_cfg_dict)\n","    cfg_local[\"embedding_dim\"]   = random.choice([128,160,192])\n","    cfg_local[\"hidden_size\"]     = random.choice([256,320,384])\n","    cfg_local[\"num_layers\"]      = random.choice([1,2])\n","    cfg_local[\"dropout\"]         = random.choice([0.2,0.3])\n","\n","    # Optim\n","    cfg_local[\"lr\"]              = log_uniform(5e-4, 5e-3)\n","    cfg_local[\"weight_decay\"]    = random.choice([0.0, 1e-4, 5e-4])\n","    cfg_local[\"grad_clip\"]       = random.choice([0.5, 1.0])\n","\n","    # Data y task\n","    cfg_local[\"batch_size\"]      = random.choice([64, 128])\n","    cfg_local[\"seq_len\"]         = random.choice([16, 24])\n","\n","    # Criterio y regularizacion\n","    cfg_local[\"label_smoothing\"] = random.choice([0.03, 0.05])\n","    cfg_local[\"tie_weights\"]     = True # fijado por pruebas A/B\n","\n","    # Nuevo\n","    cfg_local[\"scheduler\"] = \"cosine\" # fijado por pruebas A/B\n","\n","    # OneCycle params (no aplican, pero mantenemos keys por compatibilidad)\n","    cfg_local[\"pct_start\"]      = base_cfg_dict.get(\"pct_start\", 0.15)\n","    cfg_local[\"div_factor\"]     = base_cfg_dict.get(\"div_factor\", 10.0)\n","    cfg_local[\"final_div_factor\"]= base_cfg_dict.get(\"final_div_factor\", 1e3)\n","\n","    # Entrenamiento\n","    cfg_local[\"epochs\"]   = base_cfg_dict[\"epochs\"]\n","    cfg_local[\"patience\"] = 2\n","    cfg_local[\"amp\"]      = base_cfg_dict[\"amp\"]\n","    return cfg_local\n","\n","BASE = cfg  # dataclass\n","RESULTS = []\n","BEST = {\"mrr\": -1, \"path\": None, \"cfg\": None, \"test\": None}\n","\n","N_TRIALS = 20  # n combinaciones a probar\n","\n","for t in range(1, N_TRIALS+1):\n","    trial_cfg = sample_cfg(vars(BASE))  # dict\n","    print(f\"\\n=== TRIAL {t}/{N_TRIALS} ===\")\n","    print({k:trial_cfg[k] for k in [\"embedding_dim\",\"hidden_size\",\"num_layers\",\"dropout\",\n","                                     \"seq_len\",\"batch_size\",\"lr\",\"weight_decay\",\"grad_clip\",\n","                                     \"label_smoothing\"]}),\n","\n","\n","    # DataLoaders específicos del trial\n","    train_loader_t, val_loader_t, test_loader_t, n_test = make_dataloaders(\n","        train_seqs, val_seqs, test_seqs,\n","        seq_len=trial_cfg[\"seq_len\"], batch_size=trial_cfg[\"batch_size\"]\n","    )\n","\n","    # Modelo para el trial\n","    model_t = ChordLSTM(vocab_size=len(vocab),\n","                        embedding_dim=trial_cfg[\"embedding_dim\"],\n","                        hidden_size=trial_cfg[\"hidden_size\"],\n","                        num_layers=trial_cfg[\"num_layers\"],\n","                        dropout=trial_cfg[\"dropout\"],\n","                        tie_weights=trial_cfg[\"tie_weights\"]).to(device)\n","\n","    # Entrenamiento con early stopping por MRR (val)\n","    save_path = os.path.join(BASE.save_dir, f\"rs_trial_{t}.pt\")\n","    best_mrr_val = train_once(\n","        model_t, train_loader_t, val_loader_t,\n","        epochs=trial_cfg[\"epochs\"], lr=trial_cfg[\"lr\"], weight_decay=trial_cfg[\"weight_decay\"],\n","        grad_clip=trial_cfg[\"grad_clip\"], amp=trial_cfg[\"amp\"],\n","        save_path=save_path, label_smoothing=trial_cfg[\"label_smoothing\"],\n","        patience=trial_cfg[\"patience\"], device=device,\n","        scheduler_type=trial_cfg[\"scheduler\"],\n","        pct_start=trial_cfg[\"pct_start\"], div_factor=trial_cfg[\"div_factor\"],\n","        final_div_factor=trial_cfg[\"final_div_factor\"]\n","    )\n","\n","    # Evaluación en test (coherente con training)\n","    test_crit = nn.CrossEntropyLoss(label_smoothing=trial_cfg[\"label_smoothing\"])\n","    testm = evaluate(model_t, test_loader_t, test_crit, device)\n","\n","\n","    row = {\"trial\": t, **{k:trial_cfg[k] for k in [\"embedding_dim\",\"hidden_size\",\"num_layers\",\"dropout\",\n","                                                   \"seq_len\",\"batch_size\",\"lr\",\"weight_decay\",\"grad_clip\",\n","                                                   \"label_smoothing\",\"tie_weights\"]},\n","           \"tie_weights\": True, \"scheduler\": \"cosine\",\n","           \"val_best_MRR\": best_mrr_val,\n","           **{k:testm[k] for k in [\"loss\",\"ppl\",\"Top@1\",\"Top@3\",\"Top@5\",\"MRR\"]},\n","           \"n_test\": n_test, \"ckpt\": save_path}\n","    RESULTS.append(row)\n","\n","    # Track best por MRR (test)\n","    if testm[\"MRR\"] > BEST[\"mrr\"]:\n","        BEST = {\"mrr\": testm[\"MRR\"], \"path\": save_path, \"cfg\": trial_cfg, \"test\": testm}\n","\n","    # Limpieza\n","    del model_t; gc.collect()\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","\n","# Mostrar resultados\n","df_rs = pd.DataFrame(RESULTS).sort_values(by=\"MRR\", ascending=False)\n","print(\"Top 10 trials por MRR (test):\")\n","display(df_rs.head(10))\n","\n","# Guardar CSV con todos los ensayos\n","os.makedirs(BASE.save_dir, exist_ok=True)\n","csv_path = os.path.join(BASE.save_dir, \"random_search_results.csv\")\n","df_rs.to_csv(csv_path, index=False)\n","print(\"Resultados guardados en:\", csv_path)\n","\n","print(\"\\n=== MEJOR ENSAYO (por MRR en test) ===\")\n","print(\"Config:\", {k:BEST[\"cfg\"][k] for k in [\"embedding_dim\",\"hidden_size\",\"num_layers\",\"dropout\",\n","                                             \"seq_len\",\"batch_size\",\"lr\",\"weight_decay\",\"grad_clip\",\n","                                             \"label_smoothing\",\"tie_weights\", \"scheduler\"]})\n","print(\"Metrics (test):\", BEST[\"test\"])\n","print(\"Checkpoint:\", BEST[\"path\"])\n"],"id":"3rUKOPX6GUqN"},{"cell_type":"markdown","source":["warnings a revisar:\n","/tmp/ipython-input-1199272555.py:31: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler(enabled=(amp and device.type=='cuda'))\n","/tmp/ipython-input-1199272555.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast(enabled=(amp and device.type=='cuda')):"],"metadata":{"id":"kC-VAPg7GUqN"},"id":"kC-VAPg7GUqN"},{"cell_type":"markdown","source":["## 11) Empaquetar el mejor checkpoint con metadatos y nombre informativo"],"metadata":{"id":"mM7TDYxgGUqO"},"id":"mM7TDYxgGUqO"},{"cell_type":"code","source":["# === Re-entrenar SOLO el mejor trial del CSV y exportar ===\n","import os, json, sys, datetime, torch, pandas as pd\n","import torch.nn as nn\n","\n","CSV_PATH = \"random_search_results.csv\"\n","TOKENIZER_PATH = \"lstm_tokenizer_.json\"\n","\n","# 1) Leer mejor fila por MRR\n","df = pd.read_csv(CSV_PATH)\n","best = df.sort_values(\"MRR\", ascending=False).iloc[0]\n","\n","cfg_best = {\n","    \"embedding_dim\":   int(best[\"embedding_dim\"]),\n","    \"hidden_size\":     int(best[\"hidden_size\"]),\n","    \"num_layers\":      int(best[\"num_layers\"]),\n","    \"dropout\":         float(best[\"dropout\"]),\n","    \"seq_len\":         int(best[\"seq_len\"]),\n","    \"batch_size\":      int(best[\"batch_size\"]),\n","    \"lr\":              float(best[\"lr\"]),\n","    \"weight_decay\":    float(best[\"weight_decay\"]),\n","    \"grad_clip\":       float(best[\"grad_clip\"]),\n","    \"label_smoothing\": float(best[\"label_smoothing\"]),\n","    \"tie_weights\":     bool(best.get(\"tie_weights\", True)),\n","    \"scheduler\":       str(best.get(\"scheduler\", \"cosine\")),\n","}\n","\n","print(\"Reentrenando config:\", cfg_best)\n","\n","# 2) Dataloaders con la config ganadora (usa tus funciones ya definidas)\n","train_loader, val_loader, test_loader, n_test = make_dataloaders(\n","    train_seqs, val_seqs, test_seqs,\n","    seq_len=cfg_best[\"seq_len\"], batch_size=cfg_best[\"batch_size\"]\n",")\n","\n","# 3) Modelo\n","model = ChordLSTM(\n","    vocab_size=len(vocab),\n","    embedding_dim=cfg_best[\"embedding_dim\"],\n","    hidden_size=cfg_best[\"hidden_size\"],\n","    num_layers=cfg_best[\"num_layers\"],\n","    dropout=cfg_best[\"dropout\"],\n","    tie_weights=cfg_best[\"tie_weights\"]\n",").to(device)\n","\n","# 4) Entrenar con el mismo esquema (early stop por MRR)\n","_ = train_once(\n","    model, train_loader, val_loader,\n","    epochs=cfg.epochs, lr=cfg_best[\"lr\"], weight_decay=cfg_best[\"weight_decay\"],\n","    grad_clip=cfg_best[\"grad_clip\"], amp=cfg.amp,\n","    save_path=None, label_smoothing=cfg_best[\"label_smoothing\"],\n","    patience=2, device=device,\n","    scheduler_type=cfg_best[\"scheduler\"], pct_start=cfg.pct_start,\n","    div_factor=cfg.div_factor, final_div_factor=cfg.final_div_factor\n",")\n","\n","# 5) Test coherente con el training\n","test_crit = nn.CrossEntropyLoss(label_smoothing=cfg_best[\"label_smoothing\"])\n","testm = evaluate(model, test_loader, test_crit, device)\n","print(\"Test:\", testm)\n","\n","# 6) Exportar con vocab del tokenizer (reproducible)\n","with open(TOKENIZER_PATH, \"r\") as f:\n","    tok = json.load(f)\n","vocab = tok[\"vocab\"]\n","stoi = {t:i for i,t in enumerate(vocab)}\n","itos = {i:t for i,t in enumerate(vocab)}\n","\n","export = {\n","    \"model_state\": model.state_dict(),\n","    \"model_class\": \"ChordLSTM\",\n","    \"config\": cfg_best,\n","    \"metrics_test\": testm,\n","    \"stoi\": stoi,\n","    \"itos\": itos,\n","    \"vocab_size\": len(stoi),\n","    \"created_at\": datetime.datetime.utcnow().isoformat() + \"Z\",\n","    \"env\": {\"python\": sys.version, \"torch\": torch.__version__, \"cuda_available\": torch.cuda.is_available()},\n","}\n","\n","out_dir = \".\"\n","name_info = f\"Top1-{testm['Top@1']:.4f}_MRR-{testm['MRR']:.4f}_ppl-{testm['ppl']:.3f}\"\n","best_named = os.path.join(out_dir, f\"lstm_rs_best__{name_info}.pt\")\n","stable_best = os.path.join(out_dir, \"lstm_rs_best.pt\")\n","\n","torch.save(export, best_named)\n","torch.save(export, stable_best)\n","\n","print(\"✅ Guardado\")\n","print(\" ├ OUT 1:\", best_named)\n","print(\" └ OUT 2:\", stable_best)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJkYWRjYUDwZ","executionInfo":{"status":"ok","timestamp":1755690714845,"user_tz":-120,"elapsed":59213,"user":{"displayName":"Antonio L. Trapote","userId":"06525061061648817839"}},"outputId":"79d95520-1c8b-4770-a668-8e4237e716fe"},"id":"JJkYWRjYUDwZ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reentrenando config: {'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0013711030226214, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.03, 'tie_weights': True, 'scheduler': 'cosine'}\n","Epoch 1 | val loss 2.3547 ppl 10.53 Top@1 0.426 Top@3 0.666 Top@5 0.755 MRR 0.573\n","Epoch 2 | val loss 2.2820 ppl 9.80 Top@1 0.442 Top@3 0.680 Top@5 0.767 MRR 0.587\n","Epoch 3 | val loss 2.2506 ppl 9.49 Top@1 0.448 Top@3 0.692 Top@5 0.773 MRR 0.593\n","Epoch 4 | val loss 2.2280 ppl 9.28 Top@1 0.459 Top@3 0.690 Top@5 0.776 MRR 0.601\n","Epoch 5 | val loss 2.2312 ppl 9.31 Top@1 0.462 Top@3 0.696 Top@5 0.777 MRR 0.603\n","Epoch 6 | val loss 2.2347 ppl 9.34 Top@1 0.463 Top@3 0.692 Top@5 0.776 MRR 0.603\n","Test: {'loss': 2.252060778257626, 'ppl': 9.50730811622195, 'Top@1': 0.45036420395421434, 'Top@3': 0.6936524453818116, 'Top@5': 0.7761706556043317, 'MRR': 0.5956792587544246}\n","✅ Guardado\n"," ├ OUT 1: ./lstm_rs_best__Top1-0.4504_MRR-0.5957_ppl-9.507.pt\n"," └ OUT 2: ./lstm_rs_best.pt\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2444798807.py:76: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  \"created_at\": datetime.datetime.utcnow().isoformat() + \"Z\",\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1odYJYUxeN7ykSQqhuGkCQTnOafQE8ZMZ","timestamp":1755598899865}],"gpuType":"T4","toc_visible":true},"accelerator":"GPU","language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}