{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ac126525",
      "metadata": {
        "id": "ac126525"
      },
      "source": [
        "**Nota**: Se recomienda ejecutar este notebook en Google Colab para asegurar la compatibilidad y evitar problemas de dependencias. El entrenamiento de los modelos requiere una cantidad significativa de memoria RAM y potencia de cómputo, que puede no estar disponible en todos los entornos locales.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/antoniotrapote/chord-prediction-tfm/blob/main/anexos/notebooks/03_modelado/05_modelo_lstm_finetuning.ipynb)\n",
        "[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-black?logo=github)](https://github.com/antoniotrapote/chord-prediction-tfm/blob/main/anexos/notebooks/03_modelado/05_modelo_lstm_finetuning.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "615071c5",
      "metadata": {
        "id": "615071c5"
      },
      "source": [
        "# LSTM_torch_v3 — LSTM + Random Search (PyTorch)\n",
        "\n",
        "**Objetivo:** ajuste de hiperparámetros sobre un modelo **LSTM** base.  \n",
        "**dataset:** `songdb_funcional_v4`\n",
        "\n",
        "**Estructura:**  \n",
        "1) Entorno (semillas, GPU/versions).  \n",
        "2) Carga de CSV + tokenización.  \n",
        "3) Split train/val/test.  \n",
        "4) Vocab + codificación.  \n",
        "5) Dataset + DataLoaders.  \n",
        "6) Modelo LSTM con `tie_weights` opcional.  \n",
        "7) Métricas y entrenamiento (Top@k, MRR, PPL).  \n",
        "8) A/B Test: selección manual de hiperparámetros.  \n",
        "9) Random Search (espacio de búsqueda, tabla de resultados, checkpoints).  \n",
        "10) Empaquetar el mejor checkpoint con metadatos y nombre informativo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb6d041e",
      "metadata": {
        "id": "fb6d041e"
      },
      "source": [
        "## 1) Entorno (Colab)\n",
        "El modelo fue entrenado en Google Colab, con las siguientes especificaciones:\n",
        ">Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]  \n",
        ">PyTorch: 2.8.0+cu126  \n",
        ">CUDA disponible: True  \n",
        ">GPU: Tesla T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "53e2aad0",
      "metadata": {
        "id": "53e2aad0"
      },
      "outputs": [],
      "source": [
        "#@title  Semillas y determinismo\n",
        "import random, os, numpy as np, torch\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "da47f894",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da47f894",
        "outputId": "073427c9-8e9f-406e-95f3-831a9c54dab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "PyTorch: 2.8.0+cu126\n",
            "CUDA disponible: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "#@title Comprobar GPU/versions\n",
        "import sys, torch\n",
        "print(\"Python:\", sys.version)  # python 3.11.13\n",
        "print(\"PyTorch:\", torch.__version__)  # PyTorch: 2.6.0+cu124\n",
        "print(\"CUDA disponible:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"⚠️ Activa GPU: Runtime ▶ Change runtime type ▶ GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96aca577",
      "metadata": {
        "id": "96aca577"
      },
      "source": [
        "## 2) Cargar CSV y tokenizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "79963c9e",
      "metadata": {
        "id": "79963c9e",
        "outputId": "6efdd65d-81f9-4045-b655-7249a4621aa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset descargado en: /content/songdb_funcional_v4.csv\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "# Configuración de datos\n",
        "USER = \"antoniotrapote\"\n",
        "REPO = \"chord-prediction-tfm\"\n",
        "BRANCH = \"main\"\n",
        "PATH_IN_REPO = \"anexos/data/songdb_funcional_v4.csv\"\n",
        "URL = f\"https://raw.githubusercontent.com/{USER}/{REPO}/{BRANCH}/{PATH_IN_REPO}\"\n",
        "\n",
        "# Ruta local donde guardar el archivo\n",
        "data_path = \"/content/songdb_funcional_v4.csv\"\n",
        "\n",
        "# Descargar el archivo CSV desde GitHub\n",
        "urllib.request.urlretrieve(URL, data_path)\n",
        "print(f\"Dataset descargado en: {data_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "21ebeacb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "21ebeacb",
        "outputId": "2fde996d-c27e-4da3-bbcd-b0e9d34dd974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filas totales: 2613\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                      funcional_prog\n",
              "0  vi #ivø V/III V/VI vi IV ii V7 iii vi ii V7 I ...\n",
              "1  VII VII I vi ii V7 VII VII I vi ii V7 I IV #iv...\n",
              "2  i VI V/V V7 i VI V/V V7 i VI iiø V7 i VI iiø V..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c49e4bd8-e81c-4064-848b-41d53df8dec3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>funcional_prog</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>vi #ivø V/III V/VI vi IV ii V7 iii vi ii V7 I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VII VII I vi ii V7 VII VII I vi ii V7 I IV #iv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i VI V/V V7 i VI V/V V7 i VI iiø V7 i VI iiø V...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c49e4bd8-e81c-4064-848b-41d53df8dec3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c49e4bd8-e81c-4064-848b-41d53df8dec3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c49e4bd8-e81c-4064-848b-41d53df8dec3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3d7262b8-cd38-4823-a20e-6e3de77dbda8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d7262b8-cd38-4823-a20e-6e3de77dbda8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3d7262b8-cd38-4823-a20e-6e3de77dbda8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"Filas tras filtro min_seq_len >= {min_seq_len}:\\\", len(df))\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"funcional_prog\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"vi #iv\\u00f8 V/III V/VI vi IV ii V7 iii vi ii V7 I IV7 vii\\u00f8 V/VI vi #iv\\u00f8 V/III V/VI vi IV ii V7 iii vi ii V7 I V7 I V/II ii ii V7 I V/II ii V7 I V/VI vi #iv\\u00f8 V/III V/VI vi IV ii V7 iii vi ii V7 I V7 I III7\",\n          \"VII VII I vi ii V7 VII VII I vi ii V7 I IV #ivo I iii vi V/V V7 VII VII I vi ii V7 VII VII I vi ii V7 I IV #ivo I ii V7 I I vi bvi v V/IV IV IV vi bvi v V/IV IV IV vii bvii vi V/V V V ii V7 ii V7 VII VII I vi ii V7 VII VII I vi ii V7 I IV #ivo I iii vi V/V V7 iii IV iii IV iii ii ii V7 I V7\",\n          \"i VI V/V V7 i VI V/V V7 i VI ii\\u00f8 V7 i VI ii\\u00f8 V7 i i Vsub/V V7 iv iv ii\\u00f8 bII7 iv bII v\\u00f8 V/IV iv bII v\\u00f8 V/IV iv bII v\\u00f8 V/IV iv Vsub/II ii\\u00f8 V7 i VI ii\\u00f8 V7 i VI ii\\u00f8 V7 i i Vsub/V V7 iv iv ii\\u00f8 bII7 bII bII\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filas tras filtro min_seq_len >= 8: 2612\n"
          ]
        }
      ],
      "source": [
        "#@title Tokenización de las progresiones funcionales\n",
        "import pandas as pd, ast, re, json\n",
        "\n",
        "# Configuración de datos\n",
        "sequence_col = \"funcional_prog\"  # Columna con la secuencia (\"chordprog\" si prefieres cifrado americano)\n",
        "min_seq_len = 8  # Filtrado - ignora secuencias muy cortas\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "assert sequence_col in df.columns, f\"Columna {sequence_col} no encontrada en el CSV.\"\n",
        "print(\"Filas totales:\", len(df))\n",
        "display(df[[sequence_col]].head(3))\n",
        "\n",
        "def parse_tokens_simple(s: str):\n",
        "    # Si viene como lista en string, intenta parsear\n",
        "    if isinstance(s, str) and s.strip().startswith(\"[\") and s.strip().endswith(\"]\"):\n",
        "        try:\n",
        "            lst = ast.literal_eval(s)\n",
        "            if isinstance(lst, list):\n",
        "                return [str(t) for t in lst]\n",
        "        except Exception:\n",
        "            pass\n",
        "    # Normalizar a tokens por espacios\n",
        "    s = str(s).replace(\"|\", \" \").replace(\"\\n\", \" \")\n",
        "    toks = [t for t in re.findall(r\"\\S+\", s) if t.strip()]\n",
        "    return toks\n",
        "\n",
        "df[\"_tokens_\"] = df[sequence_col].apply(parse_tokens_simple)\n",
        "df = df[df[\"_tokens_\"].apply(len) >= min_seq_len].reset_index(drop=True)\n",
        "print(f\"Filas tras filtro min_seq_len >= {min_seq_len}:\", len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b213aaa1",
      "metadata": {
        "id": "b213aaa1"
      },
      "source": [
        "## 3) Split train/val/test (simple, por filas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ebe2a8d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebe2a8d9",
        "outputId": "3d876e08-9347-4c54-8fff-a8ccbf8a335b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 2089, Val: 261, Test: 262\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Parámetros de división del dataset\n",
        "val_size = 0.10     # 10% para validación\n",
        "test_size = 0.10    # 10% para test\n",
        "random_state = 42   # Semilla para reproducibilidad\n",
        "\n",
        "# Dividir en train/val/test\n",
        "train_df, tmp_df = train_test_split(df, test_size=val_size+test_size, random_state=random_state, shuffle=True)\n",
        "rel_test = test_size / (val_size + test_size) if (val_size + test_size) > 0 else 0.5\n",
        "val_df, test_df = train_test_split(tmp_df, test_size=rel_test, random_state=random_state, shuffle=True)\n",
        "\n",
        "# Extraer las secuencias tokenizadas\n",
        "train_seqs = train_df[\"_tokens_\"].tolist()\n",
        "val_seqs   = val_df[\"_tokens_\"].tolist()\n",
        "test_seqs  = test_df[\"_tokens_\"].tolist()\n",
        "\n",
        "print(f\"Train: {len(train_seqs)}, Val: {len(val_seqs)}, Test: {len(test_seqs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "718adf54",
      "metadata": {
        "id": "718adf54"
      },
      "source": [
        "## 4) Vocabulario y codificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9967a362",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9967a362",
        "outputId": "710f6e87-4d09-48f9-8b54-70760b3bad8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del vocabulario: 86\n",
            "📊 Tokens únicos encontrados en entrenamiento: 82\n",
            "Tokenizer guardado en: lstm_tokenizer.json\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "# Tokens especiales\n",
        "PAD, UNK, BOS, EOS = \"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"\n",
        "tokenizer_path = \"lstm_tokenizer.json\"  # Nombre del archivo del tokenizer\n",
        "\n",
        "def build_vocab(seqs, min_freq=1):\n",
        "    \"\"\"\n",
        "    Construye el vocabulario SOLO con secuencias de entrenamiento.\n",
        "\n",
        "    IMPORTANTE: No incluir datos de validación/test para evitar data leakage.\n",
        "    Los tokens no vistos en entrenamiento se mapearán a <unk> durante la evaluación.\n",
        "    \"\"\"\n",
        "    c = Counter()\n",
        "    for s in seqs:\n",
        "        c.update(s)\n",
        "\n",
        "    # Crear vocabulario: tokens especiales + tokens frecuentes\n",
        "    vocab = [PAD, UNK, BOS, EOS] + [t for t,f in c.items() if f >= min_freq and t not in {PAD,UNK,BOS,EOS}]\n",
        "    stoi = {t:i for i,t in enumerate(vocab)}  # string to index\n",
        "    itos = {i:t for t,i in stoi.items()}     # index to string\n",
        "    return vocab, stoi, itos\n",
        "\n",
        "# 🎯 Construir vocabulario SOLO con datos de entrenamiento (evita data leakage)\n",
        "vocab, stoi, itos = build_vocab(train_seqs, min_freq=1)\n",
        "vocab_size = len(vocab)\n",
        "print(\"Tamaño del vocabulario:\", vocab_size)\n",
        "print(f\"📊 Tokens únicos encontrados en entrenamiento: {vocab_size - 4}\")  # -4 por tokens especiales\n",
        "\n",
        "# Guardar el tokenizer para uso posterior\n",
        "with open(tokenizer_path, \"w\") as f:\n",
        "    json.dump({\"vocab\": vocab}, f, ensure_ascii=False, indent=2)\n",
        "print(f\"Tokenizer guardado en: {tokenizer_path}\")\n",
        "\n",
        "def encode(seq, add_bos=True):\n",
        "    \"\"\"\n",
        "    Convierte una secuencia de tokens a índices numéricos.\n",
        "    Los tokens no vistos en entrenamiento se mapean automáticamente a <unk>.\n",
        "    \"\"\"\n",
        "    ids = [stoi[BOS]] if add_bos else []\n",
        "    ids += [stoi.get(t, stoi[UNK]) for t in seq]  # .get() maneja tokens desconocidos\n",
        "    return ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9bf672b",
      "metadata": {
        "id": "c9bf672b"
      },
      "source": [
        "## 5) Dataset (context→next) + DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "612fc37a",
      "metadata": {
        "id": "612fc37a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class NextTokenDataset(Dataset):\n",
        "    def __init__(self, sequences, seq_len):\n",
        "        self.samples = []\n",
        "        for seq in sequences:\n",
        "            ids = encode(seq, add_bos=True)\n",
        "            if len(ids) <= seq_len: continue\n",
        "            for i in range(seq_len, len(ids)):\n",
        "                self.samples.append((ids[i-seq_len:i], ids[i]))\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.samples[idx]\n",
        "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "def make_dataloaders(train_seqs, val_seqs, test_seqs, seq_len, batch_size):\n",
        "    \"\"\"\n",
        "    Crea los DataLoaders para entrenamiento, validación y test.\n",
        "\n",
        "    Args:\n",
        "        train_seqs, val_seqs, test_seqs: listas de secuencias tokenizadas\n",
        "        seq_len: longitud de secuencia de contexto\n",
        "        batch_size: tamaño del batch\n",
        "\n",
        "    Returns:\n",
        "        train_loader, val_loader, test_loader, n_test_samples\n",
        "    \"\"\"\n",
        "    train_data = NextTokenDataset(train_seqs, seq_len)\n",
        "    val_data   = NextTokenDataset(val_seqs, seq_len)\n",
        "    test_data  = NextTokenDataset(test_seqs, seq_len)\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    val_loader   = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "    test_loader  = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader, len(test_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecc527fa",
      "metadata": {
        "id": "ecc527fa"
      },
      "source": [
        "## 6) Modelo LSTM (con `tie_weights` opcional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "70a9da81",
      "metadata": {
        "id": "70a9da81"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class ChordLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM sencillo con opción tie_weights. Si tie_weights=True y hidden_size!=embedding_dim,\n",
        "    se añade una proyección H->E antes de decodificar con los pesos compartidos de la embedding.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout, tie_weights=False):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n",
        "                           batch_first=True, dropout=dropout if num_layers>1 else 0.0)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.tie_weights = tie_weights\n",
        "        if tie_weights:\n",
        "            self.proj = nn.Linear(hidden_size, embedding_dim, bias=False) if hidden_size != embedding_dim else nn.Identity()\n",
        "            self.decoder = nn.Linear(embedding_dim, vocab_size, bias=False)\n",
        "            self.decoder.weight = self.emb.weight\n",
        "        else:\n",
        "            self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.emb(x)                 # (B, T, E)\n",
        "        o, _ = self.rnn(e)              # (B, T, H)\n",
        "        h_t = self.dropout(o[:, -1, :]) # (B, H)\n",
        "        if self.tie_weights:\n",
        "            e_t = self.proj(h_t)        # (B, E)\n",
        "            return self.decoder(e_t)    # (B, V)\n",
        "        else:\n",
        "            return self.fc(h_t)         # (B, V)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac38d1fa",
      "metadata": {
        "id": "ac38d1fa"
      },
      "source": [
        "## 7) Métricas y entrenamiento (Top@k, MRR, PPL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aff6518e",
      "metadata": {
        "id": "aff6518e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import math, time, os, torch\n",
        "import torch.nn.functional as F\n",
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "def topk_metrics(logits, targets, ks=(1,3,5)):\n",
        "    \"\"\"\n",
        "    Definción de métricas Top@k y MRR.\n",
        "    \"\"\"\n",
        "    out = {}\n",
        "    with torch.no_grad():\n",
        "        for k in ks:\n",
        "            topk = logits.topk(k, dim=-1).indices\n",
        "            out[f\"Top@{k}\"] = (topk == targets.unsqueeze(1)).any(dim=1).float().mean().item()\n",
        "        ranks = (logits.argsort(dim=-1, descending=True) == targets.unsqueeze(1)).nonzero(as_tuple=False)[:,1] + 1\n",
        "        out[\"MRR\"] = (1.0 / ranks.float()).mean().item()\n",
        "    return out\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Función de evaluación\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total, n = 0.0, 0\n",
        "    agg = {\"Top@1\":0.0,\"Top@3\":0.0,\"Top@5\":0.0,\"MRR\":0.0}\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            b = x.size(0); total += loss.item()*b; n += b\n",
        "            m = topk_metrics(logits, y)\n",
        "            for k in agg: agg[k] += m[k]*b\n",
        "    for k in agg: agg[k] /= max(1,n)\n",
        "    return {\"loss\": total/max(1,n), \"ppl\": math.exp(total/max(1,n)), **agg}\n",
        "\n",
        "def train_once(model, train_loader, val_loader, epochs, lr, weight_decay,\n",
        "               grad_clip=1.0, amp=True, save_path=None, label_smoothing=0.0,\n",
        "               patience=2, device=torch.device(\"cpu\"),\n",
        "               scheduler_type=\"cosine\", pct_start=0.15, div_factor=10.0,   #nuevo\n",
        "               final_div_factor=1e3):                                   #nuevo\n",
        "    \"\"\"\n",
        "    train_once: bucle de entrenamiento con early stopping por MRR.\n",
        "\n",
        "    Parámetros clave:\n",
        "    - scheduler_type: \"cosine\" (por defecto), \"onecycle\" o \"none\".\n",
        "    - label_smoothing: e.g., 0.05 en train/val. (En test solemos usar 0.0 para comparabilidad.)\n",
        "    - pct_start / div_factor / final_div_factor: SOLO aplican si scheduler_type == \"onecycle\".\n",
        "      Con \"cosine\" y \"none\" se ignoran.\n",
        "\n",
        "    Notas:\n",
        "    - Se hace scheduler.step() por batch (T_max = epochs * steps_per_epoch para cosine).\n",
        "    - Guardamos el mejor estado según MRR de validación y lo restauramos al final.\n",
        "\"\"\"\n",
        "\n",
        "    scaler = GradScaler('cuda' if device.type=='cuda' else 'cpu',\n",
        "                        enabled=(amp and device.type=='cuda'))\n",
        "    crit = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    # Scheduler\n",
        "    steps_per_epoch = len(train_loader)\n",
        "    if scheduler_type == \"onecycle\":\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            opt, max_lr=lr, steps_per_epoch=steps_per_epoch, epochs=epochs,\n",
        "            pct_start=pct_start,\n",
        "            anneal_strategy='cos',\n",
        "            div_factor=div_factor,\n",
        "            final_div_factor=final_div_factor\n",
        "        )\n",
        "    elif scheduler_type == \"cosine\":\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            opt, T_max=epochs * steps_per_epoch\n",
        "        )\n",
        "    else:\n",
        "        scheduler = None\n",
        "\n",
        "    best_mrr, best_state = -1.0, None\n",
        "    no_improve = 0\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        for x,y in train_loader:\n",
        "            x,y = x.to(device), y.to(device)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with autocast('cuda', enabled=(amp and device.type=='cuda')):\n",
        "                logits = model(x); loss = crit(logits,y)\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip is not None:\n",
        "                scaler.unscale_(opt)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(opt); scaler.update()\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "        valm = evaluate(model, val_loader, crit, device)\n",
        "        print(f\"Epoch {ep} | val loss {valm['loss']:.4f} ppl {valm['ppl']:.2f} Top@1 {valm['Top@1']:.3f} Top@3 {valm['Top@3']:.3f} Top@5 {valm['Top@5']:.3f} MRR {valm['MRR']:.3f}\")\n",
        "        if valm[\"MRR\"] > best_mrr:\n",
        "            best_mrr, no_improve = valm[\"MRR\"], 0\n",
        "            best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
        "            if save_path:\n",
        "                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "                torch.save({\"model_state\": model.state_dict()}, save_path)\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience:\n",
        "                print(f\"⏹️ Early stopping (patience={patience})\")\n",
        "                break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    return best_mrr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tL8l7uvDXWpw",
      "metadata": {
        "id": "tL8l7uvDXWpw"
      },
      "source": [
        "## 8) A/B Tests: comparativa de parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "K_k3Z2Lg9GbS",
      "metadata": {
        "id": "K_k3Z2Lg9GbS"
      },
      "outputs": [],
      "source": [
        "#@title A/B helper\n",
        "import copy, torch.nn as nn, random, numpy as np, torch\n",
        "\n",
        "# Configuración base para A/B tests\n",
        "BASE_CONFIG = {\n",
        "    \"seq_len\": 24,\n",
        "    \"batch_size\": 128,\n",
        "    \"epochs\": 6,\n",
        "    \"lr\": 2e-3,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"dropout\": 0.2,\n",
        "    \"embedding_dim\": 128,\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 2,\n",
        "    \"grad_clip\": 1.0,\n",
        "    \"amp\": True,\n",
        "    \"scheduler\": \"cosine\",\n",
        "    \"pct_start\": 0.15,\n",
        "    \"div_factor\": 10.0,\n",
        "    \"final_div_factor\": 1e3,\n",
        "    \"random_state\": random_state\n",
        "}\n",
        "\n",
        "def _reseed(seed: int):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def run_single(cfg_local, *, tie_weights=False, label_smoothing=0.05,\n",
        "               test_label_smoothing=0.0):\n",
        "    \"\"\"\n",
        "    Ejecuta 1 entrenamiento + test con la config dada (sin RS).\n",
        "    - tie_weights: para probar rápido con/ sin weight tying\n",
        "    - label_smoothing: en training/validación\n",
        "    - test_label_smoothing: en test (0.0 para comparabilidad entre runs)\n",
        "    \"\"\"\n",
        "    # reseed para que las A/B sean comparables\n",
        "    _reseed(cfg_local[\"random_state\"])\n",
        "\n",
        "    # dataloaders\n",
        "    train_loader_t, val_loader_t, test_loader_t, _ = make_dataloaders(\n",
        "        train_seqs, val_seqs, test_seqs,\n",
        "        seq_len=cfg_local[\"seq_len\"], batch_size=cfg_local[\"batch_size\"]\n",
        "    )\n",
        "\n",
        "    # modelo\n",
        "    model = ChordLSTM(\n",
        "        vocab_size=len(vocab),\n",
        "        embedding_dim=cfg_local[\"embedding_dim\"],\n",
        "        hidden_size=cfg_local[\"hidden_size\"],\n",
        "        num_layers=cfg_local[\"num_layers\"],\n",
        "        dropout=cfg_local[\"dropout\"],\n",
        "        tie_weights=tie_weights\n",
        "    ).to(device)\n",
        "\n",
        "    # train (usa el scheduler definido en cfg_local)\n",
        "    _ = train_once(\n",
        "        model, train_loader_t, val_loader_t,\n",
        "        epochs=cfg_local[\"epochs\"], lr=cfg_local[\"lr\"], weight_decay=cfg_local[\"weight_decay\"],\n",
        "        grad_clip=cfg_local[\"grad_clip\"], amp=cfg_local[\"amp\"], save_path=None,\n",
        "        label_smoothing=label_smoothing, patience=2, device=device,\n",
        "        scheduler_type=cfg_local[\"scheduler\"], pct_start=cfg_local[\"pct_start\"],\n",
        "        div_factor=cfg_local[\"div_factor\"], final_div_factor=cfg_local[\"final_div_factor\"]\n",
        "    )\n",
        "\n",
        "    # test (elige coherencia con training o comparabilidad entre runs)\n",
        "    test_crit = nn.CrossEntropyLoss(label_smoothing=test_label_smoothing)\n",
        "    return evaluate(model, test_loader_t, test_crit, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "sVBLyHuV-HrA",
      "metadata": {
        "id": "sVBLyHuV-HrA"
      },
      "outputs": [],
      "source": [
        "#@title Mini A/B test function: compara Top@1 y MRR y muestra difs ===\n",
        "\n",
        "def compare_ab(cfg_A, cfg_B, *,\n",
        "               tie_A=False, tie_B=False,\n",
        "               ls_train=0.05, ls_test=0.0,\n",
        "               label_A=\"A\", label_B=\"B\"):\n",
        "    \"\"\"\n",
        "    Ejecuta A y B con mismos seeds/hparams (salvo los cambios que pongas en cfg_A/cfg_B)\n",
        "    y muestra Top@1 / MRR + diferencias.\n",
        "    - ls_train: label smoothing usado en training/validación\n",
        "    - ls_test:  label smoothing del criterio en test (0.0 para comparabilidad)\n",
        "    - tie_A/B:  activa/desactiva tie_weights en cada iteración\n",
        "    \"\"\"\n",
        "    print(f\"\\n>>> Run {label_A}\")\n",
        "    resA = run_single(cfg_A, tie_weights=tie_A, label_smoothing=ls_train, test_label_smoothing=ls_test)\n",
        "    print(f\"{label_A}: Top@1={resA['Top@1']:.4f}  MRR={resA['MRR']:.4f}\")\n",
        "\n",
        "    print(f\"\\n>>> Run {label_B}\")\n",
        "    resB = run_single(cfg_B, tie_weights=tie_B, label_smoothing=ls_train, test_label_smoothing=ls_test)\n",
        "    print(f\"{label_B}: Top@1={resB['Top@1']:.4f}  MRR={resB['MRR']:.4f}\")\n",
        "\n",
        "    d_top1 = resB['Top@1'] - resA['Top@1']\n",
        "    d_mrr  = resB['MRR']  - resA['MRR']\n",
        "    print(\"\\nΔ (B − A):  Top@1={:+.4f}  MRR={:+.4f}\".format(d_top1, d_mrr))\n",
        "\n",
        "    return resA, resB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3_veX7c_9cZL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_veX7c_9cZL",
        "outputId": "a223cded-a5fb-4640-e6ff-36e8bcef5ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Run none\n",
            "Epoch 1 | val loss 2.4192 ppl 11.24 Top@1 0.430 Top@3 0.669 Top@5 0.758 MRR 0.577\n",
            "Epoch 2 | val loss 2.3566 ppl 10.55 Top@1 0.444 Top@3 0.680 Top@5 0.767 MRR 0.588\n",
            "Epoch 3 | val loss 2.3282 ppl 10.26 Top@1 0.453 Top@3 0.687 Top@5 0.773 MRR 0.595\n",
            "Epoch 4 | val loss 2.3258 ppl 10.23 Top@1 0.459 Top@3 0.690 Top@5 0.775 MRR 0.599\n",
            "Epoch 5 | val loss 2.3287 ppl 10.26 Top@1 0.464 Top@3 0.694 Top@5 0.772 MRR 0.602\n",
            "Epoch 6 | val loss 2.3492 ppl 10.48 Top@1 0.453 Top@3 0.693 Top@5 0.770 MRR 0.596\n",
            "none: Top@1=0.4384  MRR=0.5829\n",
            "\n",
            ">>> Run onecycle\n",
            "Epoch 1 | val loss 2.4731 ppl 11.86 Top@1 0.423 Top@3 0.655 Top@5 0.745 MRR 0.567\n",
            "Epoch 2 | val loss 2.3602 ppl 10.59 Top@1 0.451 Top@3 0.679 Top@5 0.767 MRR 0.591\n",
            "Epoch 3 | val loss 2.3126 ppl 10.10 Top@1 0.461 Top@3 0.692 Top@5 0.775 MRR 0.601\n",
            "Epoch 4 | val loss 2.2974 ppl 9.95 Top@1 0.469 Top@3 0.696 Top@5 0.778 MRR 0.607\n",
            "Epoch 5 | val loss 2.2914 ppl 9.89 Top@1 0.465 Top@3 0.698 Top@5 0.778 MRR 0.605\n",
            "Epoch 6 | val loss 2.2957 ppl 9.93 Top@1 0.468 Top@3 0.698 Top@5 0.778 MRR 0.606\n",
            "⏹️ Early stopping (patience=2)\n",
            "onecycle: Top@1=0.4432  MRR=0.5870\n",
            "\n",
            "Δ (B − A):  Top@1=+0.0048  MRR=+0.0041\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'loss': 2.191780496691302,\n",
              "  'ppl': 8.951136403560488,\n",
              "  'Top@1': 0.43838831713557447,\n",
              "  'Top@3': 0.6777937152672038,\n",
              "  'Top@5': 0.7609857871520316,\n",
              "  'MRR': 0.582893018788442},\n",
              " {'loss': 2.1547056823436495,\n",
              "  'ppl': 8.62535121220173,\n",
              "  'Top@1': 0.44321293572214315,\n",
              "  'Top@3': 0.6841830750117325,\n",
              "  'Top@5': 0.7624201332439359,\n",
              "  'MRR': 0.5869966540891229})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#@title 8.1) A/B test: scheduler 'none' vs 'onecycle' (mismos hparams)\n",
        "cfgA = BASE_CONFIG.copy()\n",
        "cfgA[\"scheduler\"] = \"none\"\n",
        "\n",
        "cfgB = BASE_CONFIG.copy()\n",
        "cfgB[\"scheduler\"] = \"onecycle\"\n",
        "\n",
        "compare_ab(cfgA, cfgB, tie_A=False, tie_B=False, ls_train=0.05, ls_test=0.0,\n",
        "           label_A=\"none\", label_B=\"onecycle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "xJUCH657-ZwA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJUCH657-ZwA",
        "outputId": "a69d1c8f-135c-4ebc-a24f-54f092ed9967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Run cosine\n",
            "Epoch 1 | val loss 2.4185 ppl 11.23 Top@1 0.431 Top@3 0.671 Top@5 0.758 MRR 0.577\n",
            "Epoch 2 | val loss 2.3394 ppl 10.37 Top@1 0.449 Top@3 0.687 Top@5 0.773 MRR 0.594\n",
            "Epoch 3 | val loss 2.3022 ppl 10.00 Top@1 0.463 Top@3 0.692 Top@5 0.776 MRR 0.603\n",
            "Epoch 4 | val loss 2.2928 ppl 9.90 Top@1 0.466 Top@3 0.697 Top@5 0.780 MRR 0.606\n",
            "Epoch 5 | val loss 2.2906 ppl 9.88 Top@1 0.468 Top@3 0.697 Top@5 0.780 MRR 0.607\n",
            "Epoch 6 | val loss 2.2938 ppl 9.91 Top@1 0.467 Top@3 0.698 Top@5 0.779 MRR 0.607\n",
            "cosine: Top@1=0.4433  MRR=0.5879\n",
            "\n",
            ">>> Run onecycle\n",
            "Epoch 1 | val loss 2.4731 ppl 11.86 Top@1 0.423 Top@3 0.655 Top@5 0.745 MRR 0.567\n",
            "Epoch 2 | val loss 2.3602 ppl 10.59 Top@1 0.451 Top@3 0.679 Top@5 0.767 MRR 0.591\n",
            "Epoch 3 | val loss 2.3126 ppl 10.10 Top@1 0.461 Top@3 0.692 Top@5 0.775 MRR 0.601\n",
            "Epoch 4 | val loss 2.2974 ppl 9.95 Top@1 0.469 Top@3 0.696 Top@5 0.778 MRR 0.607\n",
            "Epoch 5 | val loss 2.2914 ppl 9.89 Top@1 0.465 Top@3 0.698 Top@5 0.778 MRR 0.605\n",
            "Epoch 6 | val loss 2.2957 ppl 9.93 Top@1 0.468 Top@3 0.698 Top@5 0.778 MRR 0.606\n",
            "⏹️ Early stopping (patience=2)\n",
            "onecycle: Top@1=0.4432  MRR=0.5870\n",
            "\n",
            "Δ (B − A):  Top@1=-0.0001  MRR=-0.0009\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'loss': 2.1458166598776263,\n",
              "  'ppl': 8.549020028907307,\n",
              "  'Top@1': 0.44334333079597105,\n",
              "  'Top@3': 0.6858782112823811,\n",
              "  'Top@5': 0.7680271224133707,\n",
              "  'MRR': 0.5879050129969904},\n",
              " {'loss': 2.1547056823436495,\n",
              "  'ppl': 8.62535121220173,\n",
              "  'Top@1': 0.44321293572214315,\n",
              "  'Top@3': 0.6841830750117325,\n",
              "  'Top@5': 0.7624201332439359,\n",
              "  'MRR': 0.5869966540891229})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#@title 8.2) A/B test: scheduler 'cosine' vs 'onecycle'\n",
        "cfgA = BASE_CONFIG.copy()\n",
        "cfgA[\"scheduler\"] = \"cosine\"\n",
        "\n",
        "cfgB = BASE_CONFIG.copy()\n",
        "cfgB[\"scheduler\"] = \"onecycle\"\n",
        "\n",
        "compare_ab(cfgA, cfgB, tie_A=False, tie_B=False, ls_train=0.05, ls_test=0.0,\n",
        "           label_A=\"cosine\", label_B=\"onecycle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "MJ07EnUH9hPw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ07EnUH9hPw",
        "outputId": "7b129c80-eb82-4db9-923b-e7d8a83cbfc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Run tie=False\n",
            "Epoch 1 | val loss 2.4731 ppl 11.86 Top@1 0.423 Top@3 0.655 Top@5 0.745 MRR 0.567\n",
            "Epoch 2 | val loss 2.3602 ppl 10.59 Top@1 0.451 Top@3 0.679 Top@5 0.767 MRR 0.591\n",
            "Epoch 3 | val loss 2.3126 ppl 10.10 Top@1 0.461 Top@3 0.692 Top@5 0.775 MRR 0.601\n",
            "Epoch 4 | val loss 2.2974 ppl 9.95 Top@1 0.469 Top@3 0.696 Top@5 0.778 MRR 0.607\n",
            "Epoch 5 | val loss 2.2914 ppl 9.89 Top@1 0.465 Top@3 0.698 Top@5 0.778 MRR 0.605\n",
            "Epoch 6 | val loss 2.2957 ppl 9.93 Top@1 0.468 Top@3 0.698 Top@5 0.778 MRR 0.606\n",
            "⏹️ Early stopping (patience=2)\n",
            "tie=False: Top@1=0.4432  MRR=0.5870\n",
            "\n",
            ">>> Run tie=True\n",
            "Epoch 1 | val loss 2.5040 ppl 12.23 Top@1 0.411 Top@3 0.664 Top@5 0.753 MRR 0.561\n",
            "Epoch 2 | val loss 2.3834 ppl 10.84 Top@1 0.442 Top@3 0.683 Top@5 0.769 MRR 0.586\n",
            "Epoch 3 | val loss 2.3310 ppl 10.29 Top@1 0.455 Top@3 0.689 Top@5 0.775 MRR 0.597\n",
            "Epoch 4 | val loss 2.3270 ppl 10.25 Top@1 0.458 Top@3 0.698 Top@5 0.776 MRR 0.601\n",
            "Epoch 5 | val loss 2.3231 ppl 10.21 Top@1 0.458 Top@3 0.699 Top@5 0.778 MRR 0.601\n",
            "Epoch 6 | val loss 2.3372 ppl 10.35 Top@1 0.462 Top@3 0.696 Top@5 0.777 MRR 0.602\n",
            "tie=True: Top@1=0.4428  MRR=0.5898\n",
            "\n",
            "Δ (B − A):  Top@1=-0.0004  MRR=+0.0028\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'loss': 2.1547056823436495,\n",
              "  'ppl': 8.62535121220173,\n",
              "  'Top@1': 0.44321293572214315,\n",
              "  'Top@3': 0.6841830750117325,\n",
              "  'Top@5': 0.7624201332439359,\n",
              "  'MRR': 0.5869966540891229},\n",
              " {'loss': 2.158039945063216,\n",
              "  'ppl': 8.654158397866162,\n",
              "  'Top@1': 0.44282174999158347,\n",
              "  'Top@3': 0.692137175953082,\n",
              "  'Top@5': 0.7701134439676802,\n",
              "  'MRR': 0.5898252001702824})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#@title 8.3) A/B test: tie_weights False vs True (con mismo scheduler)\n",
        "cfg_fix = BASE_CONFIG.copy()\n",
        "cfg_fix[\"scheduler\"] = \"onecycle\"  # o \"none\"\n",
        "\n",
        "compare_ab(cfg_fix, cfg_fix, tie_A=False, tie_B=True, ls_train=0.05, ls_test=0.0,\n",
        "           label_A=\"tie=False\", label_B=\"tie=True\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rMR-AeySFWDu",
      "metadata": {
        "id": "rMR-AeySFWDu"
      },
      "source": [
        "Se probaron distintos parámetros de entrenamiento:\n",
        "- scheduler: 'cosine', 'OneCycle', 'none'\n",
        "- weight_tying: True, False.\n",
        "\n",
        "Todas ellas aportaron ligeras mejoras en métricas Top@1/MRR.\n",
        "\n",
        "Finalmente, se seleccionó la configuración con scheduler: 'cosine' y tie_weights= True, aunque las diferencias respecto a OneCycle sin tying no fueron verdaderamente significativas."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-W2NbGAHGUqN",
      "metadata": {
        "id": "-W2NbGAHGUqN"
      },
      "source": [
        "## 9) Random Search (espacio de búsqueda, resultados, checkpoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3rUKOPX6GUqN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3rUKOPX6GUqN",
        "outputId": "647ea44b-3a1a-4dc0-b2f4-a79e018b3bb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TRIAL 1/20 ===\n",
            "{'embedding_dim': 192, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0008787429588337066, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n",
            "Epoch 1 | val loss 2.3949 ppl 10.97 Top@1 0.415 Top@3 0.664 Top@5 0.754 MRR 0.566\n",
            "Epoch 2 | val loss 2.3093 ppl 10.07 Top@1 0.440 Top@3 0.676 Top@5 0.764 MRR 0.585\n",
            "Epoch 3 | val loss 2.2728 ppl 9.71 Top@1 0.442 Top@3 0.685 Top@5 0.771 MRR 0.589\n",
            "Epoch 4 | val loss 2.2382 ppl 9.38 Top@1 0.454 Top@3 0.689 Top@5 0.776 MRR 0.597\n",
            "Epoch 5 | val loss 2.2269 ppl 9.27 Top@1 0.454 Top@3 0.694 Top@5 0.777 MRR 0.599\n",
            "Epoch 6 | val loss 2.2241 ppl 9.25 Top@1 0.459 Top@3 0.694 Top@5 0.777 MRR 0.601\n",
            "\n",
            "=== TRIAL 2/20 ===\n",
            "{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 128, 'lr': 0.0016007565680120513, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4322 ppl 11.38 Top@1 0.433 Top@3 0.673 Top@5 0.759 MRR 0.578\n",
            "Epoch 2 | val loss 2.3791 ppl 10.80 Top@1 0.446 Top@3 0.681 Top@5 0.766 MRR 0.588\n",
            "Epoch 3 | val loss 2.3469 ppl 10.45 Top@1 0.450 Top@3 0.689 Top@5 0.776 MRR 0.595\n",
            "Epoch 4 | val loss 2.3180 ppl 10.16 Top@1 0.463 Top@3 0.691 Top@5 0.778 MRR 0.602\n",
            "Epoch 5 | val loss 2.3127 ppl 10.10 Top@1 0.464 Top@3 0.697 Top@5 0.779 MRR 0.604\n",
            "Epoch 6 | val loss 2.3144 ppl 10.12 Top@1 0.460 Top@3 0.697 Top@5 0.780 MRR 0.603\n",
            "\n",
            "=== TRIAL 3/20 ===\n",
            "{'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0024952231976338324, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.5216 ppl 12.45 Top@1 0.418 Top@3 0.655 Top@5 0.747 MRR 0.565\n",
            "Epoch 2 | val loss 2.4192 ppl 11.24 Top@1 0.434 Top@3 0.675 Top@5 0.759 MRR 0.579\n",
            "Epoch 3 | val loss 2.3715 ppl 10.71 Top@1 0.446 Top@3 0.685 Top@5 0.767 MRR 0.590\n",
            "Epoch 4 | val loss 2.3594 ppl 10.58 Top@1 0.452 Top@3 0.688 Top@5 0.774 MRR 0.594\n",
            "Epoch 5 | val loss 2.3498 ppl 10.48 Top@1 0.456 Top@3 0.691 Top@5 0.773 MRR 0.597\n",
            "Epoch 6 | val loss 2.3525 ppl 10.51 Top@1 0.457 Top@3 0.690 Top@5 0.771 MRR 0.597\n",
            "\n",
            "=== TRIAL 4/20 ===\n",
            "{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0011427451449300696, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.03}\n",
            "Epoch 1 | val loss 2.3355 ppl 10.33 Top@1 0.429 Top@3 0.673 Top@5 0.762 MRR 0.576\n",
            "Epoch 2 | val loss 2.2805 ppl 9.78 Top@1 0.446 Top@3 0.681 Top@5 0.771 MRR 0.589\n",
            "Epoch 3 | val loss 2.2444 ppl 9.43 Top@1 0.447 Top@3 0.689 Top@5 0.776 MRR 0.594\n",
            "Epoch 4 | val loss 2.2282 ppl 9.28 Top@1 0.454 Top@3 0.689 Top@5 0.777 MRR 0.597\n",
            "Epoch 5 | val loss 2.2235 ppl 9.24 Top@1 0.460 Top@3 0.693 Top@5 0.779 MRR 0.602\n",
            "Epoch 6 | val loss 2.2326 ppl 9.32 Top@1 0.463 Top@3 0.694 Top@5 0.777 MRR 0.603\n",
            "\n",
            "=== TRIAL 5/20 ===\n",
            "{'embedding_dim': 160, 'hidden_size': 256, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0018893923369180784, 'weight_decay': 0.0005, 'grad_clip': 0.5, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4565 ppl 11.66 Top@1 0.434 Top@3 0.664 Top@5 0.755 MRR 0.575\n",
            "Epoch 2 | val loss 2.3573 ppl 10.56 Top@1 0.451 Top@3 0.689 Top@5 0.770 MRR 0.594\n",
            "Epoch 3 | val loss 2.3334 ppl 10.31 Top@1 0.449 Top@3 0.690 Top@5 0.781 MRR 0.595\n",
            "Epoch 4 | val loss 2.3098 ppl 10.07 Top@1 0.459 Top@3 0.695 Top@5 0.781 MRR 0.602\n",
            "Epoch 5 | val loss 2.3015 ppl 9.99 Top@1 0.462 Top@3 0.699 Top@5 0.783 MRR 0.605\n",
            "Epoch 6 | val loss 2.3064 ppl 10.04 Top@1 0.463 Top@3 0.698 Top@5 0.783 MRR 0.605\n",
            "\n",
            "=== TRIAL 6/20 ===\n",
            "{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0009482953204352053, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4486 ppl 11.57 Top@1 0.424 Top@3 0.664 Top@5 0.755 MRR 0.571\n",
            "Epoch 2 | val loss 2.4043 ppl 11.07 Top@1 0.443 Top@3 0.672 Top@5 0.764 MRR 0.584\n",
            "Epoch 3 | val loss 2.3406 ppl 10.39 Top@1 0.449 Top@3 0.689 Top@5 0.773 MRR 0.593\n",
            "Epoch 4 | val loss 2.3218 ppl 10.19 Top@1 0.458 Top@3 0.689 Top@5 0.776 MRR 0.599\n",
            "Epoch 5 | val loss 2.2973 ppl 9.95 Top@1 0.465 Top@3 0.696 Top@5 0.783 MRR 0.606\n",
            "Epoch 6 | val loss 2.2983 ppl 9.96 Top@1 0.466 Top@3 0.694 Top@5 0.782 MRR 0.605\n",
            "\n",
            "=== TRIAL 7/20 ===\n",
            "{'embedding_dim': 128, 'hidden_size': 384, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0020328297598925242, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4467 ppl 11.55 Top@1 0.424 Top@3 0.671 Top@5 0.761 MRR 0.573\n",
            "Epoch 2 | val loss 2.3676 ppl 10.67 Top@1 0.431 Top@3 0.690 Top@5 0.773 MRR 0.585\n",
            "Epoch 3 | val loss 2.3208 ppl 10.18 Top@1 0.461 Top@3 0.694 Top@5 0.780 MRR 0.602\n",
            "Epoch 4 | val loss 2.3182 ppl 10.16 Top@1 0.461 Top@3 0.701 Top@5 0.780 MRR 0.604\n",
            "Epoch 5 | val loss 2.3420 ppl 10.40 Top@1 0.463 Top@3 0.699 Top@5 0.777 MRR 0.604\n",
            "Epoch 6 | val loss 2.3597 ppl 10.59 Top@1 0.462 Top@3 0.698 Top@5 0.777 MRR 0.603\n",
            "⏹️ Early stopping (patience=2)\n",
            "\n",
            "=== TRIAL 8/20 ===\n",
            "{'embedding_dim': 160, 'hidden_size': 384, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 24, 'batch_size': 64, 'lr': 0.003481945141955723, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.5510 ppl 12.82 Top@1 0.407 Top@3 0.649 Top@5 0.744 MRR 0.556\n",
            "Epoch 2 | val loss 2.4496 ppl 11.58 Top@1 0.432 Top@3 0.670 Top@5 0.768 MRR 0.578\n",
            "Epoch 3 | val loss 2.3800 ppl 10.80 Top@1 0.432 Top@3 0.683 Top@5 0.775 MRR 0.583\n",
            "Epoch 4 | val loss 2.3364 ppl 10.34 Top@1 0.449 Top@3 0.691 Top@5 0.776 MRR 0.594\n",
            "Epoch 5 | val loss 2.3270 ppl 10.25 Top@1 0.457 Top@3 0.694 Top@5 0.777 MRR 0.600\n",
            "Epoch 6 | val loss 2.3260 ppl 10.24 Top@1 0.456 Top@3 0.696 Top@5 0.779 MRR 0.600\n",
            "\n",
            "=== TRIAL 9/20 ===\n",
            "{'embedding_dim': 160, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 128, 'lr': 0.0008158241335586644, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4514 ppl 11.60 Top@1 0.423 Top@3 0.672 Top@5 0.761 MRR 0.572\n",
            "Epoch 2 | val loss 2.3864 ppl 10.87 Top@1 0.438 Top@3 0.679 Top@5 0.770 MRR 0.584\n",
            "Epoch 3 | val loss 2.3512 ppl 10.50 Top@1 0.449 Top@3 0.685 Top@5 0.776 MRR 0.592\n",
            "Epoch 4 | val loss 2.3190 ppl 10.17 Top@1 0.458 Top@3 0.692 Top@5 0.775 MRR 0.600\n",
            "Epoch 5 | val loss 2.3090 ppl 10.06 Top@1 0.459 Top@3 0.696 Top@5 0.781 MRR 0.602\n",
            "Epoch 6 | val loss 2.3075 ppl 10.05 Top@1 0.459 Top@3 0.695 Top@5 0.779 MRR 0.602\n",
            "\n",
            "=== TRIAL 10/20 ===\n",
            "{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.003951781173884884, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4735 ppl 11.86 Top@1 0.428 Top@3 0.659 Top@5 0.751 MRR 0.572\n",
            "Epoch 2 | val loss 2.3790 ppl 10.79 Top@1 0.445 Top@3 0.681 Top@5 0.767 MRR 0.588\n",
            "Epoch 3 | val loss 2.3321 ppl 10.30 Top@1 0.458 Top@3 0.691 Top@5 0.775 MRR 0.598\n",
            "Epoch 4 | val loss 2.3103 ppl 10.08 Top@1 0.460 Top@3 0.694 Top@5 0.775 MRR 0.602\n",
            "Epoch 5 | val loss 2.2992 ppl 9.97 Top@1 0.464 Top@3 0.697 Top@5 0.777 MRR 0.604\n",
            "Epoch 6 | val loss 2.3027 ppl 10.00 Top@1 0.462 Top@3 0.696 Top@5 0.777 MRR 0.604\n",
            "\n",
            "=== TRIAL 11/20 ===\n",
            "{'embedding_dim': 128, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0021203914581812977, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4585 ppl 11.69 Top@1 0.420 Top@3 0.668 Top@5 0.758 MRR 0.569\n",
            "Epoch 2 | val loss 2.3999 ppl 11.02 Top@1 0.439 Top@3 0.679 Top@5 0.773 MRR 0.584\n",
            "Epoch 3 | val loss 2.3532 ppl 10.52 Top@1 0.455 Top@3 0.697 Top@5 0.775 MRR 0.598\n",
            "Epoch 4 | val loss 2.3227 ppl 10.20 Top@1 0.457 Top@3 0.700 Top@5 0.783 MRR 0.601\n",
            "Epoch 5 | val loss 2.3214 ppl 10.19 Top@1 0.463 Top@3 0.700 Top@5 0.780 MRR 0.605\n",
            "Epoch 6 | val loss 2.3238 ppl 10.21 Top@1 0.462 Top@3 0.698 Top@5 0.782 MRR 0.604\n",
            "\n",
            "=== TRIAL 12/20 ===\n",
            "{'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 128, 'lr': 0.002394712684403, 'weight_decay': 0.0, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4101 ppl 11.13 Top@1 0.438 Top@3 0.670 Top@5 0.759 MRR 0.580\n",
            "Epoch 2 | val loss 2.3567 ppl 10.56 Top@1 0.449 Top@3 0.686 Top@5 0.773 MRR 0.593\n",
            "Epoch 3 | val loss 2.3191 ppl 10.17 Top@1 0.456 Top@3 0.695 Top@5 0.780 MRR 0.599\n",
            "Epoch 4 | val loss 2.3188 ppl 10.16 Top@1 0.462 Top@3 0.697 Top@5 0.780 MRR 0.603\n",
            "Epoch 5 | val loss 2.3237 ppl 10.21 Top@1 0.466 Top@3 0.693 Top@5 0.781 MRR 0.604\n",
            "Epoch 6 | val loss 2.3350 ppl 10.33 Top@1 0.467 Top@3 0.693 Top@5 0.779 MRR 0.605\n",
            "\n",
            "=== TRIAL 13/20 ===\n",
            "{'embedding_dim': 160, 'hidden_size': 256, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 64, 'lr': 0.004495582084837762, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4697 ppl 11.82 Top@1 0.426 Top@3 0.662 Top@5 0.756 MRR 0.571\n",
            "Epoch 2 | val loss 2.3843 ppl 10.85 Top@1 0.440 Top@3 0.684 Top@5 0.767 MRR 0.586\n",
            "Epoch 3 | val loss 2.3465 ppl 10.45 Top@1 0.459 Top@3 0.689 Top@5 0.771 MRR 0.599\n",
            "Epoch 4 | val loss 2.3178 ppl 10.15 Top@1 0.460 Top@3 0.695 Top@5 0.776 MRR 0.602\n",
            "Epoch 5 | val loss 2.3042 ppl 10.02 Top@1 0.469 Top@3 0.699 Top@5 0.780 MRR 0.608\n",
            "Epoch 6 | val loss 2.3096 ppl 10.07 Top@1 0.469 Top@3 0.697 Top@5 0.780 MRR 0.608\n",
            "\n",
            "=== TRIAL 14/20 ===\n",
            "{'embedding_dim': 192, 'hidden_size': 384, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 128, 'lr': 0.0011827252180412623, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n",
            "Epoch 1 | val loss 2.4148 ppl 11.19 Top@1 0.422 Top@3 0.659 Top@5 0.748 MRR 0.568\n",
            "Epoch 2 | val loss 2.3071 ppl 10.05 Top@1 0.433 Top@3 0.675 Top@5 0.767 MRR 0.582\n",
            "Epoch 3 | val loss 2.2661 ppl 9.64 Top@1 0.441 Top@3 0.691 Top@5 0.778 MRR 0.590\n",
            "Epoch 4 | val loss 2.2393 ppl 9.39 Top@1 0.450 Top@3 0.692 Top@5 0.779 MRR 0.595\n",
            "Epoch 5 | val loss 2.2334 ppl 9.33 Top@1 0.455 Top@3 0.696 Top@5 0.780 MRR 0.600\n",
            "Epoch 6 | val loss 2.2378 ppl 9.37 Top@1 0.459 Top@3 0.697 Top@5 0.779 MRR 0.602\n",
            "\n",
            "=== TRIAL 15/20 ===\n",
            "{'embedding_dim': 128, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0005713407109004834, 'weight_decay': 0.0005, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n",
            "Epoch 1 | val loss 2.3569 ppl 10.56 Top@1 0.434 Top@3 0.670 Top@5 0.759 MRR 0.577\n",
            "Epoch 2 | val loss 2.2913 ppl 9.89 Top@1 0.443 Top@3 0.679 Top@5 0.766 MRR 0.586\n",
            "Epoch 3 | val loss 2.2460 ppl 9.45 Top@1 0.457 Top@3 0.688 Top@5 0.774 MRR 0.598\n",
            "Epoch 4 | val loss 2.2341 ppl 9.34 Top@1 0.463 Top@3 0.691 Top@5 0.776 MRR 0.602\n",
            "Epoch 5 | val loss 2.2275 ppl 9.28 Top@1 0.465 Top@3 0.696 Top@5 0.777 MRR 0.605\n",
            "Epoch 6 | val loss 2.2296 ppl 9.30 Top@1 0.465 Top@3 0.694 Top@5 0.777 MRR 0.605\n",
            "\n",
            "=== TRIAL 16/20 ===\n",
            "{'embedding_dim': 192, 'hidden_size': 256, 'num_layers': 1, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 128, 'lr': 0.004424036323090671, 'weight_decay': 0.0, 'grad_clip': 1.0, 'label_smoothing': 0.03}\n",
            "Epoch 1 | val loss 2.4481 ppl 11.57 Top@1 0.419 Top@3 0.647 Top@5 0.736 MRR 0.562\n",
            "Epoch 2 | val loss 2.3694 ppl 10.69 Top@1 0.432 Top@3 0.670 Top@5 0.759 MRR 0.576\n",
            "Epoch 3 | val loss 2.3175 ppl 10.15 Top@1 0.437 Top@3 0.676 Top@5 0.766 MRR 0.583\n",
            "Epoch 4 | val loss 2.2699 ppl 9.68 Top@1 0.447 Top@3 0.690 Top@5 0.773 MRR 0.593\n",
            "Epoch 5 | val loss 2.2508 ppl 9.50 Top@1 0.451 Top@3 0.690 Top@5 0.775 MRR 0.595\n",
            "Epoch 6 | val loss 2.2491 ppl 9.48 Top@1 0.452 Top@3 0.690 Top@5 0.777 MRR 0.596\n",
            "\n",
            "=== TRIAL 17/20 ===\n",
            "{'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0013711030226214714, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.03}\n",
            "Epoch 1 | val loss 2.3538 ppl 10.53 Top@1 0.433 Top@3 0.665 Top@5 0.756 MRR 0.577\n",
            "Epoch 2 | val loss 2.2722 ppl 9.70 Top@1 0.446 Top@3 0.684 Top@5 0.770 MRR 0.590\n",
            "Epoch 3 | val loss 2.2501 ppl 9.49 Top@1 0.451 Top@3 0.688 Top@5 0.776 MRR 0.595\n",
            "Epoch 4 | val loss 2.2336 ppl 9.33 Top@1 0.457 Top@3 0.696 Top@5 0.779 MRR 0.600\n",
            "Epoch 5 | val loss 2.2299 ppl 9.30 Top@1 0.461 Top@3 0.701 Top@5 0.779 MRR 0.603\n",
            "Epoch 6 | val loss 2.2384 ppl 9.38 Top@1 0.461 Top@3 0.700 Top@5 0.778 MRR 0.603\n",
            "\n",
            "=== TRIAL 18/20 ===\n",
            "{'embedding_dim': 128, 'hidden_size': 320, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0019382514554016706, 'weight_decay': 0.0, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n",
            "Epoch 1 | val loss 2.4005 ppl 11.03 Top@1 0.424 Top@3 0.656 Top@5 0.753 MRR 0.568\n",
            "Epoch 2 | val loss 2.3021 ppl 10.00 Top@1 0.441 Top@3 0.678 Top@5 0.765 MRR 0.585\n",
            "Epoch 3 | val loss 2.2755 ppl 9.73 Top@1 0.451 Top@3 0.691 Top@5 0.770 MRR 0.594\n",
            "Epoch 4 | val loss 2.2646 ppl 9.63 Top@1 0.457 Top@3 0.688 Top@5 0.773 MRR 0.598\n",
            "Epoch 5 | val loss 2.2576 ppl 9.56 Top@1 0.456 Top@3 0.690 Top@5 0.774 MRR 0.598\n",
            "Epoch 6 | val loss 2.2637 ppl 9.62 Top@1 0.460 Top@3 0.690 Top@5 0.773 MRR 0.600\n",
            "\n",
            "=== TRIAL 19/20 ===\n",
            "{'embedding_dim': 128, 'hidden_size': 320, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 64, 'lr': 0.0009493957173113636, 'weight_decay': 0.0001, 'grad_clip': 0.5, 'label_smoothing': 0.03}\n",
            "Epoch 1 | val loss 2.3691 ppl 10.69 Top@1 0.423 Top@3 0.667 Top@5 0.759 MRR 0.571\n",
            "Epoch 2 | val loss 2.2967 ppl 9.94 Top@1 0.432 Top@3 0.683 Top@5 0.770 MRR 0.582\n",
            "Epoch 3 | val loss 2.2491 ppl 9.48 Top@1 0.448 Top@3 0.695 Top@5 0.774 MRR 0.595\n",
            "Epoch 4 | val loss 2.2351 ppl 9.35 Top@1 0.453 Top@3 0.691 Top@5 0.781 MRR 0.599\n",
            "Epoch 5 | val loss 2.2275 ppl 9.28 Top@1 0.463 Top@3 0.698 Top@5 0.779 MRR 0.605\n",
            "Epoch 6 | val loss 2.2300 ppl 9.30 Top@1 0.463 Top@3 0.696 Top@5 0.777 MRR 0.604\n",
            "\n",
            "=== TRIAL 20/20 ===\n",
            "{'embedding_dim': 160, 'hidden_size': 320, 'num_layers': 1, 'dropout': 0.2, 'seq_len': 24, 'batch_size': 128, 'lr': 0.0006250299360799462, 'weight_decay': 0.0001, 'grad_clip': 1.0, 'label_smoothing': 0.05}\n",
            "Epoch 1 | val loss 2.4491 ppl 11.58 Top@1 0.426 Top@3 0.663 Top@5 0.756 MRR 0.571\n",
            "Epoch 2 | val loss 2.3849 ppl 10.86 Top@1 0.435 Top@3 0.680 Top@5 0.768 MRR 0.583\n",
            "Epoch 3 | val loss 2.3439 ppl 10.42 Top@1 0.451 Top@3 0.682 Top@5 0.772 MRR 0.593\n",
            "Epoch 4 | val loss 2.3177 ppl 10.15 Top@1 0.460 Top@3 0.690 Top@5 0.777 MRR 0.600\n",
            "Epoch 5 | val loss 2.3071 ppl 10.05 Top@1 0.461 Top@3 0.696 Top@5 0.779 MRR 0.603\n",
            "Epoch 6 | val loss 2.3022 ppl 10.00 Top@1 0.461 Top@3 0.698 Top@5 0.779 MRR 0.603\n",
            "Top 10 trials por MRR (test):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    trial  embedding_dim  hidden_size  num_layers  dropout  seq_len  \\\n",
              "16     17            192          320           2      0.3       16   \n",
              "8       9            160          256           1      0.3       16   \n",
              "12     13            160          256           2      0.2       16   \n",
              "1       2            128          256           1      0.2       16   \n",
              "4       5            160          256           2      0.3       16   \n",
              "11     12            192          320           2      0.2       16   \n",
              "9      10            128          256           2      0.3       16   \n",
              "17     18            128          320           1      0.2       16   \n",
              "18     19            128          320           1      0.2       24   \n",
              "6       7            128          384           2      0.2       24   \n",
              "\n",
              "    batch_size        lr  weight_decay  grad_clip  ...  scheduler  \\\n",
              "16          64  0.001371        0.0005        1.0  ...     cosine   \n",
              "8          128  0.000816        0.0001        1.0  ...     cosine   \n",
              "12          64  0.004496        0.0005        1.0  ...     cosine   \n",
              "1          128  0.001601        0.0000        0.5  ...     cosine   \n",
              "4           64  0.001889        0.0005        0.5  ...     cosine   \n",
              "11         128  0.002395        0.0000        1.0  ...     cosine   \n",
              "9           64  0.003952        0.0001        1.0  ...     cosine   \n",
              "17          64  0.001938        0.0000        0.5  ...     cosine   \n",
              "18          64  0.000949        0.0001        0.5  ...     cosine   \n",
              "6           64  0.002033        0.0000        0.5  ...     cosine   \n",
              "\n",
              "    val_best_MRR      loss        ppl     Top@1     Top@3     Top@5       MRR  \\\n",
              "16      0.603018  2.236275   9.358407  0.451197  0.699480  0.779188  0.597337   \n",
              "8       0.601694  2.324085  10.217326  0.449844  0.693132  0.777836  0.594969   \n",
              "12      0.607986  2.329090  10.268592  0.449116  0.691675  0.777523  0.594903   \n",
              "1       0.604191  2.339745  10.378589  0.448595  0.695317  0.775338  0.594343   \n",
              "4       0.604717  2.333321  10.312136  0.449324  0.693548  0.775442  0.594256   \n",
              "11      0.604657  2.379006  10.794168  0.450156  0.692404  0.770552  0.594072   \n",
              "9       0.604258  2.323171  10.207992  0.448179  0.693132  0.776067  0.594039   \n",
              "17      0.600129  2.292265   9.897333  0.449948  0.689594  0.769615  0.593399   \n",
              "18      0.604553  2.290088   9.875811  0.444778  0.692007  0.773373  0.590615   \n",
              "6       0.603992  2.363687  10.630075  0.444647  0.688747  0.774547  0.590102   \n",
              "\n",
              "    n_test                               ckpt  \n",
              "16    9610  /content/models_rs/rs_trial_17.pt  \n",
              "8     9610   /content/models_rs/rs_trial_9.pt  \n",
              "12    9610  /content/models_rs/rs_trial_13.pt  \n",
              "1     9610   /content/models_rs/rs_trial_2.pt  \n",
              "4     9610   /content/models_rs/rs_trial_5.pt  \n",
              "11    9610  /content/models_rs/rs_trial_12.pt  \n",
              "9     9610  /content/models_rs/rs_trial_10.pt  \n",
              "17    9610  /content/models_rs/rs_trial_18.pt  \n",
              "18    7669  /content/models_rs/rs_trial_19.pt  \n",
              "6     7669   /content/models_rs/rs_trial_7.pt  \n",
              "\n",
              "[10 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52d44298-7681-44f0-98f6-3d423dae6582\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trial</th>\n",
              "      <th>embedding_dim</th>\n",
              "      <th>hidden_size</th>\n",
              "      <th>num_layers</th>\n",
              "      <th>dropout</th>\n",
              "      <th>seq_len</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>lr</th>\n",
              "      <th>weight_decay</th>\n",
              "      <th>grad_clip</th>\n",
              "      <th>...</th>\n",
              "      <th>scheduler</th>\n",
              "      <th>val_best_MRR</th>\n",
              "      <th>loss</th>\n",
              "      <th>ppl</th>\n",
              "      <th>Top@1</th>\n",
              "      <th>Top@3</th>\n",
              "      <th>Top@5</th>\n",
              "      <th>MRR</th>\n",
              "      <th>n_test</th>\n",
              "      <th>ckpt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>192</td>\n",
              "      <td>320</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0.001371</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.603018</td>\n",
              "      <td>2.236275</td>\n",
              "      <td>9.358407</td>\n",
              "      <td>0.451197</td>\n",
              "      <td>0.699480</td>\n",
              "      <td>0.779188</td>\n",
              "      <td>0.597337</td>\n",
              "      <td>9610</td>\n",
              "      <td>/content/models_rs/rs_trial_17.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>160</td>\n",
              "      <td>256</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>0.000816</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.601694</td>\n",
              "      <td>2.324085</td>\n",
              "      <td>10.217326</td>\n",
              "      <td>0.449844</td>\n",
              "      <td>0.693132</td>\n",
              "      <td>0.777836</td>\n",
              "      <td>0.594969</td>\n",
              "      <td>9610</td>\n",
              "      <td>/content/models_rs/rs_trial_9.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>160</td>\n",
              "      <td>256</td>\n",
              "      <td>2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0.004496</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.607986</td>\n",
              "      <td>2.329090</td>\n",
              "      <td>10.268592</td>\n",
              "      <td>0.449116</td>\n",
              "      <td>0.691675</td>\n",
              "      <td>0.777523</td>\n",
              "      <td>0.594903</td>\n",
              "      <td>9610</td>\n",
              "      <td>/content/models_rs/rs_trial_13.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>256</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>0.001601</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.604191</td>\n",
              "      <td>2.339745</td>\n",
              "      <td>10.378589</td>\n",
              "      <td>0.448595</td>\n",
              "      <td>0.695317</td>\n",
              "      <td>0.775338</td>\n",
              "      <td>0.594343</td>\n",
              "      <td>9610</td>\n",
              "      <td>/content/models_rs/rs_trial_2.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>160</td>\n",
              "      <td>256</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0.001889</td>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.604717</td>\n",
              "      <td>2.333321</td>\n",
              "      <td>10.312136</td>\n",
              "      <td>0.449324</td>\n",
              "      <td>0.693548</td>\n",
              "      <td>0.775442</td>\n",
              "      <td>0.594256</td>\n",
              "      <td>9610</td>\n",
              "      <td>/content/models_rs/rs_trial_5.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>192</td>\n",
              "      <td>320</td>\n",
              "      <td>2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>16</td>\n",
              "      <td>128</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.604657</td>\n",
              "      <td>2.379006</td>\n",
              "      <td>10.794168</td>\n",
              "      <td>0.450156</td>\n",
              "      <td>0.692404</td>\n",
              "      <td>0.770552</td>\n",
              "      <td>0.594072</td>\n",
              "      <td>9610</td>\n",
              "      <td>/content/models_rs/rs_trial_12.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>128</td>\n",
              "      <td>256</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0.003952</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.604258</td>\n",
              "      <td>2.323171</td>\n",
              "      <td>10.207992</td>\n",
              "      <td>0.448179</td>\n",
              "      <td>0.693132</td>\n",
              "      <td>0.776067</td>\n",
              "      <td>0.594039</td>\n",
              "      <td>9610</td>\n",
              "      <td>/content/models_rs/rs_trial_10.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>128</td>\n",
              "      <td>320</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>16</td>\n",
              "      <td>64</td>\n",
              "      <td>0.001938</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.600129</td>\n",
              "      <td>2.292265</td>\n",
              "      <td>9.897333</td>\n",
              "      <td>0.449948</td>\n",
              "      <td>0.689594</td>\n",
              "      <td>0.769615</td>\n",
              "      <td>0.593399</td>\n",
              "      <td>9610</td>\n",
              "      <td>/content/models_rs/rs_trial_18.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>128</td>\n",
              "      <td>320</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>24</td>\n",
              "      <td>64</td>\n",
              "      <td>0.000949</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.604553</td>\n",
              "      <td>2.290088</td>\n",
              "      <td>9.875811</td>\n",
              "      <td>0.444778</td>\n",
              "      <td>0.692007</td>\n",
              "      <td>0.773373</td>\n",
              "      <td>0.590615</td>\n",
              "      <td>7669</td>\n",
              "      <td>/content/models_rs/rs_trial_19.pt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>128</td>\n",
              "      <td>384</td>\n",
              "      <td>2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>24</td>\n",
              "      <td>64</td>\n",
              "      <td>0.002033</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>...</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.603992</td>\n",
              "      <td>2.363687</td>\n",
              "      <td>10.630075</td>\n",
              "      <td>0.444647</td>\n",
              "      <td>0.688747</td>\n",
              "      <td>0.774547</td>\n",
              "      <td>0.590102</td>\n",
              "      <td>7669</td>\n",
              "      <td>/content/models_rs/rs_trial_7.pt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52d44298-7681-44f0-98f6-3d423dae6582')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52d44298-7681-44f0-98f6-3d423dae6582 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52d44298-7681-44f0-98f6-3d423dae6582');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a6b34a58-6bca-4164-ac66-fc8f44c0eb09\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6b34a58-6bca-4164-ac66-fc8f44c0eb09')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a6b34a58-6bca-4164-ac66-fc8f44c0eb09 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados guardados en: /content/models_rs/random_search_results.csv\n",
            "\n",
            "=== MEJOR ENSAYO (por MRR en test) ===\n",
            "Config: {'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0013711030226214714, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.03, 'tie_weights': True, 'scheduler': 'cosine'}\n",
            "Metrics (test): {'loss': 2.236275031737805, 'ppl': 9.358406513740468, 'Top@1': 0.45119667014147813, 'Top@3': 0.6994797086368366, 'Top@5': 0.7791883455106793, 'MRR': 0.5973372343427557}\n",
            "Checkpoint: /content/models_rs/rs_trial_17.pt\n"
          ]
        }
      ],
      "source": [
        "import math, time, copy, random, os, gc\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import torch.nn as nn\n",
        "\n",
        "# Configuración base para el Random Search\n",
        "base_epochs = 6\n",
        "base_amp = True\n",
        "base_save_dir = \"/content/models_rs\"\n",
        "\n",
        "# Parámetros de scheduler (para OneCycle, aunque usaremos cosine por defecto)\n",
        "base_pct_start = 0.15\n",
        "base_div_factor = 10.0\n",
        "base_final_div_factor = 1e3\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def log_uniform(a,b):\n",
        "    return math.exp(random.uniform(math.log(a), math.log(b)))\n",
        "\n",
        "def sample_cfg():\n",
        "    \"\"\"Genera una configuración aleatoria para Random Search\"\"\"\n",
        "    cfg_local = {}\n",
        "\n",
        "    # Arquitectura del modelo\n",
        "    cfg_local[\"embedding_dim\"]   = random.choice([128,160,192])\n",
        "    cfg_local[\"hidden_size\"]     = random.choice([256,320,384])\n",
        "    cfg_local[\"num_layers\"]      = random.choice([1,2])\n",
        "    cfg_local[\"dropout\"]         = random.choice([0.2,0.3])\n",
        "\n",
        "    # Optimización\n",
        "    cfg_local[\"lr\"]              = log_uniform(5e-4, 5e-3)\n",
        "    cfg_local[\"weight_decay\"]    = random.choice([0.0, 1e-4, 5e-4])\n",
        "    cfg_local[\"grad_clip\"]       = random.choice([0.5, 1.0])\n",
        "\n",
        "    # Datos y entrenamiento\n",
        "    cfg_local[\"batch_size\"]      = random.choice([64, 128])\n",
        "    cfg_local[\"seq_len\"]         = random.choice([16, 24])\n",
        "\n",
        "    # Regularización\n",
        "    cfg_local[\"label_smoothing\"] = random.choice([0.03, 0.05])\n",
        "    cfg_local[\"tie_weights\"]     = True # fijado por pruebas A/B\n",
        "\n",
        "    # Scheduler (fijado por pruebas A/B)\n",
        "    cfg_local[\"scheduler\"] = \"cosine\"\n",
        "\n",
        "    # Parámetros de entrenamiento (fijos)\n",
        "    cfg_local[\"epochs\"]   = base_epochs\n",
        "    cfg_local[\"patience\"] = 2\n",
        "    cfg_local[\"amp\"]      = base_amp\n",
        "\n",
        "    # OneCycle params (no aplican con cosine, pero mantenemos por compatibilidad)\n",
        "    cfg_local[\"pct_start\"]      = base_pct_start\n",
        "    cfg_local[\"div_factor\"]     = base_div_factor\n",
        "    cfg_local[\"final_div_factor\"]= base_final_div_factor\n",
        "\n",
        "    return cfg_local\n",
        "\n",
        "RESULTS = []\n",
        "BEST = {\"mrr\": -1, \"path\": None, \"cfg\": None, \"test\": None}\n",
        "\n",
        "N_TRIALS = 20  # n combinaciones a probar\n",
        "\n",
        "for t in range(1, N_TRIALS+1):\n",
        "    trial_cfg = sample_cfg()\n",
        "    print(f\"\\n=== TRIAL {t}/{N_TRIALS} ===\")\n",
        "    print({k:trial_cfg[k] for k in [\"embedding_dim\",\"hidden_size\",\"num_layers\",\"dropout\",\n",
        "                                     \"seq_len\",\"batch_size\",\"lr\",\"weight_decay\",\"grad_clip\",\n",
        "                                     \"label_smoothing\"]}),\n",
        "\n",
        "\n",
        "    # DataLoaders específicos del trial\n",
        "    train_loader_t, val_loader_t, test_loader_t, n_test = make_dataloaders(\n",
        "        train_seqs, val_seqs, test_seqs,\n",
        "        seq_len=trial_cfg[\"seq_len\"], batch_size=trial_cfg[\"batch_size\"]\n",
        "    )\n",
        "\n",
        "    # Modelo para el trial\n",
        "    model_t = ChordLSTM(vocab_size=len(vocab),\n",
        "                        embedding_dim=trial_cfg[\"embedding_dim\"],\n",
        "                        hidden_size=trial_cfg[\"hidden_size\"],\n",
        "                        num_layers=trial_cfg[\"num_layers\"],\n",
        "                        dropout=trial_cfg[\"dropout\"],\n",
        "                        tie_weights=trial_cfg[\"tie_weights\"]).to(device)\n",
        "\n",
        "    # Entrenamiento con early stopping por MRR (val)\n",
        "    save_path = os.path.join(base_save_dir, f\"rs_trial_{t}.pt\")\n",
        "    best_mrr_val = train_once(\n",
        "        model_t, train_loader_t, val_loader_t,\n",
        "        epochs=trial_cfg[\"epochs\"], lr=trial_cfg[\"lr\"], weight_decay=trial_cfg[\"weight_decay\"],\n",
        "        grad_clip=trial_cfg[\"grad_clip\"], amp=trial_cfg[\"amp\"],\n",
        "        save_path=save_path, label_smoothing=trial_cfg[\"label_smoothing\"],\n",
        "        patience=trial_cfg[\"patience\"], device=device,\n",
        "        scheduler_type=trial_cfg[\"scheduler\"],\n",
        "        pct_start=trial_cfg[\"pct_start\"], div_factor=trial_cfg[\"div_factor\"],\n",
        "        final_div_factor=trial_cfg[\"final_div_factor\"]\n",
        "    )\n",
        "\n",
        "    # Evaluación en test (coherente con training)\n",
        "    test_crit = nn.CrossEntropyLoss(label_smoothing=trial_cfg[\"label_smoothing\"])\n",
        "    testm = evaluate(model_t, test_loader_t, test_crit, device)\n",
        "\n",
        "\n",
        "    row = {\"trial\": t, **{k:trial_cfg[k] for k in [\"embedding_dim\",\"hidden_size\",\"num_layers\",\"dropout\",\n",
        "                                                   \"seq_len\",\"batch_size\",\"lr\",\"weight_decay\",\"grad_clip\",\n",
        "                                                   \"label_smoothing\",\"tie_weights\"]},\n",
        "           \"tie_weights\": True, \"scheduler\": \"cosine\",\n",
        "           \"val_best_MRR\": best_mrr_val,\n",
        "           **{k:testm[k] for k in [\"loss\",\"ppl\",\"Top@1\",\"Top@3\",\"Top@5\",\"MRR\"]},\n",
        "           \"n_test\": n_test, \"ckpt\": save_path}\n",
        "    RESULTS.append(row)\n",
        "\n",
        "    # Track best por MRR (test)\n",
        "    if testm[\"MRR\"] > BEST[\"mrr\"]:\n",
        "        BEST = {\"mrr\": testm[\"MRR\"], \"path\": save_path, \"cfg\": trial_cfg, \"test\": testm}\n",
        "\n",
        "    # Limpieza\n",
        "    del model_t; gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# Mostrar resultados\n",
        "df_rs = pd.DataFrame(RESULTS).sort_values(by=\"MRR\", ascending=False)\n",
        "print(\"Top 10 trials por MRR (test):\")\n",
        "display(df_rs.head(10))\n",
        "\n",
        "# Guardar CSV con todos los ensayos\n",
        "os.makedirs(base_save_dir, exist_ok=True)\n",
        "csv_path = os.path.join(base_save_dir, \"random_search_results.csv\")\n",
        "df_rs.to_csv(csv_path, index=False)\n",
        "print(\"Resultados guardados en:\", csv_path)\n",
        "\n",
        "print(\"\\n=== MEJOR ENSAYO (por MRR en test) ===\")\n",
        "print(\"Config:\", {k:BEST[\"cfg\"][k] for k in [\"embedding_dim\",\"hidden_size\",\"num_layers\",\"dropout\",\n",
        "                                             \"seq_len\",\"batch_size\",\"lr\",\"weight_decay\",\"grad_clip\",\n",
        "                                             \"label_smoothing\",\"tie_weights\", \"scheduler\"]})\n",
        "print(\"Metrics (test):\", BEST[\"test\"])\n",
        "print(\"Checkpoint:\", BEST[\"path\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kC-VAPg7GUqN",
      "metadata": {
        "id": "kC-VAPg7GUqN"
      },
      "source": [
        "warnings a revisar:\n",
        "/tmp/ipython-input-1199272555.py:31: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
        "  scaler = torch.cuda.amp.GradScaler(enabled=(amp and device.type=='cuda'))\n",
        "/tmp/ipython-input-1199272555.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
        "  with torch.cuda.amp.autocast(enabled=(amp and device.type=='cuda')):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mM7TDYxgGUqO",
      "metadata": {
        "id": "mM7TDYxgGUqO"
      },
      "source": [
        "## 10) Empaquetar el mejor checkpoint con metadatos y nombre informativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "JJkYWRjYUDwZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJkYWRjYUDwZ",
        "outputId": "35f18248-6fc3-4362-a0d7-849f24df7edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reentrenando config: {'embedding_dim': 192, 'hidden_size': 320, 'num_layers': 2, 'dropout': 0.3, 'seq_len': 16, 'batch_size': 64, 'lr': 0.0013711030226214, 'weight_decay': 0.0005, 'grad_clip': 1.0, 'label_smoothing': 0.03, 'tie_weights': True, 'scheduler': 'cosine'}\n",
            "Epoch 1 | val loss 2.3647 ppl 10.64 Top@1 0.421 Top@3 0.661 Top@5 0.753 MRR 0.569\n",
            "Epoch 2 | val loss 2.2803 ppl 9.78 Top@1 0.450 Top@3 0.686 Top@5 0.769 MRR 0.593\n",
            "Epoch 3 | val loss 2.2436 ppl 9.43 Top@1 0.451 Top@3 0.692 Top@5 0.777 MRR 0.597\n",
            "Epoch 4 | val loss 2.2281 ppl 9.28 Top@1 0.461 Top@3 0.697 Top@5 0.777 MRR 0.603\n",
            "Epoch 5 | val loss 2.2200 ppl 9.21 Top@1 0.466 Top@3 0.696 Top@5 0.781 MRR 0.606\n",
            "Epoch 6 | val loss 2.2258 ppl 9.26 Top@1 0.467 Top@3 0.697 Top@5 0.778 MRR 0.606\n",
            "Test: {'loss': 2.256385751321338, 'ppl': 9.548516015025047, 'Top@1': 0.44443288242655665, 'Top@3': 0.6949011446534037, 'Top@5': 0.7798126951464753, 'MRR': 0.5928952473135322}\n",
            "✅ Guardado\n",
            " ├ OUT 1: ./lstm_rs_best__Top1-0.4444_MRR-0.5929_ppl-9.549.pt\n",
            " └ OUT 2: ./lstm_rs_best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1293656442.py:77: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  \"created_at\": datetime.datetime.utcnow().isoformat() + \"Z\",\n"
          ]
        }
      ],
      "source": [
        "# === Re-entrenar SOLO el mejor trial del CSV y exportar ===\n",
        "import os, json, sys, datetime, torch, pandas as pd\n",
        "import torch.nn as nn\n",
        "\n",
        "# Rutas de archivos\n",
        "CSV_PATH = \"models_rs/random_search_results.csv\"\n",
        "TOKENIZER_PATH = \"lstm_tokenizer.json\"\n",
        "\n",
        "# 1) Leer mejor fila por MRR\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "best = df.sort_values(\"MRR\", ascending=False).iloc[0]\n",
        "\n",
        "cfg_best = {\n",
        "    \"embedding_dim\":   int(best[\"embedding_dim\"]),\n",
        "    \"hidden_size\":     int(best[\"hidden_size\"]),\n",
        "    \"num_layers\":      int(best[\"num_layers\"]),\n",
        "    \"dropout\":         float(best[\"dropout\"]),\n",
        "    \"seq_len\":         int(best[\"seq_len\"]),\n",
        "    \"batch_size\":      int(best[\"batch_size\"]),\n",
        "    \"lr\":              float(best[\"lr\"]),\n",
        "    \"weight_decay\":    float(best[\"weight_decay\"]),\n",
        "    \"grad_clip\":       float(best[\"grad_clip\"]),\n",
        "    \"label_smoothing\": float(best[\"label_smoothing\"]),\n",
        "    \"tie_weights\":     bool(best.get(\"tie_weights\", True)),\n",
        "    \"scheduler\":       str(best.get(\"scheduler\", \"cosine\")),\n",
        "}\n",
        "\n",
        "print(\"Reentrenando config:\", cfg_best)\n",
        "\n",
        "# 2) Dataloaders con la config ganadora (usa las funciones ya definidas)\n",
        "train_loader, val_loader, test_loader, n_test = make_dataloaders(\n",
        "    train_seqs, val_seqs, test_seqs,\n",
        "    seq_len=cfg_best[\"seq_len\"], batch_size=cfg_best[\"batch_size\"]\n",
        ")\n",
        "\n",
        "# 3) Modelo\n",
        "model = ChordLSTM(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=cfg_best[\"embedding_dim\"],\n",
        "    hidden_size=cfg_best[\"hidden_size\"],\n",
        "    num_layers=cfg_best[\"num_layers\"],\n",
        "    dropout=cfg_best[\"dropout\"],\n",
        "    tie_weights=cfg_best[\"tie_weights\"]\n",
        ").to(device)\n",
        "\n",
        "# 4) Entrenar con el mismo esquema (early stop por MRR)\n",
        "_ = train_once(\n",
        "    model, train_loader, val_loader,\n",
        "    epochs=base_epochs, lr=cfg_best[\"lr\"], weight_decay=cfg_best[\"weight_decay\"],\n",
        "    grad_clip=cfg_best[\"grad_clip\"], amp=base_amp,\n",
        "    save_path=None, label_smoothing=cfg_best[\"label_smoothing\"],\n",
        "    patience=2, device=device,\n",
        "    scheduler_type=cfg_best[\"scheduler\"], pct_start=base_pct_start,\n",
        "    div_factor=base_div_factor, final_div_factor=base_final_div_factor\n",
        ")\n",
        "\n",
        "# 5) Test coherente con el training\n",
        "test_crit = nn.CrossEntropyLoss(label_smoothing=cfg_best[\"label_smoothing\"])\n",
        "testm = evaluate(model, test_loader, test_crit, device)\n",
        "print(\"Test:\", testm)\n",
        "\n",
        "# 6) Exportar con vocab del tokenizer (reproducible)\n",
        "with open(TOKENIZER_PATH, \"r\") as f:\n",
        "    tok = json.load(f)\n",
        "vocab = tok[\"vocab\"]\n",
        "stoi = {t:i for i,t in enumerate(vocab)}\n",
        "itos = {i:t for i,t in enumerate(vocab)}\n",
        "\n",
        "export = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"model_class\": \"ChordLSTM\",\n",
        "    \"config\": cfg_best,\n",
        "    \"metrics_test\": testm,\n",
        "    \"stoi\": stoi,\n",
        "    \"itos\": itos,\n",
        "    \"vocab_size\": len(stoi),\n",
        "    \"created_at\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
        "    \"env\": {\"python\": sys.version, \"torch\": torch.__version__, \"cuda_available\": torch.cuda.is_available()},\n",
        "}\n",
        "\n",
        "out_dir = \".\"\n",
        "name_info = f\"Top1-{testm['Top@1']:.4f}_MRR-{testm['MRR']:.4f}_ppl-{testm['ppl']:.3f}\"\n",
        "best_named = os.path.join(out_dir, f\"lstm_rs_best__{name_info}.pt\")\n",
        "stable_best = os.path.join(out_dir, \"lstm_rs_best.pt\")\n",
        "\n",
        "torch.save(export, best_named)\n",
        "torch.save(export, stable_best)\n",
        "\n",
        "print(\"✅ Guardado\")\n",
        "print(\" ├ OUT 1:\", best_named)\n",
        "print(\" └ OUT 2:\", stable_best)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}