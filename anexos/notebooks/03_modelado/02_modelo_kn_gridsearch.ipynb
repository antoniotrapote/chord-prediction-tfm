{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184a8d5a",
   "metadata": {},
   "source": [
    "# Kneser–Ney + GridSearch\n",
    "Este notebook implementa una mejora del baseline model KN sobre **progresiones funcionales** a partir de `songdb_funcional_v4.csv`:\n",
    "\n",
    "- **Modelo n-grama con Kneser–Ney (n-gramas)** sobre tokens funcionales (e.g., `I`, `ii`, `V7`, `bVII7`), con `<unk>` para raros y límites `<s>`, `</s>`.\n",
    "- **Busqueda de mejoras**: se exploran diferentes configuraciones de hiperparámetros (orden, D) para optimizar el rendimiento del modelo.\n",
    "\n",
    "Se evalúa **predicción del siguiente acorde** con **Top-k** y **MRR**, con partición **train/val/test por canción**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53882b3",
   "metadata": {},
   "source": [
    "## 1) Carga de los datos\n",
    "Leemos el CSV y preparamos las secuencias de tokens por canción. Usamos `title` + `composedby` como ID de canción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4cd7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b12c91c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2591,\n",
       " ['Lullaby of Birdland — George Shearing',\n",
       "  \"It's A Most Unusual Day — Jimmy McHugh and HYarold Adamson\",\n",
       "  'Jump Monk — Charles Mingus'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importamos el dataset de canciones con las progresiones funcionales\n",
    "csv_path = Path(\"../../data/songdb_funcional_v4.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "def tokenize_progression(prog: str):\n",
    "    \"\"\"\n",
    "    Tokeniza una progresión en acordes separados\n",
    "    \"\"\"\n",
    "    if pd.isna(prog):\n",
    "        return []\n",
    "    return [t for t in str(prog).strip().split() if t]\n",
    "\n",
    "def build_sequences_by_song(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Construye secuencias de acordes por canción a partir del DataFrame.\n",
    "    \"\"\"\n",
    "    if \"title\" in df.columns and \"composedby\" in df.columns:\n",
    "        song_ids = (df[\"title\"].astype(str) + \" — \" + df[\"composedby\"].astype(str)).tolist()\n",
    "    elif \"title\" in df.columns:\n",
    "        song_ids = df[\"title\"].astype(str).tolist()\n",
    "    else:\n",
    "        song_ids = [f\"song_{i}\" for i in range(len(df))]\n",
    "    seqs = {}\n",
    "    for sid, prog in zip(song_ids, df[\"funcional_prog\"].tolist()):\n",
    "        seqs[sid] = tokenize_progression(prog)\n",
    "    return seqs\n",
    "\n",
    "seqs = build_sequences_by_song(df)\n",
    "seqs = {k:v for k,v in seqs.items() if len(v) >= 3}\n",
    "len(seqs), list(seqs)[:3]  # tamaño y primeras claves\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f268e8b",
   "metadata": {},
   "source": [
    "## 2) Partición train/val/test por canción\n",
    "Usamos 80/10/10 con barajado determinista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ee5ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2072, 259, 260)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rng = np.random.default_rng(42)\n",
    "song_list = list(seqs.keys())\n",
    "rng.shuffle(song_list)\n",
    "\n",
    "n = len(song_list)\n",
    "n_train = int(n * 0.8)\n",
    "n_val   = int(n * 0.1)\n",
    "train_ids = song_list[:n_train]\n",
    "val_ids   = song_list[n_train:n_train+n_val]\n",
    "test_ids  = song_list[n_train+n_val:]\n",
    "\n",
    "train_seqs = [seqs[sid] for sid in train_ids]\n",
    "val_seqs   = [seqs[sid] for sid in val_ids]\n",
    "test_seqs  = [seqs[sid] for sid in test_ids]\n",
    "\n",
    "len(train_seqs), len(val_seqs), len(test_seqs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbcceb0",
   "metadata": {},
   "source": [
    "## 3) Kneser–Ney genérico (orden N) + grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b487f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === KN interpolado genérico (orden N) ===\n",
    "from collections import Counter, defaultdict\n",
    "from functools import lru_cache\n",
    "\n",
    "class KNInterpolatedNGram:\n",
    "    def __init__(self, order=3, discount=0.75, unk_threshold=1):\n",
    "        assert order >= 1\n",
    "        self.N = order\n",
    "        self.D = discount\n",
    "        self.unk_threshold = unk_threshold\n",
    "        self.vocab = set()\n",
    "        self.counts = {n: Counter() for n in range(1, self.N+1)}      # n-gram counts\n",
    "        self.context_totals = {n: Counter() for n in range(1, self.N)} # c(context)\n",
    "        self.unique_continuations = {n: Counter() for n in range(1, self.N)}  # N1+(context •)\n",
    "        self.continuation_counts_unigram = Counter()  # N1+(• w)\n",
    "        self.total_unique_bigrams = 0\n",
    "        self._rank_cache = {}\n",
    "        self._prob_cache = {}\n",
    "        self.fitted = False\n",
    "\n",
    "    def _add_bounds(self, seq):\n",
    "        \"\"\"\n",
    "        Añade marcas de comienzo y fin. \"<s>\" y \"</s>\"\n",
    "        \"\"\"\n",
    "        return [\"<s>\"]*(self.N-1) + seq + [\"</s>\"]\n",
    "\n",
    "    def fit(self, sequences):\n",
    "        \"\"\"\n",
    "        Ajusta el modelo a las secuencias de entrenamiento.\n",
    "        \"\"\"\n",
    "        token_counts = Counter(t for seq in sequences for t in seq)\n",
    "        vocab = set([t for t,c in token_counts.items() if c > self.unk_threshold])\n",
    "        vocab.update({\"<s>\",\"</s>\",\"<unk>\"})\n",
    "        self.vocab = vocab\n",
    "\n",
    "        def map_unk(seq): \n",
    "            return [t if t in vocab else \"<unk>\" for t in seq]\n",
    "\n",
    "        for seq in sequences:\n",
    "            s = self._add_bounds(map_unk(seq))\n",
    "            for i in range(len(s)):\n",
    "                for n in range(1, self.N+1):\n",
    "                    if i-n+1 < 0: \n",
    "                        continue\n",
    "                    ngram = tuple(s[i-n+1:i+1])\n",
    "                    self.counts[n][ngram] += 1\n",
    "\n",
    "        # context totals + unique continuations\n",
    "        for n in range(2, self.N+1):\n",
    "            seen = defaultdict(set)\n",
    "            for ngram, c in self.counts[n].items():\n",
    "                ctx, w = ngram[:-1], ngram[-1]\n",
    "                self.context_totals[n-1][ctx] += c\n",
    "                seen[ctx].add(w)\n",
    "            for ctx, ws in seen.items():\n",
    "                self.unique_continuations[n-1][ctx] = len(ws)\n",
    "\n",
    "        # unigram continuation counts\n",
    "        left_contexts = defaultdict(set)\n",
    "        for (w1, w2) in self.counts[2].keys():\n",
    "            left_contexts[w2].add(w1)\n",
    "        self.continuation_counts_unigram = Counter({w: len(ctxs) for w, ctxs in left_contexts.items()})\n",
    "        self.total_unique_bigrams = len(self.counts[2])\n",
    "        self.fitted = True\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def _p_cont_unigram(self, w):\n",
    "        if self.total_unique_bigrams == 0:\n",
    "            return 1.0 / max(1, len(self.vocab))\n",
    "        return self.continuation_counts_unigram.get(w, 0) / self.total_unique_bigrams\n",
    "\n",
    "    def _lambda(self, ctx):\n",
    "        m = len(ctx)\n",
    "        if m == 0:\n",
    "            return 1.0\n",
    "        cont_types = self.unique_continuations[m].get(ctx, 0)\n",
    "        total = self.context_totals[m].get(ctx, 0)\n",
    "        if total == 0:\n",
    "            return 1.0\n",
    "        return (self.D * cont_types) / total\n",
    "\n",
    "    def _base(self, ctx, w):\n",
    "        m = len(ctx)\n",
    "        if m == 0:\n",
    "            return self._p_cont_unigram(w)\n",
    "        total = self.context_totals[m].get(ctx, 0)\n",
    "        c = self.counts[m+1].get(tuple(list(ctx)+[w]), 0)\n",
    "        if total == 0:\n",
    "            return 0.0\n",
    "        return max(c - self.D, 0) / total\n",
    "\n",
    "    def prob(self, ctx, w):\n",
    "        key = (ctx, w)\n",
    "        if key in self._prob_cache:\n",
    "            return self._prob_cache[key]\n",
    "        m = len(ctx)\n",
    "        if m == 0:\n",
    "            p = self._p_cont_unigram(w)\n",
    "        else:\n",
    "            p = self._base(ctx, w) + self._lambda(ctx) * self.prob(ctx[1:], w)\n",
    "        self._prob_cache[key] = p\n",
    "        return p\n",
    "\n",
    "    def predict_ranking(self, history):\n",
    "        # mapeo a <unk> interno para usar directamente evaluate_next_token_ranking(...)\n",
    "        hist = [\"<s>\"]*(self.N-1) + [t if t in self.vocab else \"<unk>\" for t in history]\n",
    "        ctx = tuple(hist[-(self.N-1):]) if self.N > 1 else tuple()\n",
    "        if ctx in self._rank_cache:\n",
    "            return self._rank_cache[ctx]\n",
    "        cands = [w for w in self.vocab if w not in {\"<s>\"}]\n",
    "        scores = [(w, self.prob(ctx, w)) for w in cands]\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        self._rank_cache[ctx] = scores\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babff49e",
   "metadata": {},
   "source": [
    "## 4) KN + Grid search\n",
    "Parametros a probar: orden {3, 4}, D {0.5, 0.7, 0.75, 0.9, 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4dd5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_next_token_ranking(model, test_sequences, topk_list=(1,3,5)):\n",
    "    total_positions = 0\n",
    "    topk_hits = {k: 0 for k in topk_list}\n",
    "    mrr_sum = 0.0\n",
    "    for seq in test_sequences:\n",
    "        for i in range(len(seq)-1):\n",
    "            history = seq[:i+1]\n",
    "            gold = seq[i+1]\n",
    "            ranking = model.predict_ranking(history)\n",
    "            ranks = {w: r+1 for r, (w, _) in enumerate(ranking)}\n",
    "            rank_gold = ranks.get(gold, None)\n",
    "            total_positions += 1\n",
    "            if rank_gold is not None:\n",
    "                for k in topk_list:\n",
    "                    if rank_gold <= k:\n",
    "                        topk_hits[k] += 1\n",
    "                mrr_sum += 1.0 / rank_gold\n",
    "    results = {\n",
    "        \"positions\": total_positions,\n",
    "        \"MRR\": mrr_sum / total_positions if total_positions > 0 else 0.0,\n",
    "    }\n",
    "    for k in topk_list:\n",
    "        results[f\"Top@{k}\"] = topk_hits[k] / total_positions if total_positions > 0 else 0.0\n",
    "    return results\n",
    "\n",
    "class KNWrapperForEval:\n",
    "    def __init__(self, kn_model):\n",
    "        self.kn = kn_model\n",
    "    def predict_ranking(self, history):\n",
    "        hist = [t if t in self.kn.vocab else \"<unk>\" for t in history]\n",
    "        return self.kn.predict_ranking(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7846d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>D</th>\n",
       "      <th>positions</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Top@1</th>\n",
       "      <th>Top@3</th>\n",
       "      <th>Top@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.90</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.597218</td>\n",
       "      <td>0.465712</td>\n",
       "      <td>0.680181</td>\n",
       "      <td>0.762396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.596795</td>\n",
       "      <td>0.464883</td>\n",
       "      <td>0.679653</td>\n",
       "      <td>0.762321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.595597</td>\n",
       "      <td>0.463225</td>\n",
       "      <td>0.678598</td>\n",
       "      <td>0.759834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.594594</td>\n",
       "      <td>0.462472</td>\n",
       "      <td>0.676488</td>\n",
       "      <td>0.758855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.590907</td>\n",
       "      <td>0.457950</td>\n",
       "      <td>0.672720</td>\n",
       "      <td>0.755991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.582862</td>\n",
       "      <td>0.444838</td>\n",
       "      <td>0.663904</td>\n",
       "      <td>0.760060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.582846</td>\n",
       "      <td>0.444537</td>\n",
       "      <td>0.663301</td>\n",
       "      <td>0.758930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.582747</td>\n",
       "      <td>0.445139</td>\n",
       "      <td>0.663376</td>\n",
       "      <td>0.759156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.582426</td>\n",
       "      <td>0.444461</td>\n",
       "      <td>0.662547</td>\n",
       "      <td>0.758176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>13270</td>\n",
       "      <td>0.581306</td>\n",
       "      <td>0.443406</td>\n",
       "      <td>0.661115</td>\n",
       "      <td>0.757046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order     D  positions       MRR     Top@1     Top@3     Top@5\n",
       "0      4  0.90      13270  0.597218  0.465712  0.680181  0.762396\n",
       "1      4  1.00      13270  0.596795  0.464883  0.679653  0.762321\n",
       "2      4  0.75      13270  0.595597  0.463225  0.678598  0.759834\n",
       "3      4  0.70      13270  0.594594  0.462472  0.676488  0.758855\n",
       "4      4  0.50      13270  0.590907  0.457950  0.672720  0.755991\n",
       "5      3  0.90      13270  0.582862  0.444838  0.663904  0.760060\n",
       "6      3  0.75      13270  0.582846  0.444537  0.663301  0.758930\n",
       "7      3  1.00      13270  0.582747  0.445139  0.663376  0.759156\n",
       "8      3  0.70      13270  0.582426  0.444461  0.662547  0.758176\n",
       "9      3  0.50      13270  0.581306  0.443406  0.661115  0.757046"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor configuración (val): {'order': 4, 'D': 0.9, 'positions': 13270, 'MRR': 0.5972178067596974, 'Top@1': 0.46571213262999245, 'Top@3': 0.680180859080633, 'Top@5': 0.7623963828183873}\n"
     ]
    }
   ],
   "source": [
    "# === Grid search en validación y evaluación en test ===\n",
    "import pandas as pd\n",
    "\n",
    "def grid_search_kn(train_seqs, val_seqs, orders=(3,4), Ds=(0.5,0.7,0.75,0.9,1.0), unk_threshold=1, subsample_val=None):\n",
    "    if subsample_val is not None:\n",
    "        val_seqs = val_seqs[:subsample_val]\n",
    "    rows = []\n",
    "    best = None\n",
    "    best_model = None\n",
    "    for N in orders:\n",
    "        for D in Ds:\n",
    "            kn = KNInterpolatedNGram(order=N, discount=D, unk_threshold=unk_threshold)\n",
    "            kn.fit(train_seqs)\n",
    "            metrics = evaluate_next_token_ranking(kn, val_seqs, topk_list=(1,3,5))\n",
    "            row = {\"order\": N, \"D\": D, **metrics}\n",
    "            rows.append(row)\n",
    "            if (best is None) or (metrics[\"MRR\"] > best[\"MRR\"]):\n",
    "                best, best_model = row, kn\n",
    "    val_table = pd.DataFrame(rows).sort_values(\"MRR\", ascending=False).reset_index(drop=True)\n",
    "    display(val_table)\n",
    "    print(\"Mejor configuración (val):\", best)\n",
    "    return best_model, best, val_table\n",
    "\n",
    "# Ejecuta búsqueda (puedes ajustar subsample_val si quieres acelerar una primera pasada)\n",
    "best_kn, best_cfg, kn_val_table = grid_search_kn(train_seqs, val_seqs, orders=(3,4), Ds=(0.5,0.7,0.75,0.9,1.0), subsample_val=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984157df",
   "metadata": {},
   "source": [
    "## 5) Evaluación (Top-k, MRR)\n",
    "Medimos la calidad de **predicción del siguiente token** en test. Reportamos **Top@1/3/5** y **MRR**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a4ef27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>positions</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Top@1</th>\n",
       "      <th>Top@3</th>\n",
       "      <th>Top@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KN (ord=4, D=0.9)</td>\n",
       "      <td>12779</td>\n",
       "      <td>0.572782</td>\n",
       "      <td>0.432898</td>\n",
       "      <td>0.661006</td>\n",
       "      <td>0.740825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  positions       MRR     Top@1     Top@3     Top@5\n",
       "0  KN (ord=4, D=0.9)      12779  0.572782  0.432898  0.661006  0.740825"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalúa en test con el mejor KN\n",
    "kn_best_test = evaluate_next_token_ranking(best_kn, test_seqs, topk_list=(1,3,5))\n",
    "pd.DataFrame([{\"Model\": f\"KN (ord={best_cfg['order']}, D={best_cfg['D']})\", **kn_best_test}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392592e",
   "metadata": {},
   "source": [
    "Kneser–Ney (ord=4, D=0.9) v2\n",
    "(utilizando las progresiones funcionales con mejoras en la transcripción)\n",
    "\n",
    "Comparación con modelo Kneser-Ney (ord=3, D=0.75):\n",
    "- Top@1: +0,017 ptos (0.4152 → 0.4329) \n",
    "- Top@3: +0,009 ptos (0.6516 → 0.6610)\n",
    "- Top@5: +0,003 ptos (0.7375 → 0.7408)\n",
    "- MRR: +0,0123 (0.5605 → 0.5728)\n",
    "\n",
    "Aunque la mejora es modesta, es consistente en todas las métricas, indicando que el modelo se beneficia de un mayor contexto (orden 4) y un ajuste del parámetro de descuento (D=0.9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17385fd7",
   "metadata": {},
   "source": [
    "*Nota sobre las mejora en el preprocesado*\n",
    "\n",
    "*Comparación con modelo Kneser-Ney (ord=4, D=0.9) v1 (sin las últimas mejoras en la transcripción):*\n",
    "- *Top@1: +0,011 ptos (0.4219 → 0.4329)*\n",
    "- *Top@3: +0,008 ptos (0.6526 → 0.6610)*\n",
    "- *Top@5: +0,002 ptos (0.7445 → 0.7408)*\n",
    "- *MRR: +0,0091 (0.5667 → 0.5728)*\n",
    "\n",
    "*El modelo explota mejor la “nueva gramática” (V/·, Vsub/·, #iv°, natIII, natVI, etc.). El aumento en Top@1 y MRR indica que ahora el modelo “acierta antes” con más frecuencia: señal de secuencias más consistentes y menos ambigüedad en el vocabulario.*\n",
    "\n",
    "*¿Por qué mejoran las métricas?*\n",
    "- *Menos tokens “residuales” tipo (4), (6), (9) ⇒ menos ruido.*\n",
    "- *Señales funcionales explícitas (V/ii, Vsub/V) ⇒ mejor predicción local (n-gramas lo agradecen)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f91b20",
   "metadata": {},
   "source": [
    "## 7) Exportamos el modelo como 'best_kn_model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "725a749e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../models/kn_gs_v2/best_kn_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_kn, '../../models/kn_gs_v2/best_kn_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8322e571",
   "metadata": {},
   "source": [
    "## 8) Demo: sugerencias y autocompletado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d19902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEMO: sugerencias y autocompletado con el KN óptimo ===\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "assert 'best_kn' in globals(), \"No encuentro 'best_kn'. Ejecuta antes la celda de grid search.\"\n",
    "assert 'test_seqs' in globals(), \"No encuentro 'test_seqs'. Ejecuta antes la partición de datos.\"\n",
    "\n",
    "def topk_next(model, context, k=5, exclude_special=True):\n",
    "    \"\"\"Devuelve las k mejores sugerencias (token, prob) dado el contexto.\"\"\"\n",
    "    ranking = model.predict_ranking(context)\n",
    "    if exclude_special:\n",
    "        ranking = [(w,p) for (w,p) in ranking if w not in {\"<s>\", \"</s>\", \"<unk>\"}]\n",
    "    return ranking[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a0ed4",
   "metadata": {},
   "source": [
    "### 7.1) Probamos algunas secuencias clásicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c40e365",
   "metadata": {},
   "source": [
    "Modo mayor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c4cfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.3734150220734017),\n",
       " ('ii', 0.10753082407664535),\n",
       " ('vi', 0.105420704083276),\n",
       " ('V7', 0.052316504322354795),\n",
       " ('IV', 0.04821778901796282)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Echamos un vistazo a las sugerencias desde el acorde de tónica.\n",
    "pred = topk_next(best_kn, [\"I\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4c03d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.5147374520306233),\n",
       " ('V7', 0.20810002151938234),\n",
       " ('I7', 0.06348083569710526),\n",
       " ('II', 0.05433766157067823),\n",
       " ('i', 0.029277076949103812)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"II\", \"V7\"] > \"I\" @Top1\n",
    "pred = topk_next(best_kn, [\"II\", \"V7\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455b993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V', 0.3619163310072302),\n",
       " ('IV', 0.3145394182731477),\n",
       " ('I', 0.12915102984178167),\n",
       " ('vi', 0.09827329856710684),\n",
       " ('v', 0.04347285267236621)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title pop-punk [\"I\", \"V\", \"vi\" \"IV\"] \n",
    "pred = topk_next(best_kn, [\"I\", \"V\"], k=5) # @Top4\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae807d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('II7', 0.21186953407468012),\n",
       " ('V', 0.16701901045989845),\n",
       " ('V/V', 0.1431200511922982),\n",
       " ('Vsub/II', 0.1044223682400282),\n",
       " ('vi', 0.09645031890317396)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title pop-punk [\"I\", \"V\", \"vi\" \"IV\"] \n",
    "pred = topk_next(best_kn, [\"I\", \"V\", 'vi'], k=5) # No propone el acorde esperado\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9d8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.5523479680300832),\n",
       " ('iii', 0.17868779919129707),\n",
       " ('V7', 0.09357061851630752),\n",
       " ('V', 0.07075552203473516),\n",
       " ('IV', 0.06705918922323578)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = topk_next(best_kn, [\"I\", \"IV\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950d7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.6852342845268492),\n",
       " ('bVII7', 0.0911883723274025),\n",
       " ('iii', 0.07167197964826987),\n",
       " ('iv', 0.05531088804241253),\n",
       " ('V', 0.0168095248648733)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"IV\", \"iv\"] > \"I\" (@Top1)\n",
    "pred = topk_next(best_kn, [\"IV\", \"iv\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ea965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ii', 0.2536295068957499),\n",
       " ('IV', 0.19301160791927907),\n",
       " ('vi', 0.12225064852545692),\n",
       " ('V/II', 0.11544736712344839),\n",
       " ('biiio', 0.0866727151744685)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = topk_next(best_kn, [\"I\", \"ii\", \"iii\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ac02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.8007619646811053),\n",
       " ('ii', 0.0912653006604839),\n",
       " ('vi', 0.030674614403312553),\n",
       " ('Vsub/III', 0.020604351350864265),\n",
       " ('I', 0.010689323093255666)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = topk_next(best_kn, [\"vi\", \"ii\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6553f657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.5923288712978145),\n",
       " ('IV', 0.2997835833604025),\n",
       " ('bVII', 0.038251036525888314),\n",
       " ('V/IV', 0.01421183877548663),\n",
       " ('V7', 0.013465340638542427)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = topk_next(best_kn, [\"I\", \"bVII\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e430566",
   "metadata": {},
   "source": [
    "Modo menor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5117708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 0.4567366640398732),\n",
       " ('iiø', 0.11593073164806672),\n",
       " ('V7', 0.09815538622614726),\n",
       " ('VI', 0.049291912898090054),\n",
       " ('iv', 0.043694122784600234)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = topk_next(best_kn, [\"i\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7769c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 0.3797665999357742),\n",
       " ('I', 0.3726490852969921),\n",
       " ('V7', 0.10379978030365061),\n",
       " ('iiø', 0.092943737965714),\n",
       " ('VI', 0.005684761530808764)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = topk_next(best_kn, [\"iiø\", \"V7\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7172d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.9499133790613948),\n",
       " ('iiø', 0.0404212015707477),\n",
       " ('i', 0.0018882724017321784),\n",
       " ('I', 0.0014848214171321683),\n",
       " ('bVI7', 0.0013082564348126887)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = topk_next(best_kn, [\"VI\", \"iiø\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e324237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.3352135194999175),\n",
       " ('i', 0.2714959128569826),\n",
       " ('iv', 0.15174976164566029),\n",
       " ('V/III', 0.07723979242357881),\n",
       " ('bVII7', 0.04196969293049771)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = topk_next(best_kn, [\"i\", \"iv\"], k=5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d034799",
   "metadata": {},
   "source": [
    "### 7.2) Experimento: autocompletado \"greedy\" (+3 pasos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_complete(model, seed, steps=3):\n",
    "    \"\"\"Completa secuencialmente el siguiente token escogiendo siempre el de mayor prob.\"\"\"\n",
    "    seq = list(seed)\n",
    "    for _ in range(steps):\n",
    "        preds = topk_next(model, seq, k=1)\n",
    "        if not preds:\n",
    "            break\n",
    "        next_tok = preds[0][0]\n",
    "        seq.append(next_tok)\n",
    "        if next_tok == \"</s>\":\n",
    "            break\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f91512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>greedy_+3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I I V7 V7</td>\n",
       "      <td>I I V7 V7 I I I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I VII7 I vi</td>\n",
       "      <td>I VII7 I vi IV V7 I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#iv ii ii bII7</td>\n",
       "      <td>#iv ii ii bII7 I I I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seed             greedy_+3\n",
       "0       I I V7 V7       I I V7 V7 I I I\n",
       "1     I VII7 I vi   I VII7 I vi IV V7 I\n",
       "2  #iv ii ii bII7  #iv ii ii bII7 I I I"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows = []\n",
    "for seed in [s[:CTX_LEN] for s in random.sample(pool, min(3, len(pool)))]:\n",
    "    completed = greedy_complete(best_kn, seed, steps=3)\n",
    "    rows.append({\"seed\": \" \".join(seed), \"greedy_+3\": \" \".join(completed)})\n",
    "\n",
    "display(pd.DataFrame(rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da458975",
   "metadata": {},
   "source": [
    "¡Ojo! Problema con las repeticiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacb5fda",
   "metadata": {},
   "source": [
    "## Roadmap (siguientes mejoras)\n",
    "- Implementar un modelo de **re-ranking** para mejorar la precisión de las predicciones: evitar las repeticiones, ajuste a una tonalidad dada.\n",
    "\n",
    "- **Tabla de errores** para análisis de fallos en las predicciones.\n",
    "- Exportar pickle y crear API REST para usar el modelo en producción."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
