{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX_bw2Ze_3nA"
   },
   "source": [
    "# Predicciones con modelos LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdBsUpzWhBwH"
   },
   "source": [
    "## 1) Cargamos el modelo desde el archivo .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "executionInfo": {
     "elapsed": 12764,
     "status": "ok",
     "timestamp": 1756291748734,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "STru7OhxJhb_",
    "outputId": "23ce58d4-7095-489f-ac84-902c73f2a019"
   },
   "outputs": [],
   "source": [
    "#@title Subir archivo .pt\n",
    "try:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5316,
     "status": "ok",
     "timestamp": 1756291673672,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "nJjHf6P8_y4X",
    "outputId": "465f5b6c-a70b-406f-e952-e22c89e1cc85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys en el checkpoint: dict_keys(['model_state', 'model_class', 'config', 'metrics_test', 'stoi', 'itos', 'vocab_size', 'created_at', 'env'])\n",
      "Faltan: Nada\n",
      "seq_len: 16\n",
      "tie_weights: True\n"
     ]
    }
   ],
   "source": [
    "#@title Comprobar que el .pt contiene toda la información necesaria\n",
    "import torch\n",
    "path = \"/content/lstm_rs_v3.pt\"  \n",
    "ckpt = torch.load(path, map_location=\"cpu\", weights_only=False)\n",
    "print(\"Keys en el checkpoint:\", ckpt.keys())\n",
    "\n",
    "# Verificaciones mínimas\n",
    "req = {\"model_state\", \"config\", \"stoi\", \"itos\"}\n",
    "missing = req - set(ckpt.keys())\n",
    "print(\"Faltan:\", missing if missing else \"Nada\")\n",
    "\n",
    "# Tokens especiales y parámetros críticos\n",
    "for tok in [\"<unk>\", \"<bos>\"]:\n",
    "    assert tok in ckpt[\"stoi\"], f\"Falta el token {tok} en el vocabulario.\"\n",
    "print(\"seq_len:\", ckpt[\"config\"].get(\"seq_len\"))\n",
    "print(\"tie_weights:\", ckpt[\"config\"].get(\"tie_weights\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756291676573,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "jdDtncWbN90z"
   },
   "outputs": [],
   "source": [
    "#@title Comprobación extra: vocab_size = len(stoi)\n",
    "assert ckpt[\"vocab_size\"] == len(ckpt[\"stoi\"]), \"vocab_size no coincide con len(stoi)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756291760010,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "8Oj7fvL5uCxV",
    "outputId": "a5c674ba-7dea-43b7-ab8d-ae96d5db7e6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargado. Métricas (test) guardadas: {'loss': 2.252060778257626, 'ppl': 9.50730811622195, 'Top@1': 0.45036420395421434, 'Top@3': 0.6936524453818116, 'Top@5': 0.7761706556043317, 'MRR': 0.5956792587544246}\n"
     ]
    }
   ],
   "source": [
    "#@title Recreamos la arquitectura ChordLSTM y cargamos el modelo\n",
    "import torch, torch.nn as nn\n",
    "\n",
    "class ChordLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, dropout, tie_weights=False):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers=num_layers,\n",
    "                           batch_first=True, dropout=dropout if num_layers>1 else 0.0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.tie_weights = tie_weights\n",
    "        if tie_weights:\n",
    "            self.proj = nn.Linear(hidden_size, embedding_dim, bias=False) if hidden_size != embedding_dim else nn.Identity()\n",
    "            self.decoder = nn.Linear(embedding_dim, vocab_size, bias=False)\n",
    "            self.decoder.weight = self.emb.weight\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.emb(x)                 # (B, T, E)\n",
    "        o, _ = self.rnn(e)              # (B, T, H)\n",
    "        h = self.dropout(o[:, -1, :])   # (B, H)\n",
    "        return self.decoder(self.proj(h)) if self.tie_weights else self.fc(h)  # (B, V)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_best_checkpoint(path):\n",
    "    try:\n",
    "        ckpt = torch.load(path, map_location=\"cpu\")  # intenta modo seguro (weights_only=True)\n",
    "    except Exception:\n",
    "        ckpt = torch.load(path, map_location=\"cpu\", weights_only=False)  # fallback\n",
    "    cfg  = ckpt[\"config\"]\n",
    "    model = ChordLSTM(\n",
    "        vocab_size=len(ckpt[\"stoi\"]),\n",
    "        embedding_dim=cfg[\"embedding_dim\"],\n",
    "        hidden_size=cfg[\"hidden_size\"],\n",
    "        num_layers=cfg[\"num_layers\"],\n",
    "        dropout=cfg[\"dropout\"],\n",
    "        tie_weights=cfg.get(\"tie_weights\", False),\n",
    "    )\n",
    "    model.load_state_dict(ckpt[\"model_state\"], strict=True)\n",
    "    model.to(device).eval()\n",
    "    return model, ckpt[\"stoi\"], ckpt[\"itos\"], cfg, ckpt.get(\"metrics_test\", None)\n",
    "\n",
    "model, stoi, itos, cfg, metrics = load_best_checkpoint(\"/content/lstm_rs_v3.pt\") # \"lstm_rs_v3.pt\" / \"lstm_rs_v2.pt\"\n",
    "print(\"Cargado. Métricas (test) guardadas:\", metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51A1UJ5nhyPg"
   },
   "source": [
    "## 2) Definimos la función de predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1756291763921,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "L6jFusxGuS-1"
   },
   "outputs": [],
   "source": [
    "#@title Definicion de `predict_next()` usando el chekpoint empaquetado\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict_next(model, stoi, itos, context_tokens, seq_len, k=5):\n",
    "    unk_id = stoi.get(\"<unk>\")\n",
    "    if unk_id is None:\n",
    "      raise KeyError(\"El vocabulario no contiene '<unk>'.\")\n",
    "    bos_id = stoi.get(\"<bos>\")\n",
    "\n",
    "    ids = [stoi.get(t, unk_id) for t in context_tokens]\n",
    "    if len(ids) < seq_len and bos_id is not None:\n",
    "        ids = [bos_id] * (seq_len - len(ids)) + ids\n",
    "    else:\n",
    "        ids = ids[-seq_len:]\n",
    "\n",
    "    x = torch.tensor(ids, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    logits = model(x)                           # (1, V)\n",
    "    probs  = F.softmax(logits[0], dim=-1)       # (V,)\n",
    "    topk   = torch.topk(probs, k)\n",
    "    return [(itos[i.item()], float(p.item())) for i,p in zip(topk.indices, topk.values)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUP9bmVzTnXh"
   },
   "source": [
    "## 3) Evaluamos el rendimiento del modelo con algunas progresiones clásicas de acordes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8tr3_XyT6_d"
   },
   "source": [
    "#### Progresiones clásicas en tonalidad mayor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1756292235320,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "RqDKCWax6If8",
    "outputId": "2fbafc1c-675e-40e7-f237-eec01266dc12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.728754460811615),\n",
       " ('bii', 0.08350379765033722),\n",
       " ('io', 0.06358400732278824),\n",
       " ('vii', 0.02492613159120083),\n",
       " ('VII', 0.020677480846643448)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next(model, stoi, itos, [\"I\"], seq_len=cfg[\"seq_len\"], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1756292236653,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "wqfhSL2M5fAX",
    "outputId": "6bb139b1-da96-4940-f2b4-de677375e196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.19316720962524414),\n",
       " ('I', 0.1889045089483261),\n",
       " ('bii', 0.12631601095199585),\n",
       " ('Vsub/VII', 0.0901450663805008),\n",
       " ('#IV7', 0.07938558608293533)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"II\", \"V7\"] > \"I\"\n",
    "predict_next(model, stoi, itos, [\"ii\", \"V7\"], seq_len=cfg[\"seq_len\"], k=5) # Top2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1756292344758,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "4dnC1TgR6hDo",
    "outputId": "631fe783-bf64-4e8b-f55c-e154df61fdb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V', 0.3473909795284271),\n",
       " ('I', 0.11748773604631424),\n",
       " ('bii', 0.10781167447566986),\n",
       " ('II', 0.07944024354219437),\n",
       " ('vo', 0.06364025920629501),\n",
       " ('Vsub/VII', 0.04106232896447182),\n",
       " ('VII', 0.024579769000411034),\n",
       " ('vii', 0.02164432778954506),\n",
       " ('V/VII', 0.020316386595368385),\n",
       " ('io', 0.01924402080476284)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title pop-punk [\"I\", \"V\"] >  \"vi\" \"IV\"\n",
    "predict_next(model, stoi, itos, [\"I\", \"V\"], seq_len=cfg[\"seq_len\"], k=10) # No acierta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1756292355719,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "wYWGWoV8LjGp",
    "outputId": "cfc2f6ef-85f0-45f4-8011-8f9a4d74b0ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('II', 0.3430151641368866),\n",
       " ('V/V', 0.14899735152721405),\n",
       " ('vii', 0.08112698048353195),\n",
       " ('V', 0.06390789896249771),\n",
       " ('II7', 0.04675060883164406),\n",
       " ('bIII', 0.025602517649531364),\n",
       " ('bviio', 0.024007735773921013),\n",
       " ('vi', 0.020670782774686813),\n",
       " ('bii', 0.018382836133241653),\n",
       " ('Vsub/VII', 0.01828482747077942)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title pop-punk [\"I\", \"V\", \"vi\"] > \"IV\"\n",
    "predict_next(model, stoi, itos, [\"I\", \"V\", \"vi\"], seq_len=cfg[\"seq_len\"], k=10) # No acierta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1756292659904,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "sKzBgVSQ7P9O",
    "outputId": "e253fd78-81fd-46ab-ef9b-30542eaf5f52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IV', 0.3151707947254181),\n",
       " ('VII', 0.10519496351480484),\n",
       " ('iii', 0.05927819758653641),\n",
       " ('I', 0.057974252849817276),\n",
       " ('bIII', 0.05760975554585457)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"I\", \"IV\"] > \"I\"\n",
    "predict_next(model, stoi, itos, [\"I\", \"IV\"], seq_len=cfg[\"seq_len\"], k=5) # top 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1756292736046,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "T6H71Lkh7gGT",
    "outputId": "eccbaa99-6778-4bd9-c883-3e7e3f0b55ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iii', 0.2716154456138611),\n",
       " ('iv', 0.21452674269676208),\n",
       " ('V7', 0.04864968731999397),\n",
       " ('bIII7', 0.039231523871421814),\n",
       " ('VII', 0.038391176611185074),\n",
       " ('I', 0.035610079765319824)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"IV\", \"iv\"] > \"I\" (@Top1)\n",
    "predict_next(model, stoi, itos, [\"IV\", \"iv\"], seq_len=cfg[\"seq_len\"], k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1756292932415,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "HrmYfkfdNw2r",
    "outputId": "67f5415e-5923-4ac9-c33b-947e757eb152"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iii', 0.7038135528564453),\n",
       " ('bii', 0.06771917641162872),\n",
       " ('ii', 0.040831223130226135),\n",
       " ('VII', 0.03330032899975777),\n",
       " ('IV', 0.029631592333316803)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"i\", \"ii\", \"iii\"] > \"ii\" o \"IV\"\n",
    "predict_next(model, stoi, itos, [\"i\", \"ii\", \"iii\"], seq_len=cfg[\"seq_len\"], k=5) # top3 top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1755703442282,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "QX64dqb-ReTx",
    "outputId": "243915c5-e251-4f1e-aac2-f318e509f527"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ii', 0.43206366896629333),\n",
       " ('bii', 0.18932126462459564),\n",
       " ('bIII7', 0.16770334541797638),\n",
       " ('V7', 0.1022372841835022),\n",
       " ('iii', 0.022949496284127235)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"vi\", \"ii\"] > \"V7\"\n",
    "predict_next(model, stoi, itos, [\"vi\", \"ii\"], seq_len=cfg[\"seq_len\"], k=5) #top4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1756293151328,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "rtajYDlKOk7T",
    "outputId": "8d5501bb-5324-43c7-caef-dc7883cfaed3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.2037191390991211),\n",
       " ('bii', 0.14785631000995636),\n",
       " ('IV', 0.08624669909477234),\n",
       " ('V7', 0.08021286875009537),\n",
       " ('vii', 0.07252342998981476)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"I\", \"bVII\"] > \"I\"\n",
    "predict_next(model, stoi, itos, [\"I\", \"bVII\"], seq_len=cfg[\"seq_len\"], k=5) #top1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4GUP7d9T9Fh"
   },
   "source": [
    "#### Progresiones clásicas en tonalidad menor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1756293324742,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "G8bTXnE0RYC4",
    "outputId": "637aa314-a6c2-42a7-f6d6-174136899135"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.34982505440711975),\n",
       " ('bii', 0.12342175841331482),\n",
       " ('vo', 0.09434334188699722),\n",
       " ('#IV7', 0.0677952766418457),\n",
       " ('I', 0.0671551302075386)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"iiø\", \"V7\"] > \"i\"\n",
    "predict_next(model, stoi, itos, [\"iiø\",\"V7\"], seq_len=cfg[\"seq_len\"], k=5) # No acierta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1756293487382,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "CY0-JoFRHnjp",
    "outputId": "2e9069af-4709-409c-f7bb-46866c270976"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.4765273928642273),\n",
       " ('vo', 0.11953472346067429),\n",
       " ('bii', 0.0630049929022789),\n",
       " ('iiø', 0.024293364956974983),\n",
       " ('bII7', 0.022607818245887756)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"VI\", \"iiø\"] > \"V7\"\n",
    "predict_next(model, stoi, itos, [\"VI\",\"iiø\"], seq_len=cfg[\"seq_len\"], k=5) # top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1756293569453,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "cfQAo8kRQLit",
    "outputId": "c66dd8af-b61b-4671-a0fb-349cf884e72f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iv', 0.4768180251121521),\n",
       " ('V7', 0.1670931577682495),\n",
       " ('bIII7', 0.05279575660824776),\n",
       " ('i', 0.042017169296741486),\n",
       " ('iii', 0.034302033483982086)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"i\", \"iv\"] > \"V7\"\n",
    "predict_next(model, stoi, itos, [\"i\",\"iv\"], seq_len=cfg[\"seq_len\"], k=5) # top2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUiWrXHmOyU5"
   },
   "source": [
    "#### Dominantes secundatios y sustitutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1756294360582,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "kdniKd8OUErm",
    "outputId": "9632a3cd-b32b-4287-92f7-cefa78af4cc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iv', 0.5058850646018982),\n",
       " ('IV', 0.46033164858818054),\n",
       " ('ivø', 0.01178439985960722),\n",
       " ('IV7', 0.009501107037067413),\n",
       " ('vii', 0.002293897559866309)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"i\", \"V/IV\"] > \"iv\"\n",
    "predict_next(model, stoi, itos, [\"i\", \"V/IV\"], seq_len=cfg[\"seq_len\"], k=5) # top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1756293924780,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "if1D9AxqRkB5",
    "outputId": "4d22ab9d-589a-4e2f-cfb6-941891f0a43d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.7820895314216614),\n",
       " ('V', 0.10662396252155304),\n",
       " ('bii', 0.03307785838842392),\n",
       " ('vo', 0.02601395547389984),\n",
       " ('io', 0.010889648459851742)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"I\", \"Vsub/V\"] > \"V7\"\n",
    "predict_next(model, stoi, itos, [\"I\", \"Vsub/V\"], seq_len=cfg[\"seq_len\"], k=5) # top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1756294090488,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "hQi5onRIRj1p",
    "outputId": "ef19353d-4280-4819-8cf2-326c9f982064"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ii', 0.44632476568222046),\n",
       " ('vo', 0.15586133301258087),\n",
       " ('bii', 0.09905041754245758),\n",
       " ('biio', 0.06002334505319595),\n",
       " ('Vsub/VII', 0.046702779829502106)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title [\"I\", \"biio\"] > \"ii\"\n",
    "predict_next(model, stoi, itos, [\"I\", \"biio\"], seq_len=cfg[\"seq_len\"], k=5) # top1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFDOY4YAUllm"
   },
   "source": [
    "#### Caso de uso: componiendo una progresión de acordes escogiendo entre las sugerencias de predict_next()\n",
    "secuencia resultante: i → V/V → V7 → i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1756294377708,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "cNGe3AoKR-bB",
    "outputId": "5e31f1b9-3dac-43d0-b221-6ba00753d4a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 0.34708404541015625),\n",
       " ('bIII7', 0.2831963896751404),\n",
       " ('bii', 0.11497221142053604),\n",
       " ('biii', 0.04154810681939125),\n",
       " ('bIII', 0.023175673559308052)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next(model, stoi, itos, [\"i\"], seq_len=cfg[\"seq_len\"], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1755703442420,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "BigzufHWSurk",
    "outputId": "9f7ae8bc-84cd-4053-a145-b72db5e04152"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V', 0.7204613089561462),\n",
       " ('V7', 0.17053626477718353),\n",
       " ('v', 0.09626950323581696),\n",
       " ('bii', 0.005243147257715464),\n",
       " ('bvio', 0.0018288219580426812)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next(model, stoi, itos, [\"i\", \"V/V\"], seq_len=cfg[\"seq_len\"], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1755703442436,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "LgP6emeUUeAk",
    "outputId": "bb5ecd62-2cf3-42a4-8d96-c89436a83aa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.3577346205711365),\n",
       " ('bii', 0.08322422951459885),\n",
       " ('i', 0.06308762729167938),\n",
       " ('#IV7', 0.06268736720085144),\n",
       " ('vo', 0.04323260858654976)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next(model, stoi, itos, [\"i\", \"V/V\", \"V7\"], seq_len=cfg[\"seq_len\"], k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2ooRE3YiMKN"
   },
   "source": [
    "## 4) Definimos StatefulPredictor: predictor con memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQ2Jh9KKrnti"
   },
   "outputs": [],
   "source": [
    "# @title Stateful predictor para uso interactivo paso a paso\n",
    "import torch, torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class StatefulPredictor:\n",
    "    def __init__(self, model, stoi, itos, device, start_with_bos=True):\n",
    "        self.model, self.stoi, self.itos = model.eval(), stoi, itos\n",
    "        self.device = device\n",
    "        self.start_with_bos = start_with_bos\n",
    "        self.h = None  # (h,c) en LSTM; h en GRU\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinicia el estado oculto.\n",
    "        Si start_with_bos=True, inyecta el token <bos> para marcar el inicio.\n",
    "        \"\"\"\n",
    "        self.h = None\n",
    "        if self.start_with_bos and \"<bos>\" in self.stoi:\n",
    "            self._step(\"<bos>\")  # marcador de inicio\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def _step(self, token):\n",
    "        \"\"\"\n",
    "        Propaga un token y actualiza el estado oculto.\n",
    "        Devuelve los logits (no normalizados) para el SIGUIENTE token.\n",
    "        \"\"\"\n",
    "        tid = torch.tensor([[self.stoi.get(token, self.stoi[\"<unk>\"])]], device=self.device)\n",
    "        e = self.model.emb(tid)                            # (1,1,E)\n",
    "        out, self.h = self.model.rnn(e, self.h)            # (1,1,H)\n",
    "        last = out[:, -1, :]                               # (1,H)\n",
    "        last = self.model.dropout(last)                    # ruta idéntica a forward\n",
    "        logits = (\n",
    "            self.model.decoder(self.model.proj(last))\n",
    "            if getattr(self.model, \"tie_weights\", False)\n",
    "            else self.model.fc(last)\n",
    "        )                                                  # (1,V)\n",
    "        return logits[0]                                   # (V,)\n",
    "\n",
    "    def add(self, token, k=5):\n",
    "        \"\"\"\n",
    "        Añade un nuevo acorde al contexto y devuelve predicción para el siguiente.\n",
    "        \"\"\"\n",
    "        logits = self._step(token)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        topk = torch.topk(probs, k)\n",
    "        return [(self.itos[i.item()], float(p.item())) for i,p in zip(topk.indices, topk.values)]\n",
    "\n",
    "\n",
    "    def suggest_window(self, context_tokens, seq_len, k=5):\n",
    "      \"\"\"\n",
    "      Emula EXACTAMENTE la lógica de predict_next():\n",
    "      - recorta al último seq_len\n",
    "      - acolcha con <bos> a la izquierda hasta seq_len si hace falta\n",
    "      \"\"\"\n",
    "      self.h = None\n",
    "      # No inyectamos <bos> automático aquí:\n",
    "      # ignoramos self.start_with_bos a propósito\n",
    "\n",
    "      # recorte/acolchado\n",
    "      ctx = list(context_tokens)\n",
    "      if len(ctx) >= seq_len:\n",
    "          ctx = ctx[-seq_len:]\n",
    "          bos_to_add = 0\n",
    "      else:\n",
    "          bos_to_add = seq_len - len(ctx)\n",
    "\n",
    "      preds = None\n",
    "      # 1) Acolchar con <bos>\n",
    "      if \"<bos>\" in self.stoi:\n",
    "          for _ in range(bos_to_add):\n",
    "              preds = self.add(\"<bos>\", k=k)\n",
    "      # 2) Alimentar el contexto real\n",
    "      for t in ctx:\n",
    "          preds = self.add(t, k=k)\n",
    "      # La última llamada produce la sugerencia para el siguiente\n",
    "      return preds\n",
    "\n",
    "    def suggest(self, context_tokens, k=5):\n",
    "        \"\"\"\n",
    "        Modo 'streaming':\n",
    "        1. Resetea el estado\n",
    "        2. Consume el nuevo contexto completo\n",
    "        3. Devuelve la predicción para el siguiente acorde\n",
    "        - No trunca seq_len ni acolcha con múltiples <bos>\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "        preds = None\n",
    "        for t in context_tokens:\n",
    "            preds = self.add(t, k=k)  # la última llamada predice el siguiente\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1755703442450,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "S1nHo4t3gwY9",
    "outputId": "5f9f267c-e996-4376-efb8-94307f35633b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.43416544795036316),\n",
       " ('ii', 0.27106398344039917),\n",
       " ('iii', 0.07574915885925293),\n",
       " ('V', 0.04748965799808502),\n",
       " ('V7', 0.030107686296105385)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = StatefulPredictor(model, stoi, itos, device)\n",
    "sp.suggest([\"ii\",\"V\"], k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAGB_oJAqNvG"
   },
   "source": [
    "### Prueba rápida de consistencia\n",
    "Podemos comprobar como si utilizamos `sp.suggest_window()` forzamos que el tamaño de la ventana (seq_len) sea igual al utilizado por `predict_next()`.\n",
    "\n",
    "Sin embargo sp.sugest() o sp.add() no utilizan un tamaño de contexto fijo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1755703442458,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "uGDSG6FKYxxE",
    "outputId": "25cb2f91-0bc3-4deb-de9f-8523ffb38f82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_next: [('I', 0.728754460811615), ('bii', 0.08350379765033722), ('io', 0.06358400732278824), ('vii', 0.02492613159120083), ('VII', 0.020677480846643448)]\n",
      "stateful(win): [('I', 0.7287544012069702), ('bii', 0.08350386470556259), ('io', 0.06358397752046585), ('vii', 0.024926118552684784), ('VII', 0.020677490159869194)]\n",
      "stateful(free): [('I', 0.47631093859672546), ('ii', 0.080355204641819), ('vi', 0.04353588446974754), ('iii', 0.02913953922688961), ('IV', 0.029027318581938744)]\n"
     ]
    }
   ],
   "source": [
    "# A) Función predict_next()\n",
    "predA = predict_next(model, stoi, itos, [\"I\"], seq_len=cfg[\"seq_len\"], k=5)\n",
    "\n",
    "# B) Stateful emulando ventana fija\n",
    "sp = StatefulPredictor(model, stoi, itos, device, start_with_bos=False)\n",
    "predB = sp.suggest_window([\"I\"], seq_len=cfg[\"seq_len\"], k=5)\n",
    "\n",
    "# C) Stateful sin ventana fija\n",
    "predC = sp.suggest([\"I\"], k=5)\n",
    "\n",
    "print(\"predict_next:\", predA)\n",
    "print(\"stateful(win):\", predB)\n",
    "print(\"stateful(free):\", predC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ky4TRIMtyKu"
   },
   "source": [
    "#### Secuencia de acordes escogiendo entre los sugeridos: I → VII7 → iii → V7 → I\n",
    "utilizando `sp.suggest_window()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1755703942108,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "nmLddq7qaBf2",
    "outputId": "db24388d-6df5-4469-8bc7-09576a306798"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VI7', 0.08308775722980499),\n",
       " ('Vsub/IV', 0.07835402339696884),\n",
       " ('V/II', 0.06114249676465988),\n",
       " ('V/VII', 0.05947471410036087),\n",
       " ('V7', 0.049347199499607086)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.suggest([\"I\", \"V/iii\"], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1755703975267,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "5iJW773taLV7",
    "outputId": "71b29c32-7533-4a18-9380-00685919985f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iii', 0.5743696093559265),\n",
       " ('bii', 0.08598511666059494),\n",
       " ('VII', 0.062040168792009354),\n",
       " ('II', 0.05795701593160629),\n",
       " ('ii', 0.045799002051353455)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.suggest_window([\"I\", \"V/iii\", \"iii\"], seq_len=cfg[\"seq_len\"], k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1755704027395,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "jA3OW_Eyaa4l",
    "outputId": "5f1c5845-fd67-4bb3-f4f8-d44beaa3a9ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.28407374024391174),\n",
       " ('iii', 0.23797465860843658),\n",
       " ('I', 0.1087404116988182),\n",
       " ('bii', 0.05222799628973007),\n",
       " ('#IV7', 0.0371098667383194)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.suggest_window([\"I\", \"VII7\", \"iii\", 'V7'], seq_len=cfg[\"seq_len\"], k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2Q7xSHnubt8"
   },
   "source": [
    "#### Secuencia de acordes (2) escogiendo entre los sugeridos: I → I7 → IV→ iv\n",
    "utilizando `sp.add()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTndKLR-TIDY"
   },
   "outputs": [],
   "source": [
    "sp.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1755704112325,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "EZ_xFVv3TNCA",
    "outputId": "2c9e5c86-e564-4077-e8dd-86b21f485dee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.47631093859672546),\n",
       " ('ii', 0.080355204641819),\n",
       " ('vi', 0.04353588446974754),\n",
       " ('iii', 0.02913953922688961),\n",
       " ('IV', 0.029027318581938744)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.add('I', k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1755704071780,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "xAbY2gs7TTV0",
    "outputId": "cb0bcebe-19ef-490d-f664-3f19f6087a67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V7', 0.5520331263542175),\n",
       " ('ii', 0.1373572051525116),\n",
       " ('I', 0.05468360334634781),\n",
       " ('biiio', 0.0536913238465786),\n",
       " ('iii', 0.05137204751372337)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.add('ii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1755704076567,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "V3iiy94lTX8A",
    "outputId": "4e75ac99-1e90-43c0-c51e-ee62efe51ef5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ii', 0.267689049243927),\n",
       " ('IV', 0.22527460753917694),\n",
       " ('iii', 0.09536802023649216),\n",
       " ('V/II', 0.08170545101165771),\n",
       " ('vi', 0.045558806508779526)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.add('iii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1755704083769,
     "user": {
      "displayName": "Antonio L. Trapote",
      "userId": "06525061061648817839"
     },
     "user_tz": -120
    },
    "id": "X1AcuSVMTdB-",
    "outputId": "f6b4f17a-3e5e-449f-ef2e-4329108d59ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 0.6592168211936951),\n",
       " ('iii', 0.15768370032310486),\n",
       " ('V7', 0.0501166470348835),\n",
       " ('ii', 0.03659089654684067),\n",
       " ('v', 0.014157912693917751)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.add('ii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0mUC48ib5vu"
   },
   "source": [
    "## Optamos por un enfoque *stateless* (`predict_next`) para la API\n",
    "\n",
    "**Idea central:** cada interacción del cliente envía el contexto completo y recibe las **Top-k** propuestas del siguiente acorde. El servidor **no mantiene estado** entre peticiones.\n",
    "\n",
    "### Ventajas clave\n",
    "- **Simplicidad de implementación:** sin gestionar `h/c` del RNN, `reset()`, ni sincronización de estado entre sesiones.\n",
    "- **Reproducibilidad e idempotencia:** misma entrada ⇒ misma salida (sin depender de un estado oculto previo).\n",
    "- **Coherencia con la evaluación:** `predict_next` replica la **ventana fija** (`seq_len`) y el acolchado con `<bos>`, por lo que las predicciones son comparables con validación/test.\n",
    "- **Escalabilidad y arquitectura limpia:** servidor *sin estado* (stateless), fácil *horizontal scaling*, *load balancing* y *cacheo* de respuestas.\n",
    "- **Coste/latencia asumibles:** con `seq_len=16` y un LSTM pequeño, recomputar la ventana en cada paso es barato, incluso en **CPU** (no requiere GPU/CUDA).\n",
    "- **Robustez operativa:** reiniciar tras un error del usuario es trivial (no hay “estado corrupto” en memoria del servidor).\n",
    "- **Seguridad/aislamiento:** menos superficie de fallo y sin compartir estados entre usuarios.\n",
    "\n",
    "### Qué perdemos vs. *stateful*\n",
    "- **Eficiencia por paso:** en *stateful* el coste por token es O(1); aquí es O(`seq_len`). En nuestro caso el impacto es despreciable.\n",
    "- **Contexto > `seq_len`:** el modo *streaming* con estado puede aprovechar contextos más largos (aunque el modelo fue entrenado con ventana fija).\n",
    "\n",
    "### Cuándo reconsiderar *stateful*\n",
    "- Generación **muy larga** o **masiva** (beam grande / muestreos múltiples).\n",
    "- Requisitos de **latencia ultra-baja** y `seq_len` elevado.\n",
    "- Necesidad real de contexto que exceda `seq_len`.\n",
    "\n",
    "**Decisión:** dado nuestro caso (LSTM pequeño, `seq_len=16`, interacción paso a paso), el enfoque **stateless** ofrece el mejor equilibrio entre **simplicidad**, **consistencia** y **rendimiento**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0HF497xpq1a"
   },
   "source": [
    "## 4) Prototipo: explorando posibilidades para poner el modelo en producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3Way_hWEpi1D",
    "outputId": "c876156b-3f54-49bf-f7f2-c30a7ad85ce7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construye tu progresión. Escribe 'exit' para terminar.\n",
      "\n",
      "Introduce el primer acorde para empezar.\n",
      "Elige acorde (o 'exit'): i\n",
      "\n",
      "Secuencia: i\n",
      "Sugerencias:\n",
      "  1. i  (0.347)\n",
      "  2. bIII7  (0.283)\n",
      "  3. bii  (0.115)\n",
      "  4. biii  (0.042)\n",
      "  5. bIII  (0.023)\n",
      "  6. bviio  (0.018)\n",
      "  7. bVI  (0.017)\n",
      "  8. V  (0.013)\n",
      "  9. Vsub/VII  (0.013)\n",
      "  10. bvi  (0.012)\n"
     ]
    }
   ],
   "source": [
    "# @title Bucle mínimo funcional (mejorado)\n",
    "k = 10\n",
    "context = []\n",
    "\n",
    "print(\"Construye tu progresión. Escribe 'exit' para terminar.\\n\")\n",
    "\n",
    "while True:\n",
    "    if context:\n",
    "        # Mostrar la secuencia actual y sugerencias para el siguiente\n",
    "        preds = predict_next(model, stoi, itos, context, seq_len=cfg[\"seq_len\"], k=k)\n",
    "        print(f\"Secuencia: {', '.join(context)}\")\n",
    "        print(\"Sugerencias:\")\n",
    "        for i, (ch, p) in enumerate(preds, 1):\n",
    "            print(f\"  {i}. {ch}  ({p:.3f})\")\n",
    "    else:\n",
    "        # Hasta que el usuario escriba el primer acorde, no sugerimos nada\n",
    "        print(\"Introduce el primer acorde para empezar.\")\n",
    "\n",
    "    choice = input(\"Elige acorde (o 'exit'): \").strip()\n",
    "    if choice.lower() == \"exit\":\n",
    "        break\n",
    "    if choice not in stoi:\n",
    "        print(\"Acorde fuera del vocabulario; prueba otra vez.\\n\")\n",
    "        continue\n",
    "\n",
    "    context.append(choice)\n",
    "    print()  # línea en blanco para separar iteraciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySy59mmfqRD7"
   },
   "source": [
    "## 5) Roadmap\n",
    "- Incluir reranking para evitar repeticiones.\n",
    "- Opcion para ajustarse o no a una tonalidad dada.\n",
    "- Armar API Rest con Flask o FastAPI (probar en puerto local)\n",
    "- Incluir transcripcion C, Dm → I, ii → C, Dm para que el usuario introduzca y reciba acordes en notacion americana.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNEbROp0n3XavBfI644ePTv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
